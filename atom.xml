<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>OMG_By</title>
  
  <subtitle>沉心、静气、学习、总结、进步</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-06-05T12:43:42.783Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>OMG_By</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MySQL参数之innodb_autoinc_lock_mode</title>
    <link href="http://yoursite.com/2020/06/05/MySQL%E5%8F%82%E6%95%B0%E4%B9%8Binnodb-autoinc-lock-mode/"/>
    <id>http://yoursite.com/2020/06/05/MySQL参数之innodb-autoinc-lock-mode/</id>
    <published>2020-06-05T12:41:13.000Z</published>
    <updated>2020-06-05T12:43:42.783Z</updated>
    
    <content type="html"><![CDATA[<h2 id="insert种类"><a href="#insert种类" class="headerlink" title="insert种类"></a>insert种类</h2><p>在讲<code>innodb_autoinc_lock_mode</code>参数之前，我们先来了解下MySQL insert的种类</p><ul><li>simple insert：插入的记录行数是确定的。比如：insert into、replace</li><li>bulk insert：插入的记录行数不能马上确认的。比如：insert…select、replace…select、load data</li><li>mixed-mode insert：也是’simple insert’，但是语句插入中存在没指定自增值的行。比如：INSERT INTO t1 (c1,c2) VALUES (1,’a’), (NULL,’b’), (5,’c’), (NULL,’d’)、INSERT … ON DUPLICATE KEY UPDATE</li></ul><h2 id="锁模式"><a href="#锁模式" class="headerlink" title="锁模式"></a>锁模式</h2><p>在了解了以上insert种类后。我们来对<code>innodb_autoinc_lock_mode</code>参数设置不同值时的表现进行描述。</p><h3 id="传统模式"><a href="#传统模式" class="headerlink" title="传统模式"></a>传统模式</h3><p>innodb_autoinc_lock_mode=0</p><p>这种模式性能最差，它会对所有的insert模式操作都去获取一个特殊的<code>table-level auto-inc</code>。这种锁会持续到语句结束，以确保执行的insert语句以可预测且可重复的顺序分配自动递增值。这种模式更多是为了兼容老版本的MySQL运行。</p><a id="more"></a><p>举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE t1 (</span><br><span class="line">  c1 INT(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  c2 VARCHAR(10) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (c1)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Tx1: INSERT INTO t1 (c2) SELECT 1000 rows from another table ...</span><br><span class="line">Tx2: INSERT INTO t1 (c2) VALUES (&apos;xxx&apos;);</span><br></pre></td></tr></table></figure></p><p>在上面的例子中，传统模式下，Tx1执行过程中会一直持有auto-inc锁，一直到Tx1执行完。所以Tx2必须等待锁释放。这会导致一个简单insert语句执行得非常慢。严重的影响了并发效率。<br>而在连续锁定模式下，Tx1执行前会预先计算需要插入的函数，在获取到auto-inc锁后立即释放。Tx2不会受到Tx1 auto-inc的影响。</p><h3 id="连续锁定模式"><a href="#连续锁定模式" class="headerlink" title="连续锁定模式"></a>连续锁定模式</h3><p>innodb_autoinc_lock_mode=1</p><p>在MySQL8.0.3之前，<code>innodb_autoinc_lock_mode</code>参数的默认值是1。也就是连续锁定模式。<br>在这种模式下，普通insert语句，申请到自增锁后就马上释放。bulk insert这样的批量插入数据语句，自增锁还是要等语句结束后才被释放。</p><p>在这种模式下，可能会申请多一部分自增键。导致自增键空洞情况的发生。<br>例如，假设 c1 列是表 t1 的 AUTO_INCREMENT 列，且假设最新自动生成的序列号为 100<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t1` (</span><br><span class="line">  `c1` int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `c2` char(1) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`c1`)</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=100 DEFAULT CHARSET=utf8</span><br><span class="line"></span><br><span class="line">INSERT INTO t1 (c1,c2) VALUES (1,&apos;a&apos;), (NULL,&apos;b&apos;), (5,&apos;c&apos;), (NULL,&apos;d&apos;);</span><br></pre></td></tr></table></figure></p><p>在连续模式下执行插入操作后，innodb在处理时分配了4个自增值，但是只使用了两个。所以导致了103和104被丢失了。这就导致了自增键的空洞现象。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show create table t1\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: t1</span><br><span class="line">Create Table: CREATE TABLE `t1` (</span><br><span class="line">  `c1` int(10) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `c2` char(1) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`c1`)</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=104 DEFAULT CHARSET=utf8</span><br><span class="line">1 row in set (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from t1 order by c2;</span><br><span class="line">+-----+------+</span><br><span class="line">| c1  | c2   |</span><br><span class="line">+-----+------+</span><br><span class="line">|   1 | a    |</span><br><span class="line">| 100 | b    |</span><br><span class="line">|   5 | c    |</span><br><span class="line">| 101 | d    |</span><br><span class="line">+-----+------+</span><br><span class="line">4 rows in set (0.30 sec)</span><br></pre></td></tr></table></figure></p><h3 id="交叉锁定模式"><a href="#交叉锁定模式" class="headerlink" title="交叉锁定模式"></a>交叉锁定模式</h3><p>innodb_autoinc_lock_mode=2</p><p>所有的申请自增锁操作都是申请后就立刻释放锁。在这个模式下，已经没有了AUTO-INC锁，所以这个模式下的性能是最好的。<br>这一模式下存在两个问题：<br>1、在这种模式下，如果binlog格式为statement，可能会引起数据不一致。<br>2、对于同一语句来说，它得到的auto_increment值可能不是连续的。</p><p>在SBR模式下，如果该值为2可能会引起主从数据不一致：<br>Master上的插入逻辑：</p><table><thead><tr><th style="text-align:center">时间点</th><th style="text-align:center">session1</th><th style="text-align:center">session2</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">1,A</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center">2,AA</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">3,B</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">4,C</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">4</td><td style="text-align:center"></td><td style="text-align:center">5,CC</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">6,D</td></tr></tbody></table><p>Master结果记录：</p><table><thead><tr><th style="text-align:center">a</th><th style="text-align:center">b</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">A</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">AA</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">B</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">C</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">CC</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">D</td></tr></tbody></table><p>由于session2先执行完，所以slave上的结果为：</p><table><thead><tr><th style="text-align:center">a</th><th style="text-align:center">b</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">AA</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">CC</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">A</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">B</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">C</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">D</td></tr></tbody></table><blockquote><p><a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-auto-increment-handling.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/innodb-auto-increment-handling.html</a><br><a href="https://www.docs4dev.com/docs/zh/mysql/5.7/reference/innodb-auto-increment-handling.html" target="_blank" rel="noopener">https://www.docs4dev.com/docs/zh/mysql/5.7/reference/innodb-auto-increment-handling.html</a><br><a href="https://www.twle.cn/c/yufei/innodb/innodb-basic-auto_increment.html" target="_blank" rel="noopener">https://www.twle.cn/c/yufei/innodb/innodb-basic-auto_increment.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;insert种类&quot;&gt;&lt;a href=&quot;#insert种类&quot; class=&quot;headerlink&quot; title=&quot;insert种类&quot;&gt;&lt;/a&gt;insert种类&lt;/h2&gt;&lt;p&gt;在讲&lt;code&gt;innodb_autoinc_lock_mode&lt;/code&gt;参数之前，我们先来了解下MySQL insert的种类&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;simple insert：插入的记录行数是确定的。比如：insert into、replace&lt;/li&gt;
&lt;li&gt;bulk insert：插入的记录行数不能马上确认的。比如：insert…select、replace…select、load data&lt;/li&gt;
&lt;li&gt;mixed-mode insert：也是’simple insert’，但是语句插入中存在没指定自增值的行。比如：INSERT INTO t1 (c1,c2) VALUES (1,’a’), (NULL,’b’), (5,’c’), (NULL,’d’)、INSERT … ON DUPLICATE KEY UPDATE&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;锁模式&quot;&gt;&lt;a href=&quot;#锁模式&quot; class=&quot;headerlink&quot; title=&quot;锁模式&quot;&gt;&lt;/a&gt;锁模式&lt;/h2&gt;&lt;p&gt;在了解了以上insert种类后。我们来对&lt;code&gt;innodb_autoinc_lock_mode&lt;/code&gt;参数设置不同值时的表现进行描述。&lt;/p&gt;
&lt;h3 id=&quot;传统模式&quot;&gt;&lt;a href=&quot;#传统模式&quot; class=&quot;headerlink&quot; title=&quot;传统模式&quot;&gt;&lt;/a&gt;传统模式&lt;/h3&gt;&lt;p&gt;innodb_autoinc_lock_mode=0&lt;/p&gt;
&lt;p&gt;这种模式性能最差，它会对所有的insert模式操作都去获取一个特殊的&lt;code&gt;table-level auto-inc&lt;/code&gt;。这种锁会持续到语句结束，以确保执行的insert语句以可预测且可重复的顺序分配自动递增值。这种模式更多是为了兼容老版本的MySQL运行。&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL参数" scheme="http://yoursite.com/tags/MySQL%E5%8F%82%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>pt-osc死锁分析记录两则</title>
    <link href="http://yoursite.com/2020/06/04/new/MySQL/pt-osc%E6%AD%BB%E9%94%81%E5%88%86%E6%9E%90%E8%AE%B0%E5%BD%95%E4%B8%A4%E5%88%99/"/>
    <id>http://yoursite.com/2020/06/04/new/MySQL/pt-osc死锁分析记录两则/</id>
    <published>2020-06-04T15:56:06.000Z</published>
    <updated>2020-06-04T15:59:10.595Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>今天看到叶老师公众号推送文章《<a href="!https://mp.weixin.qq.com/s/mJ6a-sV2C2ru5pA5QNAAZQ">pt-osc在线重建表导致死锁的分析及对应的优化方案</a>》，让我想起了前段时间同样遇到了pt-osc改表导致的死锁。故此记录一下。</p><h2 id="pt-osc"><a href="#pt-osc" class="headerlink" title="pt-osc"></a>pt-osc</h2><p>pt-online-schema-change：PERCONA提供的在线改表工具，避免MySQL在执行改表操作时造成的锁表和主从延迟情况发生。</p><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>1、创建一个跟原表表结构一样的新表。取名为<code>_oldTableNmae_new</code><br>2、修改新表结构<br>3、在原表中创建insert、update、delete三个类型的触发器，用于做增量数据迁移。原表SQL和触发器触发SQL在同一事务当中。<br>4、以一定块大小(chunk-size)从原表拷贝数据到新表<br>5、数据拷贝完后，修改表名：<code>rename table to table_old; rename _table_new to table</code><br>6、删除old表，删除三个触发器</p><h3 id="版本变化"><a href="#版本变化" class="headerlink" title="版本变化"></a>版本变化</h3><p>3.0.2之前的update触发器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REPLACE INTO `lc`.`_hb_new` (`id`, `ts`, `ts2`, `c1`) VALUES (NEW.`id`, NEW.`ts`, NEW.`ts2`, NEW.`c1`)</span><br></pre></td></tr></table></figure></p><p>3.0.2之后的update触发器:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BEGIN</span><br><span class="line">    DELETE IGNORE FROM `lc`.`_hb_new` WHERE !(OLD.`id` &lt;=&gt; NEW.`id`) AND `lc`.`_hb_new`.`id` &lt;=&gt; OLD.`id`;</span><br><span class="line">    REPLACE INTO `lc`.`_hb_new` (`id`, `ts`, `ts2`) VALUES (NEW.`id`, NEW.`ts`, NEW.`ts2`);</span><br><span class="line">END</span><br></pre></td></tr></table></figure></p><a id="more"></a><h2 id="死锁案例一"><a href="#死锁案例一" class="headerlink" title="死锁案例一"></a>死锁案例一</h2><p>pt-osc改表操作与业务insert语句形成死锁，业务insert操作回滚。</p><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><p>MySQL5.7.26、RC隔离级别、innodb_autoinc_lock_mode=1</p><p>表结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;自增主键&apos;,</span><br><span class="line">  `c1` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;c1&apos;,</span><br><span class="line">  `c2` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;c2&apos;</span><br><span class="line">  `c3` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;c3&apos;</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB  DEFAULT CHARSET=utf8mb4 COMMENT=&apos;&apos;;</span><br></pre></td></tr></table></figure></p><h3 id="死锁日志"><a href="#死锁日志" class="headerlink" title="死锁日志"></a>死锁日志</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">2020-04-26T06:24:05.340343+08:00 733947 [Note] InnoDB: Transactions deadlock detected, dumping detailed information.</span><br><span class="line">2020-04-26T06:24:05.341246+08:00 733947 [Note] InnoDB: </span><br><span class="line">*** (1) TRANSACTION:</span><br><span class="line"></span><br><span class="line">TRANSACTION 918773485, ACTIVE 0 sec setting auto-inc lock</span><br><span class="line">mysql tables in use 2, locked 2</span><br><span class="line">LOCK WAIT 4 lock struct(s), heap size 1136, 1 row lock(s), undo log entries 2</span><br><span class="line">MySQL thread id 668554, OS thread handle 139777592952576, query id 2675769996 192.168.1.1 test_user update</span><br><span class="line">REPLACE INTO `test_db`.`_t_new` (`id`, `c1`, `c2`, `c3`) VALUES (NEW.`id`, NEW.`c1`, NEW.`c2`, NEW.`c3`)</span><br><span class="line">2020-04-26T06:24:05.341319+08:00 733947 [Note] InnoDB: *** (1) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line"></span><br><span class="line">TABLE LOCK table `test_db`.`_t_new` trx id 918773485 lock mode AUTO-INC waiting</span><br><span class="line"></span><br><span class="line">2020-04-26T06:24:05.341351+08:00 733947 [Note] InnoDB: *** (2) TRANSACTION:</span><br><span class="line"></span><br><span class="line">TRANSACTION 918773482, ACTIVE 1 sec fetching rows</span><br><span class="line">mysql tables in use 2, locked 2</span><br><span class="line">120 lock struct(s), heap size 24784, 8894 row lock(s), undo log entries 8099</span><br><span class="line">MySQL thread id 733947, OS thread handle 139777597007616, query id 2675769985 localhost root Sending data</span><br><span class="line">INSERT LOW_PRIORITY IGNORE INTO `test_db`.`_t_new` (`id`, `c1`, `c2`, `c3`) SELECT `id`, `c1`, `c2`, `c3` FROM </span><br><span class="line">`test_db`.`t` FORCE INDEX(`PRIMARY`) WHERE ((`id` &gt;= &apos;95439963&apos;)) AND ((`id` &lt;= &apos;95448404&apos;)) LOCK IN SHARE MODE </span><br><span class="line">2020-04-26T06:24:05.341398+08:00 733947 [Note] InnoDB: *** (2) HOLDS THE LOCK(S):</span><br><span class="line"></span><br><span class="line">TABLE LOCK table `test_db`.`_t_new` trx id 918773482 lock mode AUTO-INC</span><br><span class="line">2020-04-26T06:24:05.341415+08:00 733947 [Note] InnoDB: *** (2) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line"></span><br><span class="line">RECORD LOCKS space id 974 page no 145414 n bits 80 index PRIMARY of table `test_db`.`t` trx id 918773482 lock mode S locks rec but not gap waiting</span><br><span class="line">Record lock, heap no 9 PHYSICAL RECORD: n_fields 27; compact format; info bits 0</span><br><span class="line">0: len 4; hex 85b06d55; asc   mU;; --&apos;5b06d55&apos;从16进制转换为10进制,得到的值为 95448405</span><br><span class="line"></span><br><span class="line">1: len 4; hex 80002712; asc    ;;</span><br><span class="line">2: len 4; hex 800c24d7; asc   $ ;;</span><br><span class="line">3: len 4; hex 80000003; asc     ;;</span><br><span class="line"></span><br><span class="line">2020-04-26T06:24:05.342491+08:00 733947 [Note] InnoDB: *** WE ROLL BACK TRANSACTION (1)</span><br></pre></td></tr></table></figure><h3 id="死锁分析"><a href="#死锁分析" class="headerlink" title="死锁分析"></a>死锁分析</h3><p>事务：918773482<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">当前的SQL语句: </span><br><span class="line">    INSERT LOW_PRIORITY IGNORE INTO `test_db`.`_t_new` (`id`, `c1`, `c2`, `c3`) SELECT `id`, `c1`, `c2`, `c3` FROM </span><br><span class="line">    `test_db`.`t` FORCE INDEX(`PRIMARY`) WHERE ((`id` &gt;= &apos;95439963&apos;)) AND ((`id` &lt;= &apos;95448404&apos;)) LOCK IN SHARE MODE; </span><br><span class="line"></span><br><span class="line">持有的锁信息：</span><br><span class="line">    TABLE LOCK table `test_db`.`_t_new` ... lock mode AUTO-INC --表示持有表_t_new上的自增长锁;</span><br><span class="line"></span><br><span class="line">在等待的锁信息:</span><br><span class="line">     index PRIMARY of table `test_db`.`t` --表示在等的是表t的主键索引上面的锁;</span><br><span class="line">     lock_mode S locks rec but not gap waiting --表示需要加一个共享锁(读锁)，当前的状态是等待中;</span><br><span class="line">     0: len 4; hex 85b06d55; asc   mU;;   --主键字段, 5b06d55的16进制为转换为10进制得到值为: 95448405;   </span><br><span class="line"></span><br><span class="line">通过分析得知：</span><br><span class="line">    TRANSACTION 918773482持有的锁: 表_t_new的自增长锁; </span><br><span class="line">    TRANSACTION 918773482在等待TRANSACTION 918773485的锁: 表t的主键索引primary: record lock: id=95448405。</span><br></pre></td></tr></table></figure></p><p>事务：918773485<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">当前的SQL语句: </span><br><span class="line">    REPLACE INTO `test_db`.`_t_new` (`id`, `c1`, `c2`, `c3`) VALUES (NEW.`id`, NEW.`c1`, NEW.`c2`, NEW.`c3`);</span><br><span class="line"></span><br><span class="line">持有的锁信息:</span><br><span class="line">    根据TRANSACTION 918773482在等待TRANSACTION 918773485的锁为 primary: record lock: id=95448405 的行锁，所以推导出TRANSACTION 918773485持有表t主键索引 id=95448405 的行锁;</span><br><span class="line"></span><br><span class="line">在等待的锁信息:</span><br><span class="line">    TABLE LOCK table `test_db`.`_t_new` ... lock mode AUTO-INC waiting --表示在等表_t_new上的自增长锁;</span><br><span class="line"></span><br><span class="line">通过分析得知：    </span><br><span class="line">    TRANSACTION 918773485持有的锁：持有表t主键索引primary id=95448405 的行锁；</span><br><span class="line">    TRANSACTION 918773485在等待TRANSACTION 918773482的锁: 表_t_new上的自增长锁。</span><br></pre></td></tr></table></figure></p><table><thead><tr><th style="text-align:center">时间点</th><th style="text-align:center">918773482<br>pt-osc改表批量导入语句</th><th style="text-align:center">918773485918773485<br>业务正常插入操作</th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">begin</td><td style="text-align:center">begin</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">INSERT LOW_PRIORITY IGNORE INTO _t_new (id, c1, c2, c3) SELECT id, c1, c2, c3 FROM test_db.t FORCE INDEX(PRIMARY) WHERE ((id &gt;= ‘95439963’)) AND ((id &lt;= ‘95448404’)) LOCK IN SHARE MODE;</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">T1</td><td style="text-align:center">持有的锁: 表_t_new: AUTO-INC</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">T2</td><td style="text-align:center"></td><td style="text-align:center">INSERT INTO t (c1, c2, c3) VALUES (0, 0, 0);<br>持有表t主键索引 id=95448405 的行锁(排他X锁)</td></tr><tr><td style="text-align:center">T3</td><td style="text-align:center"></td><td style="text-align:center">REPLACE INTO _t_new (id, c1, c2, c3) VALUES (NEW.id, NEW.c1, NEW.c2, NEW.c3);<br>等待的锁: 表_t_new: AUTO-INC</td></tr><tr><td style="text-align:center">T4</td><td style="text-align:center">等待的锁: 表t: primary: record lock: id=95448405</td></tr></tbody></table><p>T3被T1阻塞，T4被T2阻塞，因此锁资源请求形成了环路，进而触发死锁检测，MySQL会把执行代价最小的事务回滚掉，让其它事务得以继续进行;</p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><ol><li>为什么pt-osc会去申请原表t的主键锁呢？<br>因为 id &lt;= 95448404 是范围等值查询并且id=95448404是当前主键索引的最大值 ， 锁的过程实际上是id&lt;=95448404的下一条记录也就是这个索引页的最大记录supremum（如果这个在RC隔离级别下没有被锁，则会立即释放），需要访问到 id=95448405 才会停止下来，所以需要申请 持有 id=95448405 的行锁 ，因此被 T2时刻 的SQL语句阻塞。</li></ol><p>TRANSACTION 918773482的事务语句是pt-osc拷贝的最后一个chunk-size，并且期间其它事务有对原表做insert操作， 所以才会发生死锁。</p><h2 id="死锁案例二"><a href="#死锁案例二" class="headerlink" title="死锁案例二"></a>死锁案例二</h2><p>pt-osc改表操作与业务update语句形成死锁，业务update操作回滚。</p><h3 id="环境-1"><a href="#环境-1" class="headerlink" title="环境"></a>环境</h3><p>阿里云MySQL5.6、RC隔离级别</p><p>表结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;自增主键&apos;,</span><br><span class="line">  `c1` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;c1&apos;,</span><br><span class="line">  `c2` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;c2&apos;</span><br><span class="line">  `c3` int(11) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;c3&apos;</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `idx_c1_c2(`c1`,`c2`)</span><br><span class="line">) ENGINE=InnoDB  DEFAULT CHARSET=utf8mb4 COMMENT=&apos;&apos;;</span><br></pre></td></tr></table></figure></p><h3 id="死锁日志-1"><a href="#死锁日志-1" class="headerlink" title="死锁日志"></a>死锁日志</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">2020-05-11 15:04:22 7f728ebff700</span><br><span class="line">*** (1) TRANSACTION:</span><br><span class="line">TRANSACTION 582527418, ACTIVE 0.002 sec setting auto-inc lock</span><br><span class="line">mysql tables in use 2, locked 2</span><br><span class="line">LOCK WAIT 4 lock struct(s), heap size 1184, 1 row lock(s), undo log entries 2</span><br><span class="line">LOCK BLOCKING MySQL thread id: 34439719 block 17762714</span><br><span class="line">MySQL thread id 17762714, OS thread handle 0x7f728eaba700, query id 323487893 192.168.55.8 test update</span><br><span class="line">REPLACE INTO `test`.`_t_new` (`id`, `c1`, `c2`, `c3`) VALUES (NEW.`id`, NEW.`c1`, NEW.`c2`, NEW.`c3`, NEW.`c4`)</span><br><span class="line">*** (1) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line">TABLE LOCK table `test`.`_t_new` trx id 582527418 lock mode AUTO-INC waiting</span><br><span class="line">*** (2) TRANSACTION:</span><br><span class="line">TRANSACTION 582527416, ACTIVE 0.012 sec inserting</span><br><span class="line">mysql tables in use 2, locked 2</span><br><span class="line">9 lock struct(s), heap size 1184, 6 row lock(s), undo log entries 3</span><br><span class="line">MySQL thread id 34439719, OS thread handle 0x7f728ebff700, query id 323487888 192.168.58.10 test update</span><br><span class="line">REPLACE INTO `test`.`_t_new` (`id`, `c1`, `c2`, `c3`) VALUES (NEW.`id`, NEW.`c1`, NEW.`c2`, NEW.`c3`)</span><br><span class="line">*** (2) HOLDS THE LOCK(S):</span><br><span class="line">TABLE LOCK table `test`.`_t_new` trx id 582527416 lock mode AUTO-INC</span><br><span class="line">*** (2) WAITING FOR THIS LOCK TO BE GRANTED:</span><br><span class="line">RECORD LOCKS space id 51 page no 467072 n bits 224 index `idx_c1_c2` of table `test`.`_t_new` trx id 582527416 lock_mode X waiting</span><br><span class="line">Record lock, heap no 154 PHYSICAL RECORD: n_fields 4; compact format; info bits 0</span><br><span class="line"> 0: len 8; hex 000000000f97b07e; asc        ~;;</span><br><span class="line"> 1: len 1; hex 08; asc  ;;</span><br><span class="line"> 2: len 1; hex 00; asc  ;;</span><br><span class="line"> 3: len 8; hex 0000000005f1acf1; asc         ;;</span><br><span class="line"></span><br><span class="line">*** WE ROLL BACK TRANSACTION (1)</span><br></pre></td></tr></table></figure><h3 id="死锁分析-1"><a href="#死锁分析-1" class="headerlink" title="死锁分析"></a>死锁分析</h3><p>事务：582527416<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">原业务语句：</span><br><span class="line">UPDATE t SET c3 = &apos;xx&apos; WHERE c1 = &apos;xx&apos; AND c2 = &apos;xx&apos; LIMIT 1</span><br><span class="line"></span><br><span class="line">经过触发器改写后语句：</span><br><span class="line">begin</span><br><span class="line">UPDATE t SET c3 = &apos;xx&apos; WHERE c1 = &apos;xx&apos; AND c2 = &apos;xx&apos; LIMIT 1</span><br><span class="line">DELETE IGNORE FROM `test`.`_t_new` WHERE !(OLD.`id` &lt;=&gt; NEW.`id`) AND `test`.`_t_new`.`id` &lt;=&gt; OLD.`id`</span><br><span class="line">REPLACE INTO `test`.`_t_new` (`id`, `c1`, `c2`, `c3`) VALUES (NEW.`id`, NEW.`c1`, NEW.`c2`, NEW.`c3`); </span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">锁分析：</span><br><span class="line">当前持有  lock mode AUTO-INC 锁（表级别）</span><br><span class="line">由于存在唯一索引，所以在插入的时候会进行唯一性检测，此时需要获取 next-key lock</span><br></pre></td></tr></table></figure></p><p>事务：TRANSACTION 582527418<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">原业务语句：</span><br><span class="line">UPDATE t SET c3 = &apos;xx&apos; WHERE c1 = &apos;xx&apos; AND c2 = &apos;xx&apos; LIMIT 1</span><br><span class="line"></span><br><span class="line">经过触发器改写后语句：</span><br><span class="line">begin</span><br><span class="line">UPDATE t SET c3 = &apos;xx&apos; WHERE c1 = &apos;xx&apos; AND c2 = &apos;xx&apos; LIMIT 1</span><br><span class="line">DELETE IGNORE FROM `test`.`_t_new` WHERE !(OLD.`id` &lt;=&gt; NEW.`id`) AND `test`.`_t_new`.`id` &lt;=&gt; OLD.`id`</span><br><span class="line">REPLACE INTO `test`.`_t_new` (`id`, `c1`, `c2`, `c3`) VALUES (NEW.`id`, NEW.`c1`, NEW.`c2`, NEW.`c3`); </span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">锁分析：</span><br><span class="line">持有记录的x锁和插入意向锁 等待_t_new表级别的auto-inc 锁</span><br></pre></td></tr></table></figure></p><table><thead><tr><th style="text-align:center">时间点</th><th style="text-align:center">sesson 1<br>582527416</th><th style="text-align:center">session 2<br>582527418</th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">begin</td><td style="text-align:center">begin</td></tr><tr><td style="text-align:center">T1</td><td style="text-align:center">REPLACE INTO <code>test</code>.<code>_t_new</code> (<code>id</code>, <code>c1</code>, <code>c2</code>, <code>c3</code>) VALUES (NEW.<code>id</code>, NEW.<code>c1</code>, NEW.<code>c2</code>, NEW.<code>c3</code>); <br>插入前检查，唯一键上的插入意向锁</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">T2</td><td style="text-align:center"></td><td style="text-align:center">REPLACE INTO <code>test</code>.<code>_t_new</code> (<code>id</code>, <code>c1</code>, <code>c2</code>, <code>c3</code>) VALUES (NEW.<code>id</code>, NEW.<code>c1</code>, NEW.<code>c2</code>, NEW.<code>c3</code>);<br>插入前检查，唯一键上的插入意向锁</td></tr><tr><td style="text-align:center">T3</td><td style="text-align:center">执行插入，拥有_t_new的auto-inc锁，等待唯一键插入意向锁释放</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">T4</td><td style="text-align:center"></td><td style="text-align:center">执行插入，等待_t_new的auto-inc锁</td></tr></tbody></table><h3 id="思考-1"><a href="#思考-1" class="headerlink" title="思考"></a>思考</h3><ol><li>为什么平时业务同样的update，但是只有在改表时才会触发死锁呢？<br>因为改表过程中，是增量将数据导入，此时还未导入到update所操作的id上。业务update执行时，触发器转换后的语句在执行时，会申请_t_new表的最大值之间的auto-inc锁。当业务并发大时可能就会造成业务update语句之间的死锁情况。</li></ol><h2 id="如何避免"><a href="#如何避免" class="headerlink" title="如何避免"></a>如何避免</h2><ol><li>设置pt-osc的chunk-size为更小的值，可以减少死锁的发生，但是不可能避免死锁的发生。</li><li>如果参数innodb_autoinc_lock_mode的值为2，大大降低死锁发生的概率，原因如下：<br>造成本案例死锁的原因之一就是在参数innodb_autoinc_lock_mode=1的环境下，持有的自增锁直到SQL语句结束后才释放；<br>如果参数innodb_autoinc_lock_mode=2，自增锁在申请后就释放，不需要等语句结束，大大缩短了持有自增锁的时间，从而降低了死锁发生的概率。</li><li>数据库版本为MySQL 8.0.18或者以上， 事务隔离为RR可重复读则不会出现本案例的死锁，原因如下：<br>8.0.18或者以上的版本中，对加锁规则有一个优化：在RR可重复读级别下，唯一索引上的范围查询，不再需要访问到不满足条件的第一个值为止（即不再需要对不必要的数据上锁）。在叶老师的这篇文章中有说明：<a href="https://mp.weixin.qq.com/s/xDKKuIvVgFNiKp5kt2NIgA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/xDKKuIvVgFNiKp5kt2NIgA</a> InnoDB这个将近20年的”bug”修复了；</li></ol><blockquote><p><a href="https://mp.weixin.qq.com/s/mJ6a-sV2C2ru5pA5QNAAZQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/mJ6a-sV2C2ru5pA5QNAAZQ</a><br><a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/8.0/en/innodb-locks-set.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;今天看到叶老师公众号推送文章《&lt;a href=&quot;!https://mp.weixin.qq.com/s/mJ6a-sV2C2ru5pA5QNAAZQ&quot;&gt;pt-osc在线重建表导致死锁的分析及对应的优化方案&lt;/a&gt;》，让我想起了前段时间同样遇到了pt-osc改表导致的死锁。故此记录一下。&lt;/p&gt;
&lt;h2 id=&quot;pt-osc&quot;&gt;&lt;a href=&quot;#pt-osc&quot; class=&quot;headerlink&quot; title=&quot;pt-osc&quot;&gt;&lt;/a&gt;pt-osc&lt;/h2&gt;&lt;p&gt;pt-online-schema-change：PERCONA提供的在线改表工具，避免MySQL在执行改表操作时造成的锁表和主从延迟情况发生。&lt;/p&gt;
&lt;h3 id=&quot;工作原理&quot;&gt;&lt;a href=&quot;#工作原理&quot; class=&quot;headerlink&quot; title=&quot;工作原理&quot;&gt;&lt;/a&gt;工作原理&lt;/h3&gt;&lt;p&gt;1、创建一个跟原表表结构一样的新表。取名为&lt;code&gt;_oldTableNmae_new&lt;/code&gt;&lt;br&gt;2、修改新表结构&lt;br&gt;3、在原表中创建insert、update、delete三个类型的触发器，用于做增量数据迁移。原表SQL和触发器触发SQL在同一事务当中。&lt;br&gt;4、以一定块大小(chunk-size)从原表拷贝数据到新表&lt;br&gt;5、数据拷贝完后，修改表名：&lt;code&gt;rename table to table_old; rename _table_new to table&lt;/code&gt;&lt;br&gt;6、删除old表，删除三个触发器&lt;/p&gt;
&lt;h3 id=&quot;版本变化&quot;&gt;&lt;a href=&quot;#版本变化&quot; class=&quot;headerlink&quot; title=&quot;版本变化&quot;&gt;&lt;/a&gt;版本变化&lt;/h3&gt;&lt;p&gt;3.0.2之前的update触发器：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;REPLACE INTO `lc`.`_hb_new` (`id`, `ts`, `ts2`, `c1`) VALUES (NEW.`id`, NEW.`ts`, NEW.`ts2`, NEW.`c1`)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;3.0.2之后的update触发器:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;BEGIN&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    DELETE IGNORE FROM `lc`.`_hb_new` WHERE !(OLD.`id` &amp;lt;=&amp;gt; NEW.`id`) AND `lc`.`_hb_new`.`id` &amp;lt;=&amp;gt; OLD.`id`;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    REPLACE INTO `lc`.`_hb_new` (`id`, `ts`, `ts2`) VALUES (NEW.`id`, NEW.`ts`, NEW.`ts2`);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;END&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="PT" scheme="http://yoursite.com/tags/PT/"/>
    
  </entry>
  
  <entry>
    <title>MySQL机制之index merge</title>
    <link href="http://yoursite.com/2020/05/31/new/MySQL/MySQL%E6%9C%BA%E5%88%B6%E4%B9%8Bindex-merge/"/>
    <id>http://yoursite.com/2020/05/31/new/MySQL/MySQL机制之index-merge/</id>
    <published>2020-05-31T14:50:20.000Z</published>
    <updated>2020-05-31T14:54:57.098Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>查询时where后面可能会涉及到多个字段，它们之间进行AND或OR。在MySQL 5.0之前，一个表一次只能使用一个索引，无法同时使用多个索引分别进行条件扫描。从5.1开始引入了<code>index merge</code>技术。<br><code>index merge</code>技术就是<font color="red">对多个索引分别进行条件扫描，然后将他们各自的结果进行合并</font></p><p>该特性主要会体现在以下场景：</p><ol><li>对OR语句求并集</li><li>对AND语句求交集</li><li>对AND和OR组合语句求结果</li></ol><p>在满足index merge条件下的查询计划中会出现<code>type:index_merge</code>。</p><h2 id="AND取交集-union"><a href="#AND取交集-union" class="headerlink" title="AND取交集(union)"></a>AND取交集(union)</h2><p>union就是多个索引条件扫描，对得到的结果进行并集运算，显然是多个条件之间进行的是 OR 运算。<br>案例：<code>SELECT * FROM tmp_index_merge where key1_part1 = 2 and key2_part1 = 4\G</code></p><h2 id="OR取并集-intersect"><a href="#OR取并集-intersect" class="headerlink" title="OR取并集(intersect)"></a>OR取并集(intersect)</h2><p>intersect就是多个索引条件扫描得到的结果进行交集运算。<br>案例：<code>SELECT * FROM tmp_index_merge where key1_part1 = 2 or key2_part1 = 4\G</code></p><h2 id="AND和OR组合取并集-sort-union"><a href="#AND和OR组合取并集-sort-union" class="headerlink" title="AND和OR组合取并集(sort_union)"></a>AND和OR组合取并集(sort_union)</h2><p>多个条件扫描进行 OR 运算，但是不符合 index union merge算法的，此时可能会使用 sort_union算法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM tbl_name WHERE key_col1 &lt; 10 OR key_col2 &lt; 20;</span><br><span class="line">SELECT * FROM tbl_name WHERE (key_col1 &gt; 10 OR key_col2 = 20) AND nonkey_col=30;</span><br></pre></td></tr></table></figure></p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>在MySQL5.6.7之前的版本中，存在<font color="red">range优先原则</font>。只要可以使用Range访问方式，那就不会再使用index merge。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>索引合并机制并不是什么新鲜东西，但是仍然存在很多人认为一条查询只能使用一个索引的观念。本篇文章只是简单的介绍MySQL存在这么一个机制，并未过深的研究。<br>简言之，索引合并会同时利用多个索引进行查询，尽可能得过滤掉不需要的数据行，然后再进行一次统一的回表行为。较少无谓的回表行为。</p><blockquote><p><a href="http://dev.mysql.com/doc/refman/5.6/en/index-merge-optimization.html" target="_blank" rel="noopener">http://dev.mysql.com/doc/refman/5.6/en/index-merge-optimization.html</a><br><a href="https://www.orczhou.com/index.php/2013/01/mysql-source-code-query-optimization-index-merge/" target="_blank" rel="noopener">https://www.orczhou.com/index.php/2013/01/mysql-source-code-query-optimization-index-merge/</a><br><a href="http://www.cnblogs.com/nocode/archive/2013/01/28/2880654.html" target="_blank" rel="noopener">http://www.cnblogs.com/nocode/archive/2013/01/28/2880654.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;查询时where后面可能会涉及到多个字段，它们之间进行AND或OR。在MySQL 5.0之前，一个表一次只能使用一个索引，无法同时使用多个索
      
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL机制" scheme="http://yoursite.com/tags/MySQL%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>MySQL机制介绍之NLJ、BNL、BKA</title>
    <link href="http://yoursite.com/2020/05/30/new/MySQL/MySQL%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D%E4%B9%8BNLJ%E3%80%81BNL%E3%80%81BKA/"/>
    <id>http://yoursite.com/2020/05/30/new/MySQL/MySQL机制介绍之NLJ、BNL、BKA/</id>
    <published>2020-05-29T17:03:51.000Z</published>
    <updated>2020-05-29T17:05:25.376Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>MySQL 5.5版本前，MySQL本身只支持一种表间关联方式，就是嵌套循环(Nested Loop)。如果关联表的数据量很大，则join关联的执行时间会非常长。<br>在5.5版本中，MySQL通过引入Block Nested-Loop Join(BNL)算法来优化嵌套执行。</p><h2 id="NLJ"><a href="#NLJ" class="headerlink" title="NLJ"></a>NLJ</h2><p>将驱动表的结果集作为循环基础数据，然后循环从该结果集中每次一条获取数据作为下一个表的过滤条件查询数据，然后合并结果。<br>如果有多表join，则将前面的表的结果集作为循环数据，取到每行再到链接的下一个表循环匹配。</p><h3 id="SNLJ"><a href="#SNLJ" class="headerlink" title="SNLJ"></a>SNLJ</h3><p>Simple Nested-Loops Join(SNLJ，简单嵌套循环联接)，该算法比较简单、直接。驱动表中的每一条记录都与被驱动表中的记录进行匹配判断。对于两表连接，驱动表只需要被访问一次，而被驱动表需要访问多次。这个算法的开销非常大，复杂度为笛卡尔积。<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9s7d0psuj307406mmxc.jpg" alt=""><br>其实现伪代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">For each row r in R do                         -- 扫描R表（驱动表）</span><br><span class="line">    For each row s in S do                     -- 扫描S表（被驱动表）</span><br><span class="line">        If r and s satisfy the join condition  -- 如果r和s满足join条件</span><br><span class="line">            Then output the tuple &lt;r, s&gt;       -- 返回结果集</span><br></pre></td></tr></table></figure></p><a id="more"></a><h3 id="INLJ"><a href="#INLJ" class="headerlink" title="INLJ"></a>INLJ</h3><p>Index Nested-Loops Join(INLJ，基于索引的嵌套循环联接)，由于SNLJ算法非常粗暴，每次都会扫描全表。所以一般会在被驱动表的相关字段上建立索引，以降低SNLJ的复杂度，这种算法就被称为INLJ。<br>外表中的每条记录通过内表的索引进行访问，就是读取外部表一行数据，然后去内部表索引进行二分查找匹配；而一般B+树的高度为3~4层，也就是说匹配一次的io消耗也就3~4次，因此索引查询的成本是比较固定的，故优化器都倾向于使用记录数少的表作为外表。<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9sg65i6yj309n0a33z0.jpg" alt=""><br>其实现为代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">For each row r in R do                     -- 扫描R表</span><br><span class="line">    lookup s in S index                    -- 查询S表的索引（固定3~4次IO，B+树高度）</span><br><span class="line">        If find s == r                     -- 如果r匹配了索引s</span><br><span class="line">            Then output the tuple &lt;r, s&gt;   -- 返回结果集</span><br></pre></td></tr></table></figure></p><h2 id="BNL"><a href="#BNL" class="headerlink" title="BNL"></a>BNL</h2><p>在SNLJ中，被驱动表需要进行全表扫描多次，由于MySQL的内存有限，所以可能会导致被驱动表中的数据页频繁的被读进内存又刷到磁盘中。<br>能不能有一个办法避免这样的情况发生呢？于是便加入了<code>join buffer</code>的概念。一次性判断多条记录，从而减少全表扫描的次数。<br>这种方式被称为BNL，BNL将外层循环的行/结果集存入到join buffer，然后每次遍历被驱动表都与join buffer中的数据进行比较。以此来减少全表扫描的次数。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9smi9vqzj30a70873z3.jpg" alt=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">For each tuple r in R do                             -- 扫描外表R</span><br><span class="line">    store used columns as p from R in Join Buffer    -- 将部分或者全部R的记录保存到Join Buffer中，记为p</span><br><span class="line">    For each tuple s in S do                         -- 扫描内表S</span><br><span class="line">        If p and s satisfy the join condition        -- p与s满足join条件</span><br><span class="line">            Then output the tuple                    -- 返回为结果集</span><br></pre></td></tr></table></figure></p><p>开启BNL的方式：<code>set optimizer_switch=&#39;block_nested_loop=on&#39;</code></p><h3 id="join-buffer"><a href="#join-buffer" class="headerlink" title="join buffer"></a>join buffer</h3><p>在MySQL实例中存在多种join查询的语句时，可通过调整join buffer的大小来减少磁盘访问。<br>但是由于join buffer是会话级别的，所以并不能设置太大，避免出现内存问题。</p><ul><li>系统变量Join_buffer_size决定了Join Buffer的大小。</li><li>Join Buffer可被用于联接是ALL、index、和range的类型。</li><li>每次联接使用一个Join Buffer，因此多表的联接可以使用多个Join Buffer。</li><li>Join Buffer在联接发生之前进行分配，在SQL语句执行完后进行释放。</li><li>Join Buffer只存储要进行查询操作的相关列数据，而不是整行的记录。</li></ul><h2 id="BKA"><a href="#BKA" class="headerlink" title="BKA"></a>BKA</h2><p>Batched Key Access Join(BKA，批量键访问联接)，MySQL在5.6版本中引入了BKA算法来对INLJ算法进行优化。<br>BKA其实就等价于MRR+INLJ。关于MRR的介绍可以参考<a href="https://omg-by.github.io/2020/05/27/new/MySQL/MySQL%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D%E4%B9%8BMRR/" target="_blank" rel="noopener">MySQL机制介绍之MRR</a></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9t27j1bhj30ki09p75j.jpg" alt=""><br>BKA主要工作流程为：</p><ol><li>将外部表中相关的列放入Join Buffer中。</li><li>批量的将Key（索引键值）发送到Multi-Range Read（MRR）接口。</li><li>Multi-Range Read（MRR）通过收到的Key，根据其对应的ROWID进行排序，然后再进行数据的读取操作。</li><li>返回结果集给客户端。</li></ol><p>开启BKA方式：<code>SET optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;</code> </p><h2 id="CHJ"><a href="#CHJ" class="headerlink" title="CHJ"></a>CHJ</h2><p>// TODO studing</p><blockquote><p><a href="https://yq.aliyun.com/articles/27687" target="_blank" rel="noopener">https://yq.aliyun.com/articles/27687</a><br><a href="https://www.cnblogs.com/zuochanzi/p/10409752.html" target="_blank" rel="noopener">https://www.cnblogs.com/zuochanzi/p/10409752.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;MySQL 5.5版本前，MySQL本身只支持一种表间关联方式，就是嵌套循环(Nested Loop)。如果关联表的数据量很大，则join关联的执行时间会非常长。&lt;br&gt;在5.5版本中，MySQL通过引入Block Nested-Loop Join(BNL)算法来优化嵌套执行。&lt;/p&gt;
&lt;h2 id=&quot;NLJ&quot;&gt;&lt;a href=&quot;#NLJ&quot; class=&quot;headerlink&quot; title=&quot;NLJ&quot;&gt;&lt;/a&gt;NLJ&lt;/h2&gt;&lt;p&gt;将驱动表的结果集作为循环基础数据，然后循环从该结果集中每次一条获取数据作为下一个表的过滤条件查询数据，然后合并结果。&lt;br&gt;如果有多表join，则将前面的表的结果集作为循环数据，取到每行再到链接的下一个表循环匹配。&lt;/p&gt;
&lt;h3 id=&quot;SNLJ&quot;&gt;&lt;a href=&quot;#SNLJ&quot; class=&quot;headerlink&quot; title=&quot;SNLJ&quot;&gt;&lt;/a&gt;SNLJ&lt;/h3&gt;&lt;p&gt;Simple Nested-Loops Join(SNLJ，简单嵌套循环联接)，该算法比较简单、直接。驱动表中的每一条记录都与被驱动表中的记录进行匹配判断。对于两表连接，驱动表只需要被访问一次，而被驱动表需要访问多次。这个算法的开销非常大，复杂度为笛卡尔积。&lt;br&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9s7d0psuj307406mmxc.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;其实现伪代码如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;For each row r in R do                         -- 扫描R表（驱动表）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    For each row s in S do                     -- 扫描S表（被驱动表）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        If r and s satisfy the join condition  -- 如果r和s满足join条件&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            Then output the tuple &amp;lt;r, s&amp;gt;       -- 返回结果集&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL机制" scheme="http://yoursite.com/tags/MySQL%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>MySQL机制介绍之ICP</title>
    <link href="http://yoursite.com/2020/05/28/new/MySQL/MySQL%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D%E4%B9%8BICP/"/>
    <id>http://yoursite.com/2020/05/28/new/MySQL/MySQL机制介绍之ICP/</id>
    <published>2020-05-28T05:22:48.000Z</published>
    <updated>2020-05-29T00:45:48.291Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ICP是什么"><a href="#ICP是什么" class="headerlink" title="ICP是什么"></a>ICP是什么</h2><p>Index Condition Pushdown，也称为索引条件下推，体现在执行计划中会出现<code>Using index condition</code>。<br>ICP优化适用于MySQL利用索引从表里检索数据的场景。<br>使用命令<code>set optimizer_switch=&#39;index_condition_pushdown=on&#39;</code>开启</p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ul><li>索引访问方式是range/ref/eq_ref/ref_or_null，并且需要访问表的完整行记录</li><li>InnoDB和MYISAM表，包括分区的表(5.7)</li><li>对于InnoDB表，ICP只适用于二级索引。ICP的目标是减少访问表的完整行的读取量从而减少IO操作。</li><li>不支持建立在虚拟列上的二级索引</li><li>引用子查询、存储函数的条件没法下推</li><li>Triggered conditions 也没法下推</li></ul><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="不使用ICP"><a href="#不使用ICP" class="headerlink" title="不使用ICP"></a>不使用ICP</h3><ol><li>用二级索引查找数据的主键</li><li>用主键回表读取完整的行记录</li><li>引擎层利用where语句的条件对行记录进行过滤<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gf83cpvaofj30gw09bq3i.jpg" alt=""></li></ol><h3 id="使用ICP"><a href="#使用ICP" class="headerlink" title="使用ICP"></a>使用ICP</h3><ol><li>用二级索引查找数据的主键</li><li>如果where条件中的字段在复合索引中，引擎层对where条件里的字段进行过滤后，返回主键</li><li>利用主键回表读取完整的行记录</li><li>引擎层用where语句的剩余条件对行记录进行过滤<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gf83ct0w3xj30ge09b74t.jpg" alt=""></li></ol><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>ICP的优化在引擎层就能够过滤掉大量的数据，这样无疑能够减少了对base table和mysql server的访问次数，提升了性能。</p><blockquote><p><a href="https://dev.mysql.com/doc/refman/5.6/en/index-condition-pushdown-optimization.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.6/en/index-condition-pushdown-optimization.html</a><br><a href="https://yq.aliyun.com/articles/259696" target="_blank" rel="noopener">https://yq.aliyun.com/articles/259696</a><br><a href="https://zhuanlan.zhihu.com/p/73035620" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/73035620</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;ICP是什么&quot;&gt;&lt;a href=&quot;#ICP是什么&quot; class=&quot;headerlink&quot; title=&quot;ICP是什么&quot;&gt;&lt;/a&gt;ICP是什么&lt;/h2&gt;&lt;p&gt;Index Condition Pushdown，也称为索引条件下推，体现在执行计划中会出现&lt;code&gt;Us
      
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL机制" scheme="http://yoursite.com/tags/MySQL%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>MySQL机制介绍之MRR</title>
    <link href="http://yoursite.com/2020/05/27/new/MySQL/MySQL%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D%E4%B9%8BMRR/"/>
    <id>http://yoursite.com/2020/05/27/new/MySQL/MySQL机制介绍之MRR/</id>
    <published>2020-05-27T04:59:51.000Z</published>
    <updated>2020-05-29T00:45:31.813Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是MRR"><a href="#什么是MRR" class="headerlink" title="什么是MRR"></a>什么是MRR</h2><p>Multi-Range Read Optimization，是优化器将随机IO转换成顺序IO以降低查询过程中IO开销的一种手段。<br>它的好处有：</p><ul><li>使数据访问由随机变为顺序</li><li>减少缓冲池中页被替换的次数</li><li>批量处理查询操作</li></ul><p>可以通过<code>set optimizer_switch=&#39;mrr=on&#39;;</code>命令进行开启。</p><h3 id="不使用MRR"><a href="#不使用MRR" class="headerlink" title="不使用MRR"></a>不使用MRR</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set optimizer_switch=&apos;mrr=off&apos;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;  explain select * from test.t1 where (a between 1 and 10) and (c between 9 and 10) ;</span><br><span class="line">+----+-------------+-------+-------+---------------+------+---------+------+------+------------------------------------+</span><br><span class="line">| id | select_type | table | type  | possible_keys | key  | key_len | ref  | rows | Extra                              |</span><br><span class="line">+----+-------------+-------+-------+---------------+------+---------+------+------+------------------------------------+</span><br><span class="line">|  1 | SIMPLE      | t1    | range | mrrx,xx       | xx   | 5       | NULL |    2 | Using index condition; Using where |</span><br><span class="line">+----+-------------+-------+-------+---------------+------+---------+------+------+------------------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>在不使用MRR时，优化器需要根据二级索引返回的记录来进行回表，这个过程一般会有较多的随机IO操作。</p><h3 id="使用MRR"><a href="#使用MRR" class="headerlink" title="使用MRR"></a>使用MRR</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set optimizer_switch=&apos;mrr=on&apos;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;  explain select * from test.t1 where (a between 1 and 10) and (c between 9 and 10) ;</span><br><span class="line">+----+-------------+-------+-------+---------------+------+---------+------+------+-----------------------------------------------+</span><br><span class="line">| id | select_type | table | type  | possible_keys | key  | key_len | ref  | rows | Extra                                         |</span><br><span class="line">+----+-------------+-------+-------+---------------+------+---------+------+------+-----------------------------------------------+</span><br><span class="line">|  1 | SIMPLE      | t1    | range | mrrx,xx       | xx   | 5       | NULL |    2 | Using index condition; Using where; Using MRR |</span><br><span class="line">+----+-------------+-------+-------+---------------+------+---------+------+------+-----------------------------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>在使用了MRR时，SQL语句的执行过程为：</p><ol><li>优化器将二级索引查询到的记录放到一块缓冲区中(read_rnd_buffer_size)</li><li>如果二级索引扫描到文件末尾或者缓冲区已满，则使用快排对缓冲区中的内容按照主键进行排序</li><li>用户线程调用MRR接口获取cluster index，然后根据cluster index获取行数据</li><li>当缓冲区中的cluster index取完数据，则继续调用过程2、3，直到扫描结束</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>MRR特性就是在查询过程中，先将满足条件的id查询出来并进行排序后，再进行批量查询操作。从而实现随机IO到顺序IO的转换，提升性能。</p><blockquote><p><a href="https://dev.mysql.com/doc/refman/5.6/en/mrr-optimization.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.6/en/mrr-optimization.html</a><br><a href="https://zhuanlan.zhihu.com/p/110154066" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/110154066</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么是MRR&quot;&gt;&lt;a href=&quot;#什么是MRR&quot; class=&quot;headerlink&quot; title=&quot;什么是MRR&quot;&gt;&lt;/a&gt;什么是MRR&lt;/h2&gt;&lt;p&gt;Multi-Range Read Optimization，是优化器将随机IO转换成顺序IO以降低查询过程中
      
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL机制" scheme="http://yoursite.com/tags/MySQL%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>Redis扩展命令实现</title>
    <link href="http://yoursite.com/2020/05/17/new/Redis/Redis%E6%89%A9%E5%B1%95%E5%91%BD%E4%BB%A4%E5%AE%9E%E7%8E%B0/"/>
    <id>http://yoursite.com/2020/05/17/new/Redis/Redis扩展命令实现/</id>
    <published>2020-05-17T05:41:47.000Z</published>
    <updated>2020-05-17T06:06:30.394Z</updated>
    
    <content type="html"><![CDATA[<p>上周，参加公司后端部门开发的分享。<br>在期间，该开发吐槽Redis好几个使用不便利的地方。</p><ol><li><font color="red">Redis没有批量设置过期时间的命令</font></li><li><font color="red">incr 不存在的key的时候，并不会设置过期时间。导致持久化key的存在</font></li></ol><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gevcwyswasj30uk0l20wd.jpg" alt=""></p><a id="more"></a><p>作为客户端，解决办法只有使用lua脚本来进行实现：<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gevcuiy2fbj30zk09g0v0.jpg" alt=""></p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>虽然说使用lua脚本也能够解决这样的问题，但是对用户体验不太友好，同时也增加了编码的复杂度。<br>而且这样的功能实现起来并不算复杂，为什么不可以在Redis服务端去实现这样的功能呢？</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>说干咱就干。<br>利用周末的时间，简单的实现了其中的一个槽点功能:mexpire<br>可能会存在考虑欠缺的地方，但基本功能还是实现了的。</p><h3 id="expire-c"><a href="#expire-c" class="headerlink" title="expire.c"></a>expire.c</h3><p><code>expire.c</code>主要是对过期管理的文件。<br>一开始只想实现mexpire功能，结果发现还有<code>expireta</code>、<code>pexpire</code>、<code>pexpirate</code>命令跟<code>expire</code>命令相近，并且底层实现都是同一个函数。<br>于是就一起实现了。</p><p>逻辑其实很简单，就是遍历传过来的参数。</p><ul><li>如果key存在，就设置过期时间。并计数。</li><li>如果key不存在，就跳过。</li><li>返回成功设置过期时间个数。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">void mexpireGenericCommand(client *c, long long basetime, int unit)&#123;</span><br><span class="line"></span><br><span class="line">    if ((c-&gt;argc % 2) == 0)&#123;</span><br><span class="line">        addReplyErrorFormat(c, &quot;wrong number of arguments for %s&quot;, c-&gt;cmd-&gt;name);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int j;</span><br><span class="line">    robj *key, *param;</span><br><span class="line">    long long when;</span><br><span class="line">    int nums = 0;</span><br><span class="line">    for (j = 1; j &lt; c-&gt;argc; j+=2)&#123;</span><br><span class="line">        key = c-&gt;argv[j];</span><br><span class="line">        param = c-&gt;argv[j+1];</span><br><span class="line">        if ((getLongLongFromObject(param, &amp;when) != C_OK) || lookupKeyWrite(c-&gt;db,key) == NULL)&#123;</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (unit == UNIT_SECONDS) when *= 1000;</span><br><span class="line">        when += basetime;</span><br><span class="line"></span><br><span class="line">        nums++;</span><br><span class="line">        if (when &lt;= mstime() &amp;&amp; !server.loading &amp;&amp; !server.masterhost) &#123;</span><br><span class="line">            int deleted = server.lazyfree_lazy_expire ? dbAsyncDelete(c-&gt;db,key) :</span><br><span class="line">                          dbSyncDelete(c-&gt;db,key);</span><br><span class="line">            serverAssertWithInfo(c,key,deleted);</span><br><span class="line">            server.dirty++;</span><br><span class="line"></span><br><span class="line">            signalModifiedKey(c-&gt;db,key);</span><br><span class="line">            notifyKeyspaceEvent(NOTIFY_GENERIC,&quot;del&quot;,key,c-&gt;db-&gt;id);</span><br><span class="line"></span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            setExpire(c,c-&gt;db,key,when);</span><br><span class="line">            signalModifiedKey(c-&gt;db,key);</span><br><span class="line">            notifyKeyspaceEvent(NOTIFY_GENERIC,&quot;expire&quot;,key,c-&gt;db-&gt;id);</span><br><span class="line">            server.dirty++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    addReplyLongLong(c, nums);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void mexpireCommand(client *c)&#123;</span><br><span class="line">    mexpireGenericCommand(c, mstime(), UNIT_SECONDS);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void mexpireatCommand(client *c) &#123;</span><br><span class="line">    mexpireGenericCommand(c,0,UNIT_SECONDS);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void mpexpireCommand(client *c) &#123;</span><br><span class="line">    mexpireGenericCommand(c,mstime(),UNIT_MILLISECONDS);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void mpexpireatCommand(client *c) &#123;</span><br><span class="line">    mexpireGenericCommand(c,0,UNIT_MILLISECONDS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="server-h"><a href="#server-h" class="headerlink" title="server.h"></a>server.h</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void mexpireCommand(client *c);</span><br><span class="line">void mexpireatCommand(client *c);</span><br><span class="line">void mpexpireCommand(client *c);</span><br><span class="line">void mpexpireatCommand(client *c);</span><br></pre></td></tr></table></figure><h3 id="server-c"><a href="#server-c" class="headerlink" title="server.c"></a>server.c</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;mexpire&quot;,mexpireCommand,-3, &quot;write @keyspace&quot;,0,NULL,1,-1,2,0,0,0&#125;,</span><br><span class="line">&#123;&quot;mexpireat&quot;,mexpireatCommand,-3,&quot;write @keyspace&quot;, 0,NULL,1,-1,2,0,0,0&#125;,</span><br><span class="line">&#123;&quot;mpexpire&quot;,mpexpireCommand,-3, &quot;write @keyspace&quot;, 0,NULL,1,-1,2,0,0,0&#125;,</span><br><span class="line">&#123;&quot;mpexpireat&quot;,mpexpireatCommand,-3, &quot;write @keyspace&quot;, 0,NULL,1,-1,2,0,0,0&#125;,</span><br></pre></td></tr></table></figure><p>这里有必要说明一下上面配置的解释。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">struct redisCommand &#123;</span><br><span class="line">    char *name;</span><br><span class="line">    redisCommandProc *proc;</span><br><span class="line">    int arity;</span><br><span class="line">    char *sflags;   /* Flags as string representation, one char per flag. */</span><br><span class="line">    uint64_t flags; /* The actual flags, obtained from the &apos;sflags&apos; field. */</span><br><span class="line">    /* Use a function to determine keys arguments in a command line.</span><br><span class="line">     * Used for Redis Cluster redirect. */</span><br><span class="line">    redisGetKeysProc *getkeys_proc;</span><br><span class="line">    /* What keys should be loaded in background when calling this command? */</span><br><span class="line">    int firstkey; /* The first argument that&apos;s a key (0 = no keys) */</span><br><span class="line">    int lastkey;  /* The last argument that&apos;s a key */</span><br><span class="line">    int keystep;  /* The step between first and last key */</span><br><span class="line">    long long microseconds, calls;</span><br><span class="line">    int id;     /* Command ID. This is a progressive ID starting from 0 that</span><br><span class="line">                   is assigned at runtime, and is used in order to check</span><br><span class="line">                   ACLs. A connection is able to execute a given command if</span><br><span class="line">                   the user associated to the connection has this command</span><br><span class="line">                   bit set in the bitmap of allowed commands. */</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><ul><li>name：命令名称</li><li>function：指向函数</li><li>arity：参数限制</li><li>sflags：命令属性</li><li>flags：命令属性掩码，一般为0</li><li>get_keys_proc：在复杂参数下，指定那个才是真正的key。一般为NULL</li><li>first_key_index：第一个参数所在位置</li><li>last_key_index：最后一个参数所在位置</li><li>key_step：命令步长</li><li>microseconds：命令的度量项，由Redis来设置，并且总是初始化为0。</li><li>calls：命令的度量项，由Redis来设置，并且总是初始化为0。</li><li>id：命令的权限，由Redis来设置，并且总是初始化为0。</li></ul><p>只需要修改以上几个文件然后启动就可以了。是不是很简单？<br>PS：前一篇文章中解决哨兵BUG<a href="https://omg-by.github.io/2020/05/17/new/redis_BUG%E8%AE%B0%E5%BD%95%E4%B8%80%E5%88%99/" target="_blank" rel="noopener">《Redis哨兵client-reconfig-script脚本bug记录一则》</a>时，调试就需要重新进行make &amp;&amp; make install操作才行。</p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>命令使用，跟正常使用其他命令并没有什么太大区别。主要会跟<code>mset</code>命令使用比较相似。<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gevdm6iviij30la0e8gsd.jpg" alt=""></p><h2 id="issue"><a href="#issue" class="headerlink" title="issue"></a>issue</h2><p>本来还想去github提提issue的，结果发现早就有人跟作者提过这些问题了。我还是too yong to simple呀。<br>但是本着学习的心态，还是提了个issue，问问作者为什么不去实现这些简单又好用的命令。<a href="https://github.com/antirez/redis/issues/7263" target="_blank" rel="noopener">https://github.com/antirez/redis/issues/7263</a><br>后面有时间还是会继续实现其他命令的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上周，参加公司后端部门开发的分享。&lt;br&gt;在期间，该开发吐槽Redis好几个使用不便利的地方。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;font color=&quot;red&quot;&gt;Redis没有批量设置过期时间的命令&lt;/font&gt;&lt;/li&gt;
&lt;li&gt;&lt;font color=&quot;red&quot;&gt;incr 不存在的key的时候，并不会设置过期时间。导致持久化key的存在&lt;/font&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1gevcwyswasj30uk0l20wd.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>MySQL闪回工具调研</title>
    <link href="http://yoursite.com/2020/05/17/new/MySQL/MySQL%E9%97%AA%E5%9B%9E%E5%B7%A5%E5%85%B7/"/>
    <id>http://yoursite.com/2020/05/17/new/MySQL/MySQL闪回工具/</id>
    <published>2020-05-16T16:41:47.000Z</published>
    <updated>2020-05-28T05:24:36.246Z</updated>
    
    <content type="html"><![CDATA[<p>刚入职2个月左右的时候，就遇到了业务误操作，将对测试环境的delete操作，到线上执行了。。。(至于业务为什么有delete权限的账号，俺也不知道)<br>由于公司所有实例都部署在阿里云上，所以只能依赖于阿里云的备份恢复系统来进行数据恢复。但是非常慢，当时是大概花了20分钟才完全恢复（-_-||）。<br>于是乎~工作量又被增加了。领导让我调研数据闪回工具。。。</p><p>在工具调研测试过程中，发现了这几个工具存在部分BUG问题，所以给记录一下。避免再次踩坑。</p><h2 id="MyFlash"><a href="#MyFlash" class="headerlink" title="MyFlash"></a>MyFlash</h2><p>MyFlash是由美团点评公司技术工程部开发维护的一个回滚DML操作的工具。该工具通过解析v4版本的binlog，完成回滚操作。相对已有的回滚工具，其增加了更多的过滤选项，让回滚更加容易。</p><font color="red">通过解析binlog来生成回滚binlog文件。</font><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点：</p><ul><li>多种过滤条件，能够按照需求实现精准过滤</li><li>支持离线解析。不会对运行实例造成影响</li></ul><p>缺点：</p><ul><li>binlog格式必须为row，并且binlog_row_image=full。</li><li>只支持5.6和5.7</li><li>只支持DML，不支持DDL</li><li>MyFlash不能解析阿里云RDS的binlog</li></ul><a id="more"></a> <h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 下载源代码</span><br><span class="line">git clone https://github.com/Meituan-Dianping/MyFlash.git</span><br><span class="line"> </span><br><span class="line"># 编译</span><br><span class="line">cd MyFlash</span><br><span class="line">sh build.sh</span><br></pre></td></tr></table></figure><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 binary]# ./flashback --help</span><br><span class="line">Usage:</span><br><span class="line">flashback [OPTION...]</span><br><span class="line"> </span><br><span class="line">Help Options:</span><br><span class="line">-h, --help Show help options</span><br><span class="line"> </span><br><span class="line">Application Options:</span><br><span class="line">--databaseNames databaseName to apply. if multiple, seperate by comma(,) 库名，多个库之间用“，”分割</span><br><span class="line">--tableNames tableName to apply. if multiple, seperate by comma(,) 表名，多个表之间用“，”分割</span><br><span class="line">--start-position start position 开始的位点。如不指定，从文件的开始处回滚。</span><br><span class="line">--stop-position stop position 结束的位点。如不指定，回滚到文件结尾。</span><br><span class="line">--start-datetime start time (format %Y-%m-%d %H:%M:%S) 开始的时间点。如不指定，则不限定时间</span><br><span class="line">--stop-datetime stop time (format %Y-%m-%d %H:%M:%S) 结束的时间点。如不指定，则不限定时间</span><br><span class="line">--sqlTypes sql type to filter . support INSERT, UPDATE ,DELETE. if multiple, seperate by comma(,) 需要回滚的SQL类型，只支持INSERT, UPDATE,DELETE。多个类型之间以“，”分割</span><br><span class="line">--maxSplitSize max file size after split, the uint is M 生成文件分割大小。以M为单位</span><br><span class="line">--binlogFileNames binlog files to process. if multiple, seperate by comma(,) binlog文件名，支持多个文件</span><br><span class="line">--outBinlogFileNameBase output binlog file name base 输出文件名前缀。文件名后缀为：.flashback</span><br><span class="line">--logLevel log level, available option is debug,warning,error</span><br><span class="line">--include-gtids gtids to process 生成的语句包含gtid</span><br><span class="line">--exclude-gtids gtids to skip 跳过gtid</span><br></pre></td></tr></table></figure><h2 id="binlog2sql"><a href="#binlog2sql" class="headerlink" title="binlog2sql"></a>binlog2sql</h2><font color="red">通过模拟从库解析数据来生成回滚SQL。</font><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点：</p><ul><li>直接生成回滚语句，可读性较好。可根据需求进行选择性回滚</li><li>python实现，安装、使用、可扩展性较好</li><li>可指定位点、时间、语句类型</li><li>支持阿里云、自建实例</li></ul><p>缺点：</p><ul><li>需要连接数据库读取binlog，会对线上环境造成一定负载</li><li>依赖binlog。如果binlog被清理则无法生成回滚语句</li><li>不支持离线解析</li><li>解析速度较慢</li></ul><h3 id="安装使用"><a href="#安装使用" class="headerlink" title="安装使用"></a>安装使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; git clone https://github.com/danfengcao/binlog2sql.git &amp;&amp; cd binlog2sql</span><br><span class="line">shell&gt; pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line">用户授权</span><br><span class="line">GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO</span><br><span class="line"></span><br><span class="line">使用</span><br><span class="line">mysql连接配置</span><br><span class="line">-h host; -P port; -u user; -p password</span><br><span class="line"> </span><br><span class="line">解析模式</span><br><span class="line">--stop-never 持续解析binlog。可选。默认False，同步至执行命令时最新的binlog位置。</span><br><span class="line">-K, --no-primary-key 对INSERT语句去除主键。可选。默认False</span><br><span class="line">-B, --flashback 生成回滚SQL，可解析大文件，不受内存限制。可选。默认False。与stop-never或no-primary-key不能同时添加。</span><br><span class="line">--back-interval -B模式下，每打印一千行回滚SQL，加一句SLEEP多少秒，如不想加SLEEP，请设为0。可选。默认1.0。</span><br><span class="line"> </span><br><span class="line">解析范围控制</span><br><span class="line">--start-file 起始解析文件，只需文件名，无需全路径 。必须。</span><br><span class="line">--start-position/--start-pos 起始解析位置。可选。默认为start-file的起始位置。</span><br><span class="line">--stop-file/--end-file 终止解析文件。可选。默认为start-file同一个文件。若解析模式为stop-never，此选项失效。</span><br><span class="line">--stop-position/--end-pos 终止解析位置。可选。默认为stop-file的最末位置；若解析模式为stop-never，此选项失效。</span><br><span class="line">--start-datetime 起始解析时间，格式&apos;%Y-%m-%d %H:%M:%S&apos;。可选。默认不过滤。</span><br><span class="line">--stop-datetime 终止解析时间，格式&apos;%Y-%m-%d %H:%M:%S&apos;。可选。默认不过滤。</span><br><span class="line"> </span><br><span class="line">对象过滤</span><br><span class="line">-d, --databases 只解析目标db的sql，多个库用空格隔开，如-d db1 db2。可选。默认为空。</span><br><span class="line">-t, --tables 只解析目标table的sql，多张表用空格隔开，如-t tbl1 tbl2。可选。默认为空。</span><br><span class="line">--only-dml 只解析dml，忽略ddl。可选。默认False。</span><br><span class="line">--sql-type 只解析指定类型，支持INSERT, UPDATE, DELETE。多个类型用空格隔开，如--sql-type INSERT DELETE。可选。默认为增删改都解析。用了此参数但没填任何类型，则三者都不解析。</span><br></pre></td></tr></table></figure><h3 id="发现的问题"><a href="#发现的问题" class="headerlink" title="发现的问题"></a>发现的问题</h3><h4 id="datetime类型恢复错误"><a href="#datetime类型恢复错误" class="headerlink" title="datetime类型恢复错误"></a>datetime类型恢复错误</h4><p>问题描述：</p><ul><li>存在字段：<code>o_update_time</code> datetime NOT NULL COMMENT</li><li>存在值：o_update_time: 0000-00-00 00:00:00</li><li>问题一：删除后，binlog2sql生成的insert语句，会将该字段值给设置为NULL。导致插入报错失败。</li><li>问题二：阿里云恢复后，数据不一致。</li></ul><p>删除前数据：<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1geurdsmu57j312a0oytct.jpg" alt=""></p><p>binlog2sql生成语句：<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1geurdyxbu0j31u007uaeg.jpg" alt=""></p><h4 id="varbinary类型字段恢复错误"><a href="#varbinary类型字段恢复错误" class="headerlink" title="varbinary类型字段恢复错误"></a>varbinary类型字段恢复错误</h4><p>现数据库中存在经过加密函数加密后的字段。并存在几条数据。然后删除其中一条语句来测试工具生成回滚语句。<br><code>pwd</code> varbinary(255) NOT NULL COMMENT ‘密码’,<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1geurfbnj9fj30jr06c74x.jpg" alt=""></p><p>使用binlog2sql生成回滚语句时出错<br><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1geurfewn49j30ps03b0tc.jpg" alt=""></p><h4 id="精度问题"><a href="#精度问题" class="headerlink" title="精度问题"></a>精度问题</h4><p>在数据类型为decimal、double、float等精度类型时，恢复时会由于精度问题导致恢复数据不一致。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show create table huzb_deci\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: huzb_deci</span><br><span class="line">Create Table: CREATE TABLE `huzb_deci` (</span><br><span class="line">  `id` int(11) NOT NULL DEFAULT &apos;0&apos;,</span><br><span class="line">  `dec` decimal(5,2) DEFAULT NULL,</span><br><span class="line">  `flo` float DEFAULT NULL,</span><br><span class="line">  `dou` double DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><p>插入几条数据后，使用binlog2sql进行恢复。可以发现存在以下问题：</p><ol><li>double类型在插入时，由于精度问题，插入数据与原数据已经不一致。</li><li>float类型数据在使用binlog2sql生成恢复语句时，转换成了double类型，小数点后多了几位精度。</li><li>生成的回滚语句执行后，恢复的double类型数据不一致。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into huzb_deci values(1,1.1111111111111111111111111111111,2.22222222,3.333333333333333333333);</span><br><span class="line">Query OK, 1 row affected, 1 warning (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; show warnings;</span><br><span class="line">+-------+------+------------------------------------------+</span><br><span class="line">| Level | Code | Message                                  |</span><br><span class="line">+-------+------+------------------------------------------+</span><br><span class="line">| Note  | 1265 | Data truncated for column &apos;dec&apos; at row 1 |</span><br><span class="line">+-------+------+------------------------------------------+</span><br><span class="line">1 row in set (0.01 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; select * from huzb_deci;</span><br><span class="line">+----+------+---------+--------------------+</span><br><span class="line">| id | dec  | flo     | dou                |</span><br><span class="line">+----+------+---------+--------------------+</span><br><span class="line">|  1 | 1.11 | 2.22222 | 3.3333333333333335 |</span><br><span class="line">+----+------+---------+--------------------+</span><br><span class="line">1 row in set (0.01 sec)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"># 利用binlog2sql生成恢复语句并执行。</span><br><span class="line">mysql&gt; INSERT INTO `huzb`.`huzb_deci`(`id`, `dec`, `flo`, `dou`) VALUES (1, 1.11, 2.22222232818604, 3.33333333333333); #start 260805 end 260989 time 2019-10-30 19:58:48</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; select * from huzb_deci;</span><br><span class="line">+----+------+---------+------------------+</span><br><span class="line">| id | dec  | flo     | dou              |</span><br><span class="line">+----+------+---------+------------------+</span><br><span class="line">|  1 | 1.11 | 2.22222 | 3.33333333333333 |</span><br><span class="line">+----+------+---------+------------------+</span><br><span class="line">1 row in set (0.01 sec)</span><br></pre></td></tr></table></figure><h3 id="问题修复"><a href="#问题修复" class="headerlink" title="问题修复"></a>问题修复</h3><h4 id="日期错误问题修复"><a href="#日期错误问题修复" class="headerlink" title="日期错误问题修复"></a>日期错误问题修复</h4><ol><li>按照<a href="https://github.com/noplay/python-mysql-replication/pull/228修改对应的python-mysql-replication包文件(需要修改：binlogstream.py和row_event.py两个文件)" target="_blank" rel="noopener">https://github.com/noplay/python-mysql-replication/pull/228修改对应的python-mysql-replication包文件(需要修改：binlogstream.py和row_event.py两个文件)</a></li><li>binlog2sql中修改。增加date_tostr参数</li><li>不能直接使用python-mysql-replication的最新依赖包。只能通过修改文件，可能会引起未知问题</li><li>如果无NULL值字段，可尝试使用文本替换方式来修改插入语句。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">binlog2sql.py 修改：</span><br><span class="line">stream = BinLogStreamReader(connection_settings=self.conn_setting, server_id=self.server_id,</span><br><span class="line">                            log_file=self.start_file, log_pos=self.start_pos, only_schemas=self.only_schemas,</span><br><span class="line">                            only_tables=self.only_tables, resume_stream=True, blocking=True, date_tostr=True)</span><br></pre></td></tr></table></figure></li></ol><h4 id="二进制流数据导入导出错误问题修复"><a href="#二进制流数据导入导出错误问题修复" class="headerlink" title="二进制流数据导入导出错误问题修复"></a>二进制流数据导入导出错误问题修复</h4><p>根据mysqldump导出二进制数据时的方式，所以有以下修复思路：</p><ol><li>在生成sql文本时，将二进制流转换成十六进制。</li><li>在导入数据时，利用原生的unhex将十六进制转换成二进制。<br>修改binlog2sql_util.py以下位置:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># TODO 改动一：二进制流解析为十六进制</span><br><span class="line">def fix_object(value):</span><br><span class="line">    &quot;&quot;&quot;Fixes python objects so that they can be properly inserted into SQL queries&quot;&quot;&quot;</span><br><span class="line">    if isinstance(value, set):</span><br><span class="line">        value = &apos;,&apos;.join(value)</span><br><span class="line">    if PY3PLUS and isinstance(value, bytes):</span><br><span class="line">        # return value.decode(&apos;utf-8&apos;, errors=&apos;ignore&apos;)</span><br><span class="line">        # 将二进制数据转换成十六进制数据，并使用特殊符号包含起来。用于后面转换</span><br><span class="line">        return &quot;----&quot; + bytes.hex(value) + &quot;____&quot;</span><br><span class="line">    elif not PY3PLUS and isinstance(value, unicode):</span><br><span class="line">        return value.encode(&apos;utf-8&apos;)</span><br><span class="line">    else:</span><br><span class="line">        return value</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"># TODO 改动二：修改生成sql中的unhex串</span><br><span class="line">unhex_inex = str.find(sql, &quot;&apos;----&quot;)</span><br><span class="line">if unhex_inex != -1:</span><br><span class="line">    sql = str.replace(sql, &quot;&apos;----&quot;, &quot;unhex(&apos;&quot;)</span><br><span class="line">    sql = str.replace(sql, &quot;____&apos;&quot;, &quot;&apos;)&quot;)</span><br><span class="line">sql += &apos; #start %s end %s time %s&apos; % (e_start_pos, binlog_event.packet.log_pos, time)</span><br></pre></td></tr></table></figure></li></ol><p>题外话：<br>小公司还是各种体系、规范不够完善，要是在上一家公司，早就被业务吊起来diss不知道多少遍了。<br>数据备份恢复是作为DBA最重要的技能点之一，但是由于云化的出现，导致很多人都只会点点点，太过于依赖平台的操作，而忽略了DBA的本质工作。这也是我接下来的工作重点：MySQL、Redis自动化备份恢复系统的建设工作（已完成）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;刚入职2个月左右的时候，就遇到了业务误操作，将对测试环境的delete操作，到线上执行了。。。(至于业务为什么有delete权限的账号，俺也不知道)&lt;br&gt;由于公司所有实例都部署在阿里云上，所以只能依赖于阿里云的备份恢复系统来进行数据恢复。但是非常慢，当时是大概花了20分钟才完全恢复（-_-||）。&lt;br&gt;于是乎~工作量又被增加了。领导让我调研数据闪回工具。。。&lt;/p&gt;
&lt;p&gt;在工具调研测试过程中，发现了这几个工具存在部分BUG问题，所以给记录一下。避免再次踩坑。&lt;/p&gt;
&lt;h2 id=&quot;MyFlash&quot;&gt;&lt;a href=&quot;#MyFlash&quot; class=&quot;headerlink&quot; title=&quot;MyFlash&quot;&gt;&lt;/a&gt;MyFlash&lt;/h2&gt;&lt;p&gt;MyFlash是由美团点评公司技术工程部开发维护的一个回滚DML操作的工具。该工具通过解析v4版本的binlog，完成回滚操作。相对已有的回滚工具，其增加了更多的过滤选项，让回滚更加容易。&lt;/p&gt;
&lt;font color=&quot;red&quot;&gt;通过解析binlog来生成回滚binlog文件。&lt;/font&gt;

&lt;h3 id=&quot;优缺点&quot;&gt;&lt;a href=&quot;#优缺点&quot; class=&quot;headerlink&quot; title=&quot;优缺点&quot;&gt;&lt;/a&gt;优缺点&lt;/h3&gt;&lt;p&gt;优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多种过滤条件，能够按照需求实现精准过滤&lt;/li&gt;
&lt;li&gt;支持离线解析。不会对运行实例造成影响&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;binlog格式必须为row，并且binlog_row_image=full。&lt;/li&gt;
&lt;li&gt;只支持5.6和5.7&lt;/li&gt;
&lt;li&gt;只支持DML，不支持DDL&lt;/li&gt;
&lt;li&gt;MyFlash不能解析阿里云RDS的binlog&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL工具" scheme="http://yoursite.com/tags/MySQL%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>Redis哨兵client-reconfig-script脚本bug记录一则</title>
    <link href="http://yoursite.com/2020/05/17/new/Redis/redis_BUG%E8%AE%B0%E5%BD%95%E4%B8%80%E5%88%99/"/>
    <id>http://yoursite.com/2020/05/17/new/Redis/redis_BUG记录一则/</id>
    <published>2020-05-16T16:00:47.000Z</published>
    <updated>2020-05-16T16:06:27.092Z</updated>
    
    <content type="html"><![CDATA[<p>前一阵子一直在做自建机房Redis主从的环境搭建。了解到哨兵高可用切换后的会调用<code>client-reconfig-script</code>参数配置的脚本。<br>但是遇到了一个从2.8版本一直存在至今的BUG。我已经提了一个PR给官方，并被meger了。<a href="https://github.com/antirez/redis/pull/7113" target="_blank" rel="noopener">https://github.com/antirez/redis/pull/7113</a><br>特此记录一下。</p><h2 id="BUG场景"><a href="#BUG场景" class="headerlink" title="BUG场景"></a>BUG场景</h2><p>手动将主实例kill掉，模拟宕机情况。在某些情况下，<font color="red">哨兵已经触发了高可用切换</font>行为（主从状态、日志均有）。但是并<font color="red">没有调用</font>配置的脚本（非必现，但是落到同一台机器调用时并不会调用）<br>重启该机器上的哨兵节点又恢复正常。（重启大法好）</p><a id="more"></a><h2 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h2><p>根据网上搜索到的脚本也自己编写了一个。大概逻辑就是</p><ol><li>新主IP等于本机IP触发域名切换、元数据修改等操作，并exit 0;</li><li>非本机IP不做任何操作，并exit 1;</li></ol><p>按道理来说，这个脚本处理逻辑跟网上99%给出的脚本一致，应该问题不大。<br>的确，在前几次或者短时间内触发多次触发高可用切换，脚本都能够正常执行。<br>但是遇到以下几种情况下不会触发。</p><ol><li>触发2次高可用切换后，本人划水半小时，再来触发，此时脚本不执行。</li><li>连续触发10次左右，都正常。总时长在5分钟左右后，脚本不执行。</li></ol><h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><h3 id="脚本问题？"><a href="#脚本问题？" class="headerlink" title="脚本问题？"></a>脚本问题？</h3><p>首先，由于是第一次接触哨兵调用脚本。所以怀疑是自己写的脚本逻辑不正确。于是在编写脚本中每一个操作前都输出日志，甚至在第一行输出东西；结果仍没有调用！<br>而且轮到其他机器上的哨兵调用脚本时，可能能够调用成功。<br>所以排除脚本问题。</p><h3 id="脚本权限问题？"><a href="#脚本权限问题？" class="headerlink" title="脚本权限问题？"></a>脚本权限问题？</h3><p>通过google在Stack Overflow上，以及在Redis交流群中咨询。了解到可能存在脚本权限问题可能会调用失败。<br>于是关注该脚本在每次被调用后的状态，发现并没有什么变化。并且机器为新机器，只有本人在操作。所以认为权限问题不大可能。</p><h3 id="发现共性"><a href="#发现共性" class="headerlink" title="发现共性"></a>发现共性</h3><p>在进行多次高可用切换测试后，所有的哨兵切换在执行完高可用切换后，都不再去调用脚本。<br>这个时候，对所有的哨兵节点状态进行查看。发现有一个共性。<code>sentinel_running_scripts</code>值都为16。<br>该参数表示正在执行的脚本。<br>进一步验证，发现：</p><ol><li>该值小于16时，会正常调用。</li><li>该值会进行周期性的增加。</li><li>只触发一次高可用时，该值变成9后不再增加。</li></ol><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><font color="red">没有什么问题是阅读源码解决不了的</font><p>通过分析哨兵节点进行高可用切换段代码。发现在调用<code>client-reconfig-script</code>脚本时，会根据其返回值做不同处理。</p><ul><li>0：表示脚本执行成功。不重试</li><li>1：表示脚本执行失败。进行重试，最多10次</li><li>大于1：表示脚本执行失败。不进行重试。</li></ul><p>bug出现点：</p><ul><li>当running_scripts &gt;= SENTINEL_SCRIPT_MAX_RUNNING(16)时就不会再进入到调用脚本的逻辑里。</li><li>当调用脚本时，running_scripts++</li><li>脚本重试也会触发running_scripts++</li><li>只有当脚本达到最大重试次数(10次)，或者脚本返回非1值时，才触发一次running_scripts–</li></ul><p>可以看到，在非新主机器脚本执行时，脚本总会exit 1。所以会重试10次。running_scripts+10-1=9。<br>当遇到两次这样的情况，running_scripts就等于16了。调用脚本逻辑将不再被执行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">/* Run pending scripts if we are not already at max number of running</span><br><span class="line"> * scripts. */</span><br><span class="line">void sentinelRunPendingScripts(void) &#123;</span><br><span class="line">    listNode *ln;</span><br><span class="line">    listIter li;</span><br><span class="line">    mstime_t now = mstime();</span><br><span class="line"></span><br><span class="line">    /* Find jobs that are not running and run them, from the top to the</span><br><span class="line">     * tail of the queue, so we run older jobs first. */</span><br><span class="line">    // li是script_queue的一个前向迭代器</span><br><span class="line">    listRewind(sentinel.scripts_queue,&amp;li);</span><br><span class="line">    // 开始遍历running_scripts队列</span><br><span class="line">    while (sentinel.running_scripts &lt; SENTINEL_SCRIPT_MAX_RUNNING &amp;&amp;</span><br><span class="line">           (ln = listNext(&amp;li)) != NULL)</span><br><span class="line">    &#123;</span><br><span class="line">        sentinelScriptJob *sj = ln-&gt;value;</span><br><span class="line">        pid_t pid;</span><br><span class="line"></span><br><span class="line">        /* Skip if already running. */</span><br><span class="line">        // 跳过正在执行的job</span><br><span class="line">        if (sj-&gt;flags &amp; SENTINEL_SCRIPT_RUNNING) continue;</span><br><span class="line"></span><br><span class="line">        /* Skip if it&apos;s a retry, but not enough time has elapsed. */</span><br><span class="line">        // 还没到执行时间，暂时跳过</span><br><span class="line">        if (sj-&gt;start_time &amp;&amp; sj-&gt;start_time &gt; now) continue;</span><br><span class="line"></span><br><span class="line">        sj-&gt;flags |= SENTINEL_SCRIPT_RUNNING;</span><br><span class="line">        sj-&gt;start_time = mstime();</span><br><span class="line">        sj-&gt;retry_num++;</span><br><span class="line">        // fork一个子进程</span><br><span class="line">        pid = fork();</span><br><span class="line"></span><br><span class="line">        // fork子进程失败</span><br><span class="line">        if (pid == -1) &#123;</span><br><span class="line">            /* Parent (fork error).</span><br><span class="line">             * We report fork errors as signal 99, in order to unify the</span><br><span class="line">             * reporting with other kind of errors. */</span><br><span class="line">            sentinelEvent(LL_WARNING,&quot;-script-error&quot;,NULL,</span><br><span class="line">                          &quot;%s %d %d&quot;, sj-&gt;argv[0], 99, 0);</span><br><span class="line">            sj-&gt;flags &amp;= ~SENTINEL_SCRIPT_RUNNING;</span><br><span class="line">            sj-&gt;pid = 0;</span><br><span class="line">        &#125; else if (pid == 0) &#123;</span><br><span class="line">            /* Child */</span><br><span class="line">            execve(sj-&gt;argv[0],sj-&gt;argv,environ);</span><br><span class="line">            /* If we are here an error occurred. */</span><br><span class="line">            _exit(2); /* Don&apos;t retry execution. */</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            sentinel.running_scripts++;</span><br><span class="line">            sj-&gt;pid = pid;</span><br><span class="line">            sentinelEvent(LL_DEBUG,&quot;+script-child&quot;,NULL,&quot;%ld&quot;,(long)pid);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/* Check for scripts that terminated, and remove them from the queue if the</span><br><span class="line"> * script terminated successfully. If instead the script was terminated by</span><br><span class="line"> * a signal, or returned exit code &quot;1&quot;, it is scheduled to run again if</span><br><span class="line"> * the max number of retries did not already elapsed. */</span><br><span class="line">void sentinelCollectTerminatedScripts(void) &#123;</span><br><span class="line">    int statloc;</span><br><span class="line">    pid_t pid;</span><br><span class="line"></span><br><span class="line">    while ((pid = wait3(&amp;statloc,WNOHANG,NULL)) &gt; 0) &#123;</span><br><span class="line">        int exitcode = WEXITSTATUS(statloc);</span><br><span class="line">        int bysignal = 0;</span><br><span class="line">        listNode *ln;</span><br><span class="line">        sentinelScriptJob *sj;</span><br><span class="line"></span><br><span class="line">        if (WIFSIGNALED(statloc)) bysignal = WTERMSIG(statloc);</span><br><span class="line">        sentinelEvent(LL_DEBUG,&quot;-script-child&quot;,NULL,&quot;%ld %d %d&quot;,</span><br><span class="line">            (long)pid, exitcode, bysignal);</span><br><span class="line"></span><br><span class="line">        ln = sentinelGetScriptListNodeByPid(pid);</span><br><span class="line">        if (ln == NULL) &#123;</span><br><span class="line">            serverLog(LL_WARNING,&quot;wait3() returned a pid (%ld) we can&apos;t find in our scripts execution queue!&quot;, (long)pid);</span><br><span class="line">            continue;</span><br><span class="line">        &#125;</span><br><span class="line">        sj = ln-&gt;value;</span><br><span class="line"></span><br><span class="line">        /* If the script was terminated by a signal or returns an</span><br><span class="line">         * exit code of &quot;1&quot; (that means: please retry), we reschedule it</span><br><span class="line">         * if the max number of retries is not already reached. */</span><br><span class="line">        // 如果脚本中断或者退出值为1。则重新进入队列，并增加执行时间</span><br><span class="line">        if ((bysignal || exitcode == 1) &amp;&amp;</span><br><span class="line">            sj-&gt;retry_num != SENTINEL_SCRIPT_MAX_RETRY)</span><br><span class="line">        &#123;</span><br><span class="line">            sj-&gt;flags &amp;= ~SENTINEL_SCRIPT_RUNNING;</span><br><span class="line">            sj-&gt;pid = 0;</span><br><span class="line">            sj-&gt;start_time = mstime() +</span><br><span class="line">                             sentinelScriptRetryDelay(sj-&gt;retry_num);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            /* Otherwise let&apos;s remove the script, but log the event if the</span><br><span class="line">             * execution did not terminated in the best of the ways. */</span><br><span class="line">            // 如果是中断或者不成功，则是因为到达了执行次数上线，打印出错误日志</span><br><span class="line">            if (bysignal || exitcode != 0) &#123;</span><br><span class="line">                sentinelEvent(LL_WARNING,&quot;-script-error&quot;,NULL,</span><br><span class="line">                              &quot;%s %d %d&quot;, sj-&gt;argv[0], bysignal, exitcode);</span><br><span class="line">            &#125;</span><br><span class="line">            // 这个地方只会在成功或者重试了10才执行到。</span><br><span class="line">            listDelNode(sentinel.scripts_queue,ln);</span><br><span class="line">            sentinelReleaseScriptJob(sj);</span><br><span class="line">            sentinel.running_scripts--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="临时解决方案"><a href="#临时解决方案" class="headerlink" title="临时解决方案"></a>临时解决方案</h3><p>脚本不exit 1。exit 2表示失败，即不进行哨兵重试调用脚本行为。</p><h3 id="源码修复"><a href="#源码修复" class="headerlink" title="源码修复"></a>源码修复</h3><p>将上面源码中的<code>sentinel.running_scripts--;</code>提到else之外。即使exit 1也需要减一。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一阵子一直在做自建机房Redis主从的环境搭建。了解到哨兵高可用切换后的会调用&lt;code&gt;client-reconfig-script&lt;/code&gt;参数配置的脚本。&lt;br&gt;但是遇到了一个从2.8版本一直存在至今的BUG。我已经提了一个PR给官方，并被meger了。&lt;a href=&quot;https://github.com/antirez/redis/pull/7113&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/antirez/redis/pull/7113&lt;/a&gt;&lt;br&gt;特此记录一下。&lt;/p&gt;
&lt;h2 id=&quot;BUG场景&quot;&gt;&lt;a href=&quot;#BUG场景&quot; class=&quot;headerlink&quot; title=&quot;BUG场景&quot;&gt;&lt;/a&gt;BUG场景&lt;/h2&gt;&lt;p&gt;手动将主实例kill掉，模拟宕机情况。在某些情况下，&lt;font color=&quot;red&quot;&gt;哨兵已经触发了高可用切换&lt;/font&gt;行为（主从状态、日志均有）。但是并&lt;font color=&quot;red&quot;&gt;没有调用&lt;/font&gt;配置的脚本（非必现，但是落到同一台机器调用时并不会调用）&lt;br&gt;重启该机器上的哨兵节点又恢复正常。（重启大法好）&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis指标说明</title>
    <link href="http://yoursite.com/2020/04/26/new/Redis/Redis_INFO/"/>
    <id>http://yoursite.com/2020/04/26/new/Redis/Redis_INFO/</id>
    <published>2020-04-26T02:30:47.000Z</published>
    <updated>2020-04-26T06:03:22.046Z</updated>
    
    <content type="html"><![CDATA[<p>本文基于Redis最新unstable版本下，执行info命令后，返回的各项指标进行解释。并对其中需要特别注意的指标进行指出说明。<br>并会对阿里云info进行简单对比。区分阿里云对info进行了哪些方面的改造。</p><a id="more"></a><h2 id="info可选命令值"><a href="#info可选命令值" class="headerlink" title="info可选命令值"></a>info可选命令值</h2><p>info这个命令的判断实现是在<code>server.c-&gt;genRedisInfoString(char *section)</code>函数中。根据不同的section返回不同的info信息。<br>section可选值有以下这些：</p><ul><li>空 or all or default：大部分简要的信息</li><li>clients：客户端相关信息</li><li>memory：内存使用相关信息</li><li>persistence：RDB 和 AOF 的相关信息</li><li>stats：一般统计信息</li><li>replication：主/从复制信息</li><li>cpu：CPU 计算量统计信息</li><li>cluster：Redis 集群信息</li><li>keyspace：数据库相关的统计信息</li><li>commandstats：Redis 命令统计信息</li></ul><h2 id="info信息介绍"><a href="#info信息介绍" class="headerlink" title="info信息介绍"></a>info信息介绍</h2><h3 id="unstable信息"><a href="#unstable信息" class="headerlink" title="unstable信息"></a>unstable信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info</span><br><span class="line"># Server</span><br><span class="line">redis_version:999.999.999           // redi服务器版本</span><br><span class="line">redis_git_sha1:d044e33c             // Git SHA1</span><br><span class="line">redis_git_dirty:1                   // Git dirty flag</span><br><span class="line">redis_build_id:f0892bae2ab3d928     // redis build 版本</span><br><span class="line">redis_mode:standalone               // redis运行模式</span><br><span class="line">os:Darwin 19.4.0 x86_64             // 运行redis服务的操作系统</span><br><span class="line">arch_bits:64                        // 服务器架构，32位or64位</span><br><span class="line">multiplexing_api:kqueue             // redis所使用的事件处理机制</span><br><span class="line">atomicvar_api:atomic-builtin        // 原子处理API</span><br><span class="line">gcc_version:4.2.1                   // 编译Reedis时使用的GCC版本</span><br><span class="line">process_id:87804                    // Redis服务进程PID</span><br><span class="line">run_id:c7373afe697afdd775ab4220091574652e10354b   // Redis服务器的随机标识符</span><br><span class="line">tcp_port:6379                       // TCP/IP端口</span><br><span class="line">uptime_in_seconds:37                // 服务器启动至今的时间，单位秒</span><br><span class="line">uptime_in_days:0                    // 服务器启动至今的时间，单位天</span><br><span class="line">hz:10                               // redis内部调用频率，每秒运行多少次serverCron</span><br><span class="line">configured_hz:10                    // 配置文件设置的频率数</span><br><span class="line">lru_clock:10750326                  // 自增时钟，用于管理LRU管理，每执行一次serverCron更新一次</span><br><span class="line">executable:/Users/hzb/redis_github/redis_debug/cmake-build-debug/src/redis-server // 执行文件</span><br><span class="line">config_file:                        // 配置文件路径</span><br><span class="line"></span><br><span class="line"># Clients</span><br><span class="line">connected_clients:2                 // 连接的客户端数</span><br><span class="line">client_recent_max_input_buffer:2    // 当前客户端连接中，最大的输入缓冲区大小</span><br><span class="line">client_recent_max_output_buffer:0   // 当前客户端连接中，最大的输出缓冲区大小</span><br><span class="line">blocked_clients:0                   // 正在等待你阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端数</span><br><span class="line"></span><br><span class="line"># Memory</span><br><span class="line">used_memory:1082368                 // 当前内存使用量，byte为单位</span><br><span class="line">used_memory_human:1.03M             // 以可读方式显示当前内存使用量</span><br><span class="line">used_memory_rss:5779456             // 从操作系统层面，返回redis已分配的内存总量，这个值与ps、top等命令输出的一样</span><br><span class="line">used_memory_rss_human:5.51M         // 可读方式显示已分配总量</span><br><span class="line">used_memory_peak:1082368            // redis内存使用峰值</span><br><span class="line">used_memory_peak_human:1.03M        // 已可读方式显示内存使用峰值</span><br><span class="line">used_memory_peak_perc:100.15%       // (used_memory/ used_memory_peak) *100%</span><br><span class="line">used_memory_overhead:1066024        // Redis为了维护数据集内部机制所需的内存开销，包括客户端输出缓冲区、查询缓冲区、AOF重写缓冲区、backlog等</span><br><span class="line">used_memory_startup:998672          // Redis服务器启动时消耗的内存</span><br><span class="line">used_memory_dataset:16344           // 数据真实使用的内存量。（used_memory—used_memory_overhead）</span><br><span class="line">used_memory_dataset_perc:19.53%     // 数据占用内存占使用内存比。（100%*(used_memory_dataset/(used_memory—used_memory_startup))）</span><br><span class="line">allocator_allocated:1035760         // </span><br><span class="line">allocator_active:5741568</span><br><span class="line">allocator_resident:5741568</span><br><span class="line">total_system_memory:17179869184     // 总系统内存</span><br><span class="line">total_system_memory_human:16.00G</span><br><span class="line">used_memory_lua:37888               // Lua引擎使用内存</span><br><span class="line">used_memory_lua_human:37.00K</span><br><span class="line">used_memory_scripts:0                 </span><br><span class="line">used_memory_scripts_human:0B</span><br><span class="line">number_of_cached_scripts:0</span><br><span class="line">maxmemory:0                         // 设置的最大内存使用量。默认为0，表示不限制</span><br><span class="line">maxmemory_human:0B</span><br><span class="line">maxmemory_policy:noeviction         // 淘汰策略</span><br><span class="line">allocator_frag_ratio:5.54           // 碎片率</span><br><span class="line">allocator_frag_bytes:4705808        // 碎片大小</span><br><span class="line">allocator_rss_ratio:1.00            // 常驻内存比例</span><br><span class="line">allocator_rss_bytes:0               // 常驻内存大小</span><br><span class="line">rss_overhead_ratio:1.01             // 常驻内存开销比例</span><br><span class="line">rss_overhead_bytes:37888            // 常驻内存开销大小</span><br><span class="line">mem_fragmentation_ratio:5.58        // 碎片率（used_memory_rss/ used_memory） 正常在（1-1.6）之间</span><br><span class="line">mem_fragmentation_bytes:4743696     // 内存碎片大小</span><br><span class="line">mem_not_counted_for_evict:0         // 被驱逐的内存</span><br><span class="line">mem_replication_backlog:0           // Redis复制积压缓冲区内存</span><br><span class="line">mem_clients_slaves:0                // Redis节点客户端消耗内存</span><br><span class="line">mem_clients_normal:66632            // Rediis常规客户端消耗内存</span><br><span class="line">mem_aof_buffer:0                    // AOF使用内存</span><br><span class="line">mem_allocator:libc                  // 内存分配器</span><br><span class="line">active_defrag_running:0             // 碎片整理是否处于活动状态</span><br><span class="line">lazyfree_pending_objects:0          // 0-不存在延迟释放的挂起对象</span><br><span class="line"></span><br><span class="line"># Persistence</span><br><span class="line">loading:0                           // 服务器是否正在载入持久化文件</span><br><span class="line">rdb_changes_since_last_save:0       // 离最近一次成功生成rdb文件，写入命令的个数，即有多少个写入命令没有持久化</span><br><span class="line">rdb_bgsave_in_progress:0            // 服务器是否正在创建rdb文件</span><br><span class="line">rdb_last_save_time:1587808593       // 离最近一次成功创建rdb文件的时间戳。当前时间戳 - rdb_last_save_time=多少秒未成功生成rdb文件</span><br><span class="line">rdb_last_bgsave_status:ok           // 最近一次rdb持久化是否成功</span><br><span class="line">rdb_last_bgsave_time_sec:-1         // 最近一次成功生成rdb文件耗时秒数</span><br><span class="line">rdb_current_bgsave_time_sec:-1      // 如果服务器正在创建rdb文件，那么这个域记录的就是当前的创建操作已经耗费的秒数</span><br><span class="line">rdb_last_cow_size:0                 // RDB过程中父进程与子进程相比执行了多少修改(包括读缓冲区，写缓冲区，数据修改等)。</span><br><span class="line">aof_enabled:0                       // 是否开启了aof</span><br><span class="line">aof_rewrite_in_progress:0           // 标识aof的rewrite操作是否在进行中</span><br><span class="line">aof_rewrite_scheduled:0             // 正在等待执行rewrite任务个数</span><br><span class="line">aof_last_rewrite_time_sec:-1        // 最近一次aof rewrite耗费的时长</span><br><span class="line">aof_current_rewrite_time_sec:-1     // 如果rewrite操作正在进行，则记录所使用的时间，单位秒</span><br><span class="line">aof_last_bgrewrite_status:ok        // 上次bgrewriteaof操作的状态</span><br><span class="line">aof_last_write_status:ok            // 上次aof写入状态</span><br><span class="line">aof_last_cow_size:0                 // AOF过程中父进程与子进程相比执行了多少修改(包括读缓冲区，写缓冲区，数据修改等)。</span><br><span class="line"></span><br><span class="line"># Stats</span><br><span class="line">total_connections_received:2        // 新创建连接的个数</span><br><span class="line">total_commands_processed:3          // redis处理命令总数</span><br><span class="line">instantaneous_ops_per_sec:0         // redis当前的QPS</span><br><span class="line">total_net_input_bytes:62            // redis网络入口流量字节数</span><br><span class="line">total_net_output_bytes:39355        // redis网络出口流量字节数</span><br><span class="line">instantaneous_input_kbps:0.00       // redis网络入口kps</span><br><span class="line">instantaneous_output_kbps:0.00      // redis网络出口kps</span><br><span class="line">rejected_connections:0              // 拒绝的连接个数</span><br><span class="line">sync_full:0                         // 主从完全同步成功次数</span><br><span class="line">sync_partial_ok:0                   // 主从部分同步成功次数</span><br><span class="line">sync_partial_err:0                  // 主从部分同步失败次数</span><br><span class="line">expired_keys:0                      // 运行以来过期的key的数量</span><br><span class="line">expired_stale_perc:0.00             // 过期的比率</span><br><span class="line">expired_time_cap_reached_count:0    // 过期计数</span><br><span class="line">evicted_keys:0                      // 运行以来剔除(超过了maxmemory后)的key的数量</span><br><span class="line">keyspace_hits:0                     // 命中次数</span><br><span class="line">keyspace_misses:0                   // 没命中次数</span><br><span class="line">pubsub_channels:0                   // 当前使用中的频道数量</span><br><span class="line">pubsub_patterns:0                   // 当前使用的模式的数量</span><br><span class="line">latest_fork_usec:0                  // 最近一次fork操作阻塞redis进程的耗时数，单位微秒</span><br><span class="line">migrate_cached_sockets:0            // 是否已经缓存了到该地址的连接</span><br><span class="line">slave_expires_tracked_keys:0        // 从实例到期key数量</span><br><span class="line">active_defrag_hits:0                // 主动碎片整理命中次数</span><br><span class="line">active_defrag_misses:0              // 主动碎片整理未命中次数</span><br><span class="line">active_defrag_key_hits:0            // 主动碎片整理key命中次数</span><br><span class="line">active_defrag_key_misses:0          // 主动碎片整理key未命中次数</span><br><span class="line"></span><br><span class="line"># Replication</span><br><span class="line">role:master                         // 实例角色</span><br><span class="line">connected_slaves:0                  // 连接的slave实例个数</span><br><span class="line">master_replid:59e5c4b387f62e131a284ca4a144152cbc38dd2b    // 主实例启动随机字符串</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000   // 主实例启动随机字符串2</span><br><span class="line">master_repl_offset:0                // 主从同步偏移量</span><br><span class="line">second_repl_offset:-1               // 主从同步偏移量2,此值如果和上面的offset相同说明主从一致没延迟</span><br><span class="line">repl_backlog_active:0               // 复制积压缓冲区是否开启</span><br><span class="line">repl_backlog_size:1048576           // 复制积压缓冲大小</span><br><span class="line">repl_backlog_first_byte_offset:0    // 复制缓冲区里偏移量的大小</span><br><span class="line">repl_backlog_histlen:0              // 此值等于 master_repl_offset - repl_backlog_first_byte_offset,该值不会超过repl_backlog_size的大小</span><br><span class="line"></span><br><span class="line"># CPU</span><br><span class="line">used_cpu_sys:0.023950               // 所有redis主进程在核心态所占用的CPU时求和累计起来</span><br><span class="line">used_cpu_user:0.021295              // 所有redis主进程在用户态所占用的CPU时求和累计起来</span><br><span class="line">used_cpu_sys_children:0.000000      // 后台进程在核心态所占用的CPU时求和累计起来</span><br><span class="line">used_cpu_user_children:0.000000     // 后台进程在用户态所占用的CPU时求和累计起来</span><br><span class="line"></span><br><span class="line"># Cluster</span><br><span class="line">cluster_enabled:0                   // 是否开启了集群模式</span><br><span class="line"></span><br><span class="line"># Keyspace</span><br><span class="line">db0:keys=14,expires=0,avg_ttl=0     // key的数量,以及带有生存期的key的数,平均存活时间</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; info commandstats</span><br><span class="line"># Commandstats</span><br><span class="line">cmdstat_get:calls=1,usec=16,usec_per_call=16.00       // 命令：调用次数，消耗的时间（微秒），消耗时间平均值（微秒）</span><br><span class="line">cmdstat_info:calls=1,usec=45,usec_per_call=45.00</span><br><span class="line">cmdstat_command:calls=1,usec=1454,usec_per_call=1454.00</span><br></pre></td></tr></table></figure><h3 id="阿里云信息"><a href="#阿里云信息" class="headerlink" title="阿里云信息"></a>阿里云信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line">r-2ze48c70febc6e34.redis.rds.aliyuncs.com:6379&gt; info</span><br><span class="line"># Server</span><br><span class="line">redis_version:4.0.11</span><br><span class="line">redis_git_sha1:0b2746f2</span><br><span class="line">redis_git_dirty:1</span><br><span class="line">redis_build_id:5cfe6fcdd30f0fbc</span><br><span class="line">redis_mode:standalone</span><br><span class="line">os:Linux  </span><br><span class="line">arch_bits:64</span><br><span class="line">multiplexing_api:epoll</span><br><span class="line">atomicvar_api:atomic-builtin</span><br><span class="line">gcc_version:0.0.0</span><br><span class="line">process_id:48004</span><br><span class="line">run_id:d61d98f1f9489bbc0f790d5a7cee510c62aa6614</span><br><span class="line">tcp_port:6379</span><br><span class="line">uptime_in_seconds:648333</span><br><span class="line">uptime_in_days:7</span><br><span class="line">hz:10</span><br><span class="line">lru_clock:10767429</span><br><span class="line">executable:</span><br><span class="line">config_file:</span><br><span class="line"></span><br><span class="line"># Clients</span><br><span class="line">connected_clients:18</span><br><span class="line">client_longest_output_list:0</span><br><span class="line">client_biggest_input_buf:14</span><br><span class="line">blocked_clients:0</span><br><span class="line"></span><br><span class="line"># Memory</span><br><span class="line">used_memory:249353384</span><br><span class="line">used_memory_human:237.80M</span><br><span class="line">used_memory_rss:283426816</span><br><span class="line">used_memory_rss_human:270.30M</span><br><span class="line">used_memory_peak:279685640</span><br><span class="line">used_memory_peak_human:266.73M</span><br><span class="line">used_memory_peak_perc:89.15%</span><br><span class="line">used_memory_overhead:145987838</span><br><span class="line">used_memory_startup:7985288</span><br><span class="line">used_memory_dataset:103365546</span><br><span class="line">used_memory_dataset_perc:42.82%</span><br><span class="line">used_memory_lua:44032</span><br><span class="line">used_memory_lua_human:43.00K</span><br><span class="line">used_memory_scripts:488</span><br><span class="line">used_memory_scripts_human:488B</span><br><span class="line">number_of_cached_scripts:1</span><br><span class="line">maxmemory:1073741824</span><br><span class="line">maxmemory_human:1.00G</span><br><span class="line">maxmemory_policy:volatile-lru</span><br><span class="line">mem_fragmentation_ratio:1.14</span><br><span class="line">mem_allocator:jemalloc-5.1.0</span><br><span class="line">active_defrag_running:0</span><br><span class="line">lazyfree_pending_objects:0</span><br><span class="line">oom_err_count:0</span><br><span class="line"></span><br><span class="line"># Stats</span><br><span class="line">total_connections_received:858268</span><br><span class="line">total_commands_processed:336711164</span><br><span class="line">instantaneous_ops_per_sec:774</span><br><span class="line">total_net_input_bytes:17239795209</span><br><span class="line">total_net_output_bytes:49608006979</span><br><span class="line">instantaneous_input_kbps:33.74</span><br><span class="line">instantaneous_output_kbps:201.54</span><br><span class="line">rejected_connections:0</span><br><span class="line">rejected_connections_status:0</span><br><span class="line">sync_full:4</span><br><span class="line">sync_partial_ok:1</span><br><span class="line">sync_partial_err:0</span><br><span class="line">expired_keys:9241799</span><br><span class="line">expired_stale_perc:11.51</span><br><span class="line">expired_time_cap_reached_count:0</span><br><span class="line">evicted_keys:0</span><br><span class="line">evicted_keys_per_sec:0</span><br><span class="line">keyspace_hits:106766672</span><br><span class="line">keyspace_misses:205934497</span><br><span class="line">hits_per_sec:405.50</span><br><span class="line">misses_per_sec:338.25</span><br><span class="line">hit_rate_percentage:54.52</span><br><span class="line">pubsub_channels:0</span><br><span class="line">pubsub_patterns:0</span><br><span class="line">latest_fork_usec:11205</span><br><span class="line">migrate_cached_sockets:0</span><br><span class="line">slave_expires_tracked_keys:0</span><br><span class="line">active_defrag_hits:0</span><br><span class="line">active_defrag_misses:0</span><br><span class="line">active_defrag_key_hits:0</span><br><span class="line">active_defrag_key_misses:0</span><br><span class="line">traffic_control_input:0</span><br><span class="line">traffic_control_input_status:0</span><br><span class="line">traffic_control_output:0</span><br><span class="line">traffic_control_output_status:0</span><br><span class="line">total_bigkeys:0</span><br><span class="line">bigkeys_status:0</span><br><span class="line">stat_avg_rt:2</span><br><span class="line">stat_max_rt:428</span><br><span class="line">pacluster_migrate_sum_rt:0</span><br><span class="line">pacluster_migrate_max_rt:0</span><br><span class="line">pacluster_migrate_qps:0</span><br><span class="line">pacluster_import_sum_rt:0</span><br><span class="line">pacluster_import_max_rt:0</span><br><span class="line">pacluster_import_qps:0</span><br><span class="line">pacluster_migrate_start_time:0</span><br><span class="line">pacluster_importing_start_time:0</span><br><span class="line"></span><br><span class="line"># CPU</span><br><span class="line">used_cpu_sys:4143.00</span><br><span class="line">used_cpu_user:3553.77</span><br><span class="line">used_cpu_sys_children:2.71</span><br><span class="line">used_cpu_user_children:26.16</span><br><span class="line"></span><br><span class="line"># Cluster</span><br><span class="line">cluster_enabled:0</span><br><span class="line">databases:256</span><br><span class="line">nodecount:1</span><br><span class="line"></span><br><span class="line"># paCluster</span><br><span class="line">pacluster_enabled:0</span><br><span class="line"></span><br><span class="line"># Keyspace</span><br><span class="line">db0:keys=1790098,expires=319664,avg_ttl=9670198</span><br></pre></td></tr></table></figure><h3 id="阿里云改造"><a href="#阿里云改造" class="headerlink" title="阿里云改造"></a>阿里云改造</h3><p>通过对比，可以看到阿里云对info中的部分信息进行改造。<br>主要有：</p><ol><li>隐藏了Persistence持久话信息。这对我们排查问题时，无法确认是否因为持久化造成。</li><li>隐藏了Replication主从复制信息。</li><li><p>Stats状态中的统计信息增加了以下统计信息。主要包含（bigkeys统计、rt信息、集群相关的一些信息）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">total_bigkeys:0</span><br><span class="line">bigkeys_status:0</span><br><span class="line">stat_avg_rt:2</span><br><span class="line">stat_max_rt:428</span><br><span class="line">pacluster_migrate_sum_rt:0</span><br><span class="line">pacluster_migrate_max_rt:0</span><br><span class="line">pacluster_migrate_qps:0</span><br><span class="line">pacluster_import_sum_rt:0</span><br><span class="line">pacluster_import_max_rt:0</span><br><span class="line">pacluster_import_qps:0</span><br><span class="line">pacluster_migrate_start_time:0</span><br><span class="line">pacluster_importing_start_time:0</span><br></pre></td></tr></table></figure></li><li><p>新增了paCluster</p></li><li>Cluster中的信息进行改造</li><li>版本区别，Redis新版本中。将client_longest_output_list、client_biggest_input_buf修改成了client_recent_max_input_buffer、client_recent_max_output_buffer</li><li>info commandstats增加了其他指标</li></ol><h2 id="需要监控的参数"><a href="#需要监控的参数" class="headerlink" title="需要监控的参数"></a>需要监控的参数</h2><ul><li>connected_clients: 当前连接客户端数</li><li>client_longest_output_list：客户端中最长的输出缓冲区大小</li><li>client_biggest_input_buf：最大的输入缓冲区大小</li><li>used_memory：当前使用内存量</li><li>used_memory_peak：内存使用峰值</li><li>used_memory_overhead：维护消耗内存</li><li>maxmemory：允许使用最大内存</li><li>mem_fragmentation_ratio：内存碎片率</li><li>mem_replication_backlog：复制积压缓冲区大小</li><li>mem_clients_slaves：节点消耗内存量</li><li>mem_clients_normal：常规客户端消耗内存量</li><li>rdb_last_save_time：最近一次rdb持久化时间</li><li>rdb_last_bgsave_status：最近一次rdb持久化状态</li><li>rdb_last_bgsave_time_sec：最近一次rdb持久化消耗时间</li><li>rdb_last_cow_size：rdb持久化时cow消耗内存</li><li>total_connections_received：新创建连接数（取差值）</li><li>instantaneous_ops_per_sec：OPS</li><li>instantaneous_input_kbps：输入带宽</li><li>instantaneous_output_kbps：输出带宽</li><li>expired_keys：已过期的key（取差值）</li><li>evicted_keys：剔除的key（取差值）</li><li>keyspace_hits：命中数（取比例）</li><li>keyspace_misses：未命中数。（取比例）</li><li>connected_slaves：当前连接slave个数</li><li>master_repl_offset-second_repl_offset：主从延迟</li><li>Keyspace：各DBkey信息</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文基于Redis最新unstable版本下，执行info命令后，返回的各项指标进行解释。并对其中需要特别注意的指标进行指出说明。&lt;br&gt;并会对阿里云info进行简单对比。区分阿里云对info进行了哪些方面的改造。&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>《向上管理的艺术》小结</title>
    <link href="http://yoursite.com/2020/04/19/new/other/%E3%80%8A%E7%BA%BF%E4%B8%8A%E7%AE%A1%E7%90%86%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B%E5%B0%8F%E7%BB%93/"/>
    <id>http://yoursite.com/2020/04/19/new/other/《线上管理的艺术》小结/</id>
    <published>2020-04-19T12:53:03.000Z</published>
    <updated>2020-04-19T13:13:34.629Z</updated>
    
    <content type="html"><![CDATA[<p>20%的向上管理，决定了80%的工作效率和工作成果。</p><p>在之前的一篇博客<a href="https://omg-by.github.io/2020/01/05/new/other/%E5%90%AC%E3%80%8A%E5%B7%A5%E4%BD%9C%E4%B8%89%E5%B9%B4%E6%88%91%E5%AD%A6%E5%88%B0%E4%BA%86%E4%BB%80%E4%B9%88%E3%80%8B%E6%80%BB%E7%BB%93/" target="_blank" rel="noopener">听《工作三年我学到了什么》总结</a>提到的音频中，讨论者推荐了《向上管理的艺术》这本书。于是便买了（我才不会告诉你是凑单），利用了一周的睡前时间把它给读完，在读的过程中，回想自己这一年半的工作经历，的确是在无意间触犯到了好几条禁忌行为。。。感谢领导的包容和支持。<br>利用周末空余时间将这本书做个简单的总结，尽量从自身层面优化。不仅是与领导沟通，在生活中也处处需要注意。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gdz9w4eciyj31dv0u07g4.jpg" alt=""></p><p>一个人的汇报反馈机制，往往能影响到上司对你的态度和看法。上司也有自己的事要做，并不会时时刻刻的盯着你；<br>领导负责下发任务，如果没有反馈，那么他将无法掌控任务的进度，甚至最终因没有反馈而导致任务失败，则会大大降低领导对你的看法。<br>领导的经验摆在那，有很多在我们看来比较困难的事，也许领导几句话、一个想法、一个电话就能轻松的解决。<font color="red">领导在一定意义上，也是我们的资源</font>。</p><p>领导也是一个人，也会有各种各样的性格和情绪。<font color="red">如何在合适时机、选择合适方式才式获取到到正反馈信息？</font>这不仅仅跟领导反馈，在生活中，这也是一门需要时时需要注意的地方。<br>毕竟是有求于人，往往就是那么一个不经意的小点，导致了事情的失败，影响的只会是自己，徒增非常多的人力物力。</p><p><font color="red">多站在别人的角度上思考</font>，别人是怎么看待这件事，需要我做什么，希望我怎么做。才能以更好的姿势、更快的效率去做好一件事。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;20%的向上管理，决定了80%的工作效率和工作成果。&lt;/p&gt;
&lt;p&gt;在之前的一篇博客&lt;a href=&quot;https://omg-by.github.io/2020/01/05/new/other/%E5%90%AC%E3%80%8A%E5%B7%A5%E4%BD%9C%E4%
      
    
    </summary>
    
      <category term="生活杂记" scheme="http://yoursite.com/categories/%E7%94%9F%E6%B4%BB%E6%9D%82%E8%AE%B0/"/>
    
    
      <category term="思考" scheme="http://yoursite.com/tags/%E6%80%9D%E8%80%83/"/>
    
      <category term="总结" scheme="http://yoursite.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Redis RDB文件存储格式</title>
    <link href="http://yoursite.com/2020/01/14/new/Redis/Redis-RDB%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/"/>
    <id>http://yoursite.com/2020/01/14/new/Redis/Redis-RDB文件存储格式/</id>
    <published>2020-01-14T12:13:30.000Z</published>
    <updated>2020-01-14T13:42:26.518Z</updated>
    
    <content type="html"><![CDATA[<p>Redis存在两种数据文件：RDB和AOF。<br>AOF文件的结构比较简单，就不做说明。主要是简介RDB数据文件的结构</p><p>*.rdb文件是表示Redis瞬间快照的一个二进制文件。根据这个快照文件，可以将Redis恢复到Redis当时的状态。<br>rdb文件针对读写进行了优化操作。尽可能的会使用LZF压缩算法来减少文件的大小。</p><p>在命令行下我们可以通过<code>od -x rdb.rdb | less</code>和<code>od -c rdb.rdb | less</code>命令查看16进制和字符模式下的rdb文件。<br>注意：使用<code>od -x</code>命令查出来的16进制是逆序的。</p><h2 id="RDB文件结构"><a href="#RDB文件结构" class="headerlink" title="RDB文件结构"></a>RDB文件结构</h2><p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gan46keebgj30r806z3z8.jpg" alt=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">----------------------------# RDB文件是二进制的，所以并不存在回车换行来分隔一行一行.</span><br><span class="line">52 45 44 49 53              # 以字符串 &quot;REDIS&quot; 开头</span><br><span class="line">30 30 30 36                 # RDB 的版本号，大端存储，比如左边这个表示版本号为0006</span><br><span class="line">----------------------------</span><br><span class="line">FE 00                       # FE = FE表示数据库编号，Redis支持多个库，以数字编号，这里00表示第0个数据库</span><br><span class="line">----------------------------# Key-Value 对存储开始了</span><br><span class="line">FD $length-encoding         # FD 表示过期时间，过期时间是用 length encoding 编码存储的，后面会讲到</span><br><span class="line">$value-type                 # 1 个字节用于表示value的类型，比如set,hash,list,zset等</span><br><span class="line">$string-encoded-key         # Key 值，通过string encoding 编码，同样后面会讲到</span><br><span class="line">$encoded-value              # Value值，根据不同的Value类型采用不同的编码方式</span><br><span class="line">----------------------------</span><br><span class="line">FC $length-encoding         # FC 表示毫秒级的过期时间，后面的具体时间用length encoding编码存储</span><br><span class="line">$value-type                 # 同上，也是一个字节的value类型</span><br><span class="line">$string-encoded-key         # 同样是以 string encoding 编码的 Key值</span><br><span class="line">$encoded-value              # 同样是以对应的数据类型编码的 Value 值</span><br><span class="line">----------------------------</span><br><span class="line">$value-type                 # 下面是没有过期时间设置的 Key-Value对，为防止冲突，数据类型不会以 FD, FC, FE, FF 开头</span><br><span class="line">$string-encoded-key</span><br><span class="line">$encoded-value</span><br><span class="line">----------------------------</span><br><span class="line">FE $length-encoding         # 下一个库开始，库的编号用 length encoding 编码</span><br><span class="line">----------------------------</span><br><span class="line">...                         # 继续存储这个数据库的 Key-Value 对</span><br><span class="line">FF                          ## FF：RDB文件结束的标志</span><br><span class="line">8 byte checksum             ## 8位校验码                  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">------------------------------------</span><br><span class="line">od -x rdb.rdb | head -n 10</span><br><span class="line">0000000 4552 4944 3053 3030 fe36 fc1e ae47 2160</span><br><span class="line">0000020 016e 0000 2800 6c65 7361 6974 5f63 3036</span><br><span class="line">0000040 3930 3562 6432 3139 3962 3233 3134 3138</span><br><span class="line">0000060 6338 3031 3338 6166 6233 3163 6264 5d4e</span><br><span class="line">0000100 8b1f 0008 0000 0000 ff00 9bcc 535b 595a</span><br><span class="line">0000120 c79b 66fb e7ae a42b 1db8 7585 7bde dea7</span><br><span class="line">0000140 a779 eb62 7264 3500 e931 2a1c 2165 116c</span><br><span class="line">0000160 6082 1838 27b5 1855 8b4d fb67 d18d 6344</span><br><span class="line">0000200 3a62 6231 51b7 6dd3 6247 bb50 9aac b9ab</span><br><span class="line">0000220 8f9c d610 7366 af95 b530 cd01 d906 8104</span><br><span class="line"></span><br><span class="line">-------------------------------------</span><br><span class="line">od -c rdb.rdb | head -n 10</span><br><span class="line">0000000   R   E   D   I   S   0   0   0   6 376 036 374   G 256   `   !</span><br><span class="line">0000020   n 001  \0  \0  \0   (   e   l   a   s   t   i   c   _   6   0</span><br><span class="line">0000040   0   9   b   5   2   d   9   1   b   9   3   2   4   1   8   1</span><br><span class="line">0000060   8   c   1   0   8   3   f   a   3   b   c   1   d   b   N   ]</span><br><span class="line">0000100 037 213  \b  \0  \0  \0  \0  \0  \0 377 314 233   [   S   Z   Y</span><br><span class="line">0000120 233 307 373   f 256 347   + 244 270 035 205   u 336   &#123; 247 336</span><br><span class="line">0000140   y 247   b 353   d   r  \0   5   1 351 034   *   e   !   l 021</span><br><span class="line">0000160 202   `   8 030 265   &apos;   U 030   M 213   g 373 215 321   D   c</span><br><span class="line">0000200   b   :   1   b 267   Q 323   m   G   b   P 273 254 232 253 271</span><br><span class="line">0000220 234 217 020 326   f   s 225 257   0 265 001 315 006 331 004 201</span><br></pre></td></tr></table></figure></p><a id="more"></a><h3 id="魔数"><a href="#魔数" class="headerlink" title="魔数"></a>魔数</h3><p>rdb文件固定以魔术字符串”REDIS”开头，表示这个rdb文件时Redis数据文件。<br><code>52 45 44 49 53 # &quot;REDIS&quot;</code></p><h3 id="版本号"><a href="#版本号" class="headerlink" title="版本号"></a>版本号</h3><p>接下来固定4个字节保存rdb格式的的版本号。<br><code>30 30 30 36 # Version = 6</code></p><h3 id="数据库编号"><a href="#数据库编号" class="headerlink" title="数据库编号"></a>数据库编号</h3><p>一个字节<code>0xfe</code>表示开始选择数据库；在这个字节之后，一个可变长度字段表示数据库编号。具体部分参考<b>长度编码</b>部分<br><code>1e</code>表示十进制的30，代表是30数据库</p><h3 id="键值对"><a href="#键值对" class="headerlink" title="键值对"></a>键值对</h3><p>在选择数据库后，就是具体的一些键值对记录。每个键值对包含4个部分</p><table><thead><tr><th>名称</th><th>大小</th><th>说明</th></tr></thead><tbody><tr><td>RDB_OPCODE_EXPIRETIME_MS</td><td>1byte</td><td>0xfc/0xfd(252/253)，说明是带过期时间的键值对</td></tr><tr><td>ms</td><td>8bytes</td><td>时间戳</td></tr><tr><td>TYPE</td><td>1byte</td><td>键值对类型</td></tr><tr><td>key</td><td>—-</td><td>键</td></tr><tr><td>value</td><td>—-</td><td>值</td></tr></tbody></table><h4 id="过期标记和过期时间戳"><a href="#过期标记和过期时间戳" class="headerlink" title="过期标记和过期时间戳"></a>过期标记和过期时间戳</h4><p>一个字节。<code>0xFD</code>表示过期时间戳以秒为单位，<code>0xFC</code>表示过期时间戳以毫秒为单位。<br>如果设置了过期时间，那么接下来的8个字节就表示具体的过期时间。<br>在导入RDB文件的时候，会将已经过期的key进行丢弃。</p><p>如果没有设置过期时间，则没有这两个字段。</p><h4 id="key类型"><a href="#key类型" class="headerlink" title="key类型"></a>key类型</h4><p>一个字节，表示保存键值对value的具体编码。<br><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gan531wxo8j30ly0dqt9u.jpg" alt=""></p><ul><li>0表示是一个简单字符串</li><li>当值为9-13时，该值被包装到字符串中，读取字符串后，会对其进行进一步解析。</li><li>当值为1-4时，该值是一个字符串序列，此字符串序列用于构造列表、集合、集合或哈希表等复杂数据类型。</li></ul><h4 id="键值对-1"><a href="#键值对-1" class="headerlink" title="键值对"></a>键值对</h4><p>key固定为字符串编码保存。<br>value取决于编码，不同的编码有不同的保存格式。<br>后面会有详细介绍。</p><h2 id="长度编码"><a href="#长度编码" class="headerlink" title="长度编码"></a>长度编码</h2><p>长度编码用于存储下一个对象的长度，长度编码是一种可变长字节编码，目的在于使用更少的字节来表示内容。<br>从数据流中取出一个字节，前面两个bit可能存在以下几种情况：</p><ul><li>00：接下来6位表示长度</li><li>01：取出下一个字节，组合的14位表示长度</li><li>10：剩余6位舍弃，取出4个字节表示长度</li><li>11：表示下一个对象以特殊格式编码。其余6位表示格式。</li></ul><p>63的数字只需要一个字节进行存储<br>64 – 16383 的数字只需要两个字节进行存储<br>16383 - 2^32 -1 的数字只需要用5个字节（1个字节的标识加4个字节的值）进行存储</p><h2 id="字符串编码"><a href="#字符串编码" class="headerlink" title="字符串编码"></a>字符串编码</h2><p>Redis字符串是二进制安全的，这意味着可以在其中存储任何内容。它没有任何特殊的字符串结尾标记。最好将Redis字符串视为字节数组。</p><p>在RDB文件中有三种类型的字符串：</p><ol><li>简单字符串</li><li>8、16、32位的整数</li><li>一个经过LZF压缩的支付串</li></ol><h3 id="简单字符串"><a href="#简单字符串" class="headerlink" title="简单字符串"></a>简单字符串</h3><p>简单字符串编码非常简单，就是 字符串长度+具体的字符串<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1ganb8w8bbzj31is03g74g.jpg" alt=""></p><h3 id="整数字符串"><a href="#整数字符串" class="headerlink" title="整数字符串"></a>整数字符串</h3><p>在长度编码为<code>11</code>的时候，读取后续的6位。如果后续的6位为：</p><ul><li>0表示跟随的是8位整数</li><li>1表示跟随的是16位整数</li><li>2表示跟随的是32位整数</li></ul><h3 id="压缩字符串"><a href="#压缩字符串" class="headerlink" title="压缩字符串"></a>压缩字符串</h3><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1ganbdubpn0j31i603mwey.jpg" alt=""><br>在长度编码为<code>11</code>的时候，读取后续的6位。如果后续的6位为<code>3</code>表示后面跟随着的是压缩字符串。具体步骤为下：</p><ol><li>使用长度编码方式从c_len中读取出压缩的长度</li><li>使用长度编码方式从o_len中读取出压缩前的长度</li><li>读取出压缩后的字符串</li><li>使用LZF算法解压缩</li></ol><h3 id="List编码和Set编码"><a href="#List编码和Set编码" class="headerlink" title="List编码和Set编码"></a>List编码和Set编码</h3><p>一个Redis list表示为一序列字符串</p><ol><li>首先，从流中读取list的大小，按照长度编码的方式读取出<code>size</code>大小值。</li><li>按照字符串编码方式从流中读取出size个字符串</li><li>使用这些字符串重新构建list</li></ol><h3 id="Hash编码"><a href="#Hash编码" class="headerlink" title="Hash编码"></a>Hash编码</h3><ol><li>从流中按照长度编码的方式读取出hash表的大小size</li><li>从流中按照字符串编码方式读取出2*size个字符串对象</li><li>键值对交替出现</li></ol><h3 id="Ziplist编码"><a href="#Ziplist编码" class="headerlink" title="Ziplist编码"></a>Ziplist编码</h3><p>一个Ziplist编码本质上是一个list类型的字符串，借助于标记(flag)和偏移量(offset)来达到双向遍历。<br>为解析一个ziplist，首先从流中按照字符串编码读取一个字符串，这个字符串就是ziplist的封装。<br>结构如下：</p><ol><li>zlbytes ：这是一个 4 字节无符号整数，表示 ziplist 的总字节数。这 4 字节是 little endian 格式－－最先出现的是最低有效位组</li><li>zltail：这是一个 4 字节无符号整数，little endian 格式。它表示到 ziplist 的尾条目（tail entry）的偏移。</li><li>zllen：这是一个 2 字节无符号整数，little endian 格式。它表示 ziplist 的条目的数量</li><li>entry：一个条目表示 ziplist 的元素。细节在下面</li><li>zlend：总是等于 255。它表示 ziplist 的结束</li></ol><p>ziplist的每个entry都是以下这样的格式： <code>&lt;length-prev-entry&gt;&lt;special-flag&gt;&lt;raw-bytes-of-entry&gt;</code><br>具体参考Redis中ziplist的实现方式。</p><h2 id="CRC校验和"><a href="#CRC校验和" class="headerlink" title="CRC校验和"></a>CRC校验和</h2><p>从Redis5开始启动参数控制是否将8字节的校验和添加到文件末尾，可以通过修改参数关闭该功能。<br>当禁用校验和的时候，此字段为0</p><blockquote><p><a href="https://github.com/sripathikrishnan/redis-rdb-tools/blob/master/docs/RDB_File_Format.textile" target="_blank" rel="noopener">https://github.com/sripathikrishnan/redis-rdb-tools/blob/master/docs/RDB_File_Format.textile</a><br><a href="https://github.com/sripathikrishnan/redis-rdb-tools/blob/master/docs/RDB_Version_History.textile" target="_blank" rel="noopener">https://github.com/sripathikrishnan/redis-rdb-tools/blob/master/docs/RDB_Version_History.textile</a><br><a href="https://github.com/wen866595/open-doc/blob/master/redis-doc/Redis-RDB-Dump-File-Format-cn.md" target="_blank" rel="noopener">https://github.com/wen866595/open-doc/blob/master/redis-doc/Redis-RDB-Dump-File-Format-cn.md</a><br><a href="https://blog.csdn.net/guiqulaxi920/article/details/51177307" target="_blank" rel="noopener">https://blog.csdn.net/guiqulaxi920/article/details/51177307</a><br><a href="http://ascii.911cha.com/" target="_blank" rel="noopener">http://ascii.911cha.com/</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis存在两种数据文件：RDB和AOF。&lt;br&gt;AOF文件的结构比较简单，就不做说明。主要是简介RDB数据文件的结构&lt;/p&gt;
&lt;p&gt;*.rdb文件是表示Redis瞬间快照的一个二进制文件。根据这个快照文件，可以将Redis恢复到Redis当时的状态。&lt;br&gt;rdb文件针对读写进行了优化操作。尽可能的会使用LZF压缩算法来减少文件的大小。&lt;/p&gt;
&lt;p&gt;在命令行下我们可以通过&lt;code&gt;od -x rdb.rdb | less&lt;/code&gt;和&lt;code&gt;od -c rdb.rdb | less&lt;/code&gt;命令查看16进制和字符模式下的rdb文件。&lt;br&gt;注意：使用&lt;code&gt;od -x&lt;/code&gt;命令查出来的16进制是逆序的。&lt;/p&gt;
&lt;h2 id=&quot;RDB文件结构&quot;&gt;&lt;a href=&quot;#RDB文件结构&quot; class=&quot;headerlink&quot; title=&quot;RDB文件结构&quot;&gt;&lt;/a&gt;RDB文件结构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwly1gan46keebgj30r806z3z8.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;----------------------------# RDB文件是二进制的，所以并不存在回车换行来分隔一行一行.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52 45 44 49 53              # 以字符串 &amp;quot;REDIS&amp;quot; 开头&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30 30 30 36                 # RDB 的版本号，大端存储，比如左边这个表示版本号为0006&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;----------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;FE 00                       # FE = FE表示数据库编号，Redis支持多个库，以数字编号，这里00表示第0个数据库&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;----------------------------# Key-Value 对存储开始了&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;FD $length-encoding         # FD 表示过期时间，过期时间是用 length encoding 编码存储的，后面会讲到&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$value-type                 # 1 个字节用于表示value的类型，比如set,hash,list,zset等&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$string-encoded-key         # Key 值，通过string encoding 编码，同样后面会讲到&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$encoded-value              # Value值，根据不同的Value类型采用不同的编码方式&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;----------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;FC $length-encoding         # FC 表示毫秒级的过期时间，后面的具体时间用length encoding编码存储&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$value-type                 # 同上，也是一个字节的value类型&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$string-encoded-key         # 同样是以 string encoding 编码的 Key值&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$encoded-value              # 同样是以对应的数据类型编码的 Value 值&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;----------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$value-type                 # 下面是没有过期时间设置的 Key-Value对，为防止冲突，数据类型不会以 FD, FC, FE, FF 开头&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$string-encoded-key&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$encoded-value&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;----------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;FE $length-encoding         # 下一个库开始，库的编号用 length encoding 编码&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;----------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;...                         # 继续存储这个数据库的 Key-Value 对&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;FF                          ## FF：RDB文件结束的标志&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8 byte checksum             ## 8位校验码                  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;------------------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;od -x rdb.rdb | head -n 10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000000 4552 4944 3053 3030 fe36 fc1e ae47 2160&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000020 016e 0000 2800 6c65 7361 6974 5f63 3036&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000040 3930 3562 6432 3139 3962 3233 3134 3138&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000060 6338 3031 3338 6166 6233 3163 6264 5d4e&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000100 8b1f 0008 0000 0000 ff00 9bcc 535b 595a&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000120 c79b 66fb e7ae a42b 1db8 7585 7bde dea7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000140 a779 eb62 7264 3500 e931 2a1c 2165 116c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000160 6082 1838 27b5 1855 8b4d fb67 d18d 6344&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000200 3a62 6231 51b7 6dd3 6247 bb50 9aac b9ab&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000220 8f9c d610 7366 af95 b530 cd01 d906 8104&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;-------------------------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;od -c rdb.rdb | head -n 10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000000   R   E   D   I   S   0   0   0   6 376 036 374   G 256   `   !&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000020   n 001  \0  \0  \0   (   e   l   a   s   t   i   c   _   6   0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000040   0   9   b   5   2   d   9   1   b   9   3   2   4   1   8   1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000060   8   c   1   0   8   3   f   a   3   b   c   1   d   b   N   ]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000100 037 213  \b  \0  \0  \0  \0  \0  \0 377 314 233   [   S   Z   Y&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000120 233 307 373   f 256 347   + 244 270 035 205   u 336   &amp;#123; 247 336&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000140   y 247   b 353   d   r  \0   5   1 351 034   *   e   !   l 021&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000160 202   `   8 030 265   &amp;apos;   U 030   M 213   g 373 215 321   D   c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000200   b   :   1   b 267   Q 323   m   G   b   P 273 254 232 253 271&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0000220 234 217 020 326   f   s 225 257   0 265 001 315 006 331 004 201&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>pika学习之同步篇</title>
    <link href="http://yoursite.com/2020/01/05/new/pika/pika%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%9D%97/"/>
    <id>http://yoursite.com/2020/01/05/new/pika/pika复制模块/</id>
    <published>2020-01-05T14:08:29.000Z</published>
    <updated>2020-01-05T14:11:12.720Z</updated>
    
    <content type="html"><![CDATA[<ul><li>pika支持m-s的复制方式，跟redis主从复制命令一样，通过slave执行slaveof命令来触发。</li><li>slave的trysync线程向master发起trysync，同时将同步位点信息发送给master</li><li>master处理trysync命令，发起对slave的同步过程，从同步点开始顺序发送binlog或进行全同步</li></ul><h1 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h1><p>pika在需要进行全量同步的时候，会将数据文件进行dump后通过rsync的deamon模式发送给slave。</p><h2 id="实现逻辑"><a href="#实现逻辑" class="headerlink" title="实现逻辑"></a>实现逻辑</h2><ol><li>slave在trysnc前启动rsync进程启动rsync服务</li><li>master发现需要全同步时，判断是否有备份文件可用，如果没有先dump一份</li><li>master通过rsync向slave发送dump出的文件</li><li>slave用收到的文件替换自己的db</li><li>slave用最新的偏移量再次发起trysnc</li><li>完成同步 </li></ol><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gam0g8e1iij30oq09q0th.jpg" alt=""></p><center>slave同步流程</center><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gam0gae0huj30me08qt99.jpg" alt=""></p><center>master同步流程</center><a id="more"></a><p>slave连接状态：</p><ul><li>No Connect：不尝试成为任何其他节点的slave</li><li>Connect：Slaveof后尝试成为某个节点的slave，发送trysnc命令和同步点</li><li>Connecting：收到master回复可以slaveof，尝试跟master建立心跳</li><li>Connected: 心跳建立成功</li><li>WaitSync：不断检测是否DBSync完成，完成后更新DB并发起新的slaveof<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gam0h9q8ulj30hn0dr0tm.jpg" alt=""></li></ul><h1 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h1><p>Pika的主从同步是通过Binlog来完成的，在一主多从的结构中，master节点也可以给多个slave复用一个Binlog，不同的slave拥有不同的偏移量。</p><h2 id="工作过程"><a href="#工作过程" class="headerlink" title="工作过程"></a>工作过程</h2><ol><li>当WorkerThread接收到客户端的命令，按照执行顺序，添加到Binlog里</li><li>BinglogSenderThread判断它所负责的从节点在主节点的Binlog里是否有需要同步的命令，若有则发送给从节点</li><li>BinglogReceiverModule模块则做以下三件事情：接收主节点的BinlogSenderThread发送过来的同步命令；把接收到的命令应用到本地的数据上；把接收到的命令添加到本地Binlog里 至此，一条命令从主节点到从节点的同步过程完成<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gam0spmbugj30i20en75l.jpg" alt=""></li></ol><ul><li>WorkerThread：接受和处理用户的命令</li><li>BinlogSenderThread：负责顺序地向对应的从节点发送在需要同步的命令</li><li>BinlogReceiverModule: 负责接受主节点发送过来的同步命令</li><li>Binglog：用于顺序的记录需要同步的命令</li></ul><p>上图中的<code>BinLogReceiverModule</code>是为了更好的说明方便而抽象出来的一个对象，从图中可以看出<code>BinLogReceiverModule</code>是由一个<code>BinlogReceiverThread</code>和多个<code>BinlogBGWorker</code>组成。</p><ul><li>BinlogReceiverThread: 负责接受由主节点传送过来的命令，并分发给各个BinlogBGWorker，若当前的节点是只读状态（不能接受客户端的同步命令），则在这个阶段写Binlog</li><li>BinlogBGWorker：负责执行同步命令；若该节点不是只读状态（还能接受客户端的同步命令），则在这个阶段写Binlog（在命令执行之前写）</li></ul><p>BinlogReceiverThread接收到一个同步命令后，它会给这个命令赋予一个唯一的序列号（这个序列号是递增的），并把它分发给一个BinlogBGWorker；而各个BinlogBGWorker则会根据各个命令的所对应的序列号的顺序来执行各个命令，这样也就保证了命令执行的顺序和主节点执行的顺序一致了 之所以这么设计主要原因是：</p><ol><li>配备多个BinlogBGWorker是可以提高主从同步的效率，减少主从同步的滞后延迟</li><li>BinlogBGWorker在执行执行之前写Binlog可以提高命令执行的并行度</li><li>在当前节点是非只读状态，让BinglogReceiverThread来写Binlog，是为了让Binglog里保存的命令顺序和命令的执行顺序保持一致</li></ol><h2 id="Binlog结构"><a href="#Binlog结构" class="headerlink" title="Binlog结构"></a>Binlog结构</h2><p>由于主从偏移量一样，所以一旦发生网络或节点故障需要重连主从时，slave只需要将当前的偏移量发送给master，master找到后从该偏移量开始同步后续命令。<br>理论上命令不做处理一条一条追加到Binlog文件中，这也就意味着如果文件写错一个字节就会导致整个文件不可用，所以pika采用了类似leveldb log的格式来进行存储。<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gam0rxhp2rj30i20att9m.jpg" alt=""></p><h3 id="leveldb-log"><a href="#leveldb-log" class="headerlink" title="leveldb log"></a>leveldb log</h3><p>在leveldb中，所有的写操作都必须先成功的append到操作日志中，然后再更新内存memtable</p><ol><li>可以将随机的写IO变成append，极大的提高写磁盘速度</li><li>防止在节点down机导致内存数据丢失，造成数据丢失<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">The log file contents are a sequence of 32KB blocks.  The only</span><br><span class="line">exception is that the tail of the file may contain a partial block.</span><br><span class="line"></span><br><span class="line">Each block consists of a sequence of records:</span><br><span class="line">   block := record* trailer?</span><br><span class="line">   record :=</span><br><span class="line">    checksum: uint32    // crc32c of type and data[] ; little-endian</span><br><span class="line">    length: uint16      // little-endian</span><br><span class="line">    type: uint8     // One of FULL, FIRST, MIDDLE, LAST</span><br><span class="line">    data: uint8[length]</span><br><span class="line"></span><br><span class="line">A record never starts within the last six bytes of a block (since it</span><br><span class="line">won&apos;t fit).  Any leftover bytes here form the trailer, which must</span><br><span class="line">consist entirely of zero bytes and must be skipped by readers.</span><br></pre></td></tr></table></figure></li></ol><p>日志文件由连续的大小为32KB的block组成，block又由连续的record组成，record的格式为 | CRC(4 byte) | Length(2 byte) | type(1 byte) | data |</p><blockquote><p><a href="https://www.jianshu.com/p/223f0c73ddc2" target="_blank" rel="noopener">LevelDB 功能与架构</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;pika支持m-s的复制方式，跟redis主从复制命令一样，通过slave执行slaveof命令来触发。&lt;/li&gt;
&lt;li&gt;slave的trysync线程向master发起trysync，同时将同步位点信息发送给master&lt;/li&gt;
&lt;li&gt;master处理trysync命令，发起对slave的同步过程，从同步点开始顺序发送binlog或进行全同步&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;全量同步&quot;&gt;&lt;a href=&quot;#全量同步&quot; class=&quot;headerlink&quot; title=&quot;全量同步&quot;&gt;&lt;/a&gt;全量同步&lt;/h1&gt;&lt;p&gt;pika在需要进行全量同步的时候，会将数据文件进行dump后通过rsync的deamon模式发送给slave。&lt;/p&gt;
&lt;h2 id=&quot;实现逻辑&quot;&gt;&lt;a href=&quot;#实现逻辑&quot; class=&quot;headerlink&quot; title=&quot;实现逻辑&quot;&gt;&lt;/a&gt;实现逻辑&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;slave在trysnc前启动rsync进程启动rsync服务&lt;/li&gt;
&lt;li&gt;master发现需要全同步时，判断是否有备份文件可用，如果没有先dump一份&lt;/li&gt;
&lt;li&gt;master通过rsync向slave发送dump出的文件&lt;/li&gt;
&lt;li&gt;slave用收到的文件替换自己的db&lt;/li&gt;
&lt;li&gt;slave用最新的偏移量再次发起trysnc&lt;/li&gt;
&lt;li&gt;完成同步 &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwgy1gam0g8e1iij30oq09q0th.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;center&gt;slave同步流程&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwgy1gam0gae0huj30me08qt99.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;center&gt;master同步流程&lt;/center&gt;
    
    </summary>
    
      <category term="Pika" scheme="http://yoursite.com/categories/Pika/"/>
    
    
      <category term="Pika" scheme="http://yoursite.com/tags/Pika/"/>
    
  </entry>
  
  <entry>
    <title>何为IO多路复用</title>
    <link href="http://yoursite.com/2020/01/05/new/Redis/%E4%BD%95%E4%B8%BAIO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"/>
    <id>http://yoursite.com/2020/01/05/new/Redis/何为IO多路复用/</id>
    <published>2020-01-05T08:29:22.000Z</published>
    <updated>2020-01-05T08:32:32.647Z</updated>
    
    <content type="html"><![CDATA[<h2 id="网络编程概念"><a href="#网络编程概念" class="headerlink" title="网络编程概念"></a>网络编程概念</h2><p>在网络当中，数据的传输是基于HTTP/TCP协议簇来实现的。TCP协议仅仅是把这些数据看做是一串二进制流来进行处理。<br>所以：<b>客户端和服务器是通过在建立的连接上发送字节流来进行通信</b></p><p>一个连接由它两端的套接字地址唯一确定，结构为<code>(客户端地址:客户端端口号，服务端地址:服务端端口号)</code>。有了通信双方的连接地址信息后，就可以进行数据传输了。</p><p>在Unix系统中，实现了一套套接字接口来描述和规范双方通信的整个过程。<br>创建-&gt;连接-&gt;绑定-&gt;监听-&gt;响应<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1galrpl667mj30hs0dzwfp.jpg" alt=""></p><blockquote><ul><li>socket()：创建一个套接字描述符</li><li>connect()：客户端通过调用connect函数来建立和服务器的连接</li><li>bind()：告诉内核将socket()创建的套接字与某个服务端地址与端口连接起来，后续会对这个地址和端口进行监听</li><li>listen()：告诉内核，将这个套接字当成服务器这种被动实体来看待(服务器是等待客户端连接的被动实体，而内核认为socket()创建的套接字默认是主动实体，所以才需要listen()函数，告诉内核进行主动到被动实体的转换)</li><li>accept()：等待客户端的连接请求并返回一个新的已连接描述符</li></ul></blockquote><a id="more"></a><h2 id="最简单的单进程服务器"><a href="#最简单的单进程服务器" class="headerlink" title="最简单的单进程服务器"></a>最简单的单进程服务器</h2><p>由于Unix的历史遗留问题，原始的套接字接口对地址和端口等数据封装并不简洁。<br>在最初的服务器中，一个服务器进程只能同时处理一个客户端连接与相关的读写操作。<br>在读写的过程中，整个进程被该客户端独占，当前服务器进程只能处理该客户端连接的读写操作，无法对其他客户端连接请求进行处理。</p><h2 id="IO并发提升"><a href="#IO并发提升" class="headerlink" title="IO并发提升"></a>IO并发提升</h2><h3 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h3><p>如果去优化单进程？<br>一个进程不行，那就搞多个进程来同时处理不就得了。</p><p>由于一个客户端的connect对应着一个服务端的accept，那么每次客户端过来时，都使用fork()来进行accept的系统调用。</p><p>缺点：</p><ul><li>进程创建的数量随连接请求的增加而增加。</li><li>fork等系统调用会使得进程的上下文进行切换，效率很低。</li><li>进程与进程之间的地址空间私有。使得进程之间的数据共享比较困难。</li></ul><h3 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h3><p>线程是运行在进程上下文的逻辑流。一个进程可以包含多个线程，多个线程运行在单一的进程上下文中，因此共享这个进程的地址空间的所有内容，解决了进程与进程之间通信难的问题。同时，由于一个线程的上下文要比一个进程的上下文小得多，所以线程的上下文切换，要比进程的上下文切换效率高得多。线程是轻量级的进程，解决了进程上下文切换效率低的问题。</p><h3 id="基于单进程的IO多路复用"><a href="#基于单进程的IO多路复用" class="headerlink" title="基于单进程的IO多路复用"></a>基于单进程的IO多路复用</h3><p>前面谈到的都是通过增加进程和线程的数量来同时处理多个套接字。而IO多路复用只需要一个进程就能够处理多个套接字。</p><p>其本质是：<b>一个服务端进程可以同时处理多个套接字描述符</b></p><p>在之前的讲述中，一个服务端进程，只能同时处理一个连接。如果想同时处理多个客户端连接，需要多进程或者多线程的帮助，免不了上下文切换的开销。IO多路复用技术就解决了上下文切换的问题。IO多路复用技术的发展可以分为select-&gt;poll-&gt;epoll三个阶段。</p><p>IO多路复用的核心就是添加了一个<b>套接字集合管理员</b>，它可以同时监听多个套接字。由于客户端连接以及读写事件到来的随机性，我们需要这个管理员在单进程内部对多个套接字的事件进行合理的调度。</p><h4 id="select"><a href="#select" class="headerlink" title="select"></a>select</h4><p>select()函数会在某个或某些套接字的状态从不可读变为可读、或不可写变为可写的时候通知服务器主进程。所以select()本身的调用是阻塞的。但是具体哪一个套接字或哪些套接字变为可读或可写我们是不知道的，所以我们需要遍历所有select()返回的套接字来判断哪些套接字可以进行处理了。</p><p>但是，select()函数本身的调用阻塞的。因为select()需要一直等到有状态变化的套接字之后（比如监听套接字或者连接套接字的状态由不可读变为可读），才能解除select()本身的阻塞，继续对读写就绪的套接字进行处理。虽然这里是阻塞的，但是它能够同时返回多个就绪的套接字，而不是之前单进程中只能够处理一个套接字，大大提升了效率</p><p>优点：</p><ul><li>实现了对多个套接字的同时、集中管理</li><li>通过遍历所有的套接字集合，能够获取所有已就绪的套接字，对这些就绪的套接字进行操作不会阻塞</li></ul><p>缺点：</p><ul><li>select管理的套接字描述符们存在数量限制。在Unix中，一个进程最多同时监听1024个套接字描述符</li><li>select返回的时候，并不知道具体是哪个套接字描述符已经就绪，所以需要遍历所有套接字来判断哪个已经就绪，可以继续进行读写</li></ul><h4 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h4><p><b>poll解决了select带来的套接字描述符的最大数量限制问题</b></p><p>poll的fds参数集合了select的read、write和exception套接字数组，合三为一。poll中的fds没有了1024个的数量限制。当有些描述符状态发生变化并就绪之后，poll同select一样会返回。但是遗憾的是，我们同样不知道具体是哪个或哪些套接字已经就绪，我们仍需要遍历套接字集合去判断究竟是哪个套接字已经就绪，这一点并没有解决刚才提到select的第二个问题。</p><h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><p>epoll是最先进的套接字管理员，解决了上述select和poll中所存在的问题。它将一个阻塞的select、poll系统调用拆分成了三个步骤。一次select或poll可以看作是由一次 epoll_create、若干次 epoll_ctl、若干次 epoll_wait构成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int epoll_create(int size);</span><br><span class="line">int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；</span><br><span class="line">int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);</span><br></pre></td></tr></table></figure></p><ul><li>epoll_create()：创建一个epoll实例。后续操作会使用</li><li>epoll_ctl()：对套接字描述符集合进行增删改操作，并告诉内核需要监听套接字描述符的什么事件</li><li>epoll_wait()：等待监听列表中的连接事件（监听套接字描述符才会发生）或读写事件（连接套接字描述符才会发生）。如果有某个或某些套接字事件已经准备就绪，就会返回这些已就绪的套接字们</li></ul><p>我们调用epoll_wait()等待连接或读写等事件，在某个套接字描述符上准备就绪。当有事件准备就绪之后，会存到第二个参数epoll_event结构体中。通过访问这个结构体就可以得到所有已经准备好事件的套接字描述符。这里就不用再像之前select和poll那样，遍历所有的套接字描述符之后才能知道究竟是哪个描述符已经准备就绪了，这样减少了一次O(n)的遍历，大大提高了效率。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;网络编程概念&quot;&gt;&lt;a href=&quot;#网络编程概念&quot; class=&quot;headerlink&quot; title=&quot;网络编程概念&quot;&gt;&lt;/a&gt;网络编程概念&lt;/h2&gt;&lt;p&gt;在网络当中，数据的传输是基于HTTP/TCP协议簇来实现的。TCP协议仅仅是把这些数据看做是一串二进制流来进行处理。&lt;br&gt;所以：&lt;b&gt;客户端和服务器是通过在建立的连接上发送字节流来进行通信&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;一个连接由它两端的套接字地址唯一确定，结构为&lt;code&gt;(客户端地址:客户端端口号，服务端地址:服务端端口号)&lt;/code&gt;。有了通信双方的连接地址信息后，就可以进行数据传输了。&lt;/p&gt;
&lt;p&gt;在Unix系统中，实现了一套套接字接口来描述和规范双方通信的整个过程。&lt;br&gt;创建-&amp;gt;连接-&amp;gt;绑定-&amp;gt;监听-&amp;gt;响应&lt;br&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwgy1galrpl667mj30hs0dzwfp.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;socket()：创建一个套接字描述符&lt;/li&gt;
&lt;li&gt;connect()：客户端通过调用connect函数来建立和服务器的连接&lt;/li&gt;
&lt;li&gt;bind()：告诉内核将socket()创建的套接字与某个服务端地址与端口连接起来，后续会对这个地址和端口进行监听&lt;/li&gt;
&lt;li&gt;listen()：告诉内核，将这个套接字当成服务器这种被动实体来看待(服务器是等待客户端连接的被动实体，而内核认为socket()创建的套接字默认是主动实体，所以才需要listen()函数，告诉内核进行主动到被动实体的转换)&lt;/li&gt;
&lt;li&gt;accept()：等待客户端的连接请求并返回一个新的已连接描述符&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>提问的智慧</title>
    <link href="http://yoursite.com/2020/01/05/new/other/%E6%8F%90%E9%97%AE%E7%9A%84%E6%99%BA%E6%85%A7/"/>
    <id>http://yoursite.com/2020/01/05/new/other/提问的智慧/</id>
    <published>2020-01-05T05:40:58.000Z</published>
    <updated>2020-01-05T05:46:49.081Z</updated>
    
    <content type="html"><![CDATA[<h1 id="在你提问之前"><a href="#在你提问之前" class="headerlink" title="在你提问之前"></a>在你提问之前</h1><ul><li>尝试在你准备提问的论坛的旧文章中搜索答案</li><li>尝试上网搜索以找到答案</li><li>尝试阅读手册以找到答案</li><li>尝试阅读常见问题文件（FAQ）以找到答案</li><li>尝试自己检查或试验以找到答案</li><li>向你身边的强者朋友打听以找到答案</li><li>如果你是程序开发者，请尝试阅读源代码以找到答案</li></ul><h1 id="当你提问时"><a href="#当你提问时" class="headerlink" title="当你提问时"></a>当你提问时</h1><ul><li>慎选提问的论坛</li><li>Stack Overflow</li><li>网站和 IRC 论坛</li><li>第二步，使用项目邮件列表</li><li>使用有意义且描述明确的标题</li><li>使问题容易回复</li><li>用清晰、正确、精准并合法语法的语句</li><li>使用易于读取且标准的文件格式发送问题</li><li>精确地描述问题并言之有物</li><li>话不在多而在精</li><li>别动辄声称找到 Bug</li><li>低声下气不能代替你的功课</li><li>描述问题症状而非你的猜测</li><li>按发生时间先后列出问题症状</li><li>描述目标而不是过程</li><li>别要求使用私人电邮回复</li><li>清楚明确的表达你的问题以及需求</li><li>询问有关代码的问题时</li><li>别把自己家庭作业的问题贴上来</li><li>去掉无意义的提问句</li><li>即使你很急也不要在标题写紧急</li><li>礼多人不怪，而且有时还很有帮助</li><li>问题解决后，加个简短的补充说明</li></ul><p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1galmxel3nqj30u00vk43j.jpg" alt=""></p><blockquote><p><a href="https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way" target="_blank" rel="noopener">原文地址</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;在你提问之前&quot;&gt;&lt;a href=&quot;#在你提问之前&quot; class=&quot;headerlink&quot; title=&quot;在你提问之前&quot;&gt;&lt;/a&gt;在你提问之前&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;尝试在你准备提问的论坛的旧文章中搜索答案&lt;/li&gt;
&lt;li&gt;尝试上网搜索以找到答案&lt;/li&gt;
&lt;
      
    
    </summary>
    
      <category term="生活杂记" scheme="http://yoursite.com/categories/%E7%94%9F%E6%B4%BB%E6%9D%82%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>听《工作三年我学到了什么》总结</title>
    <link href="http://yoursite.com/2020/01/05/new/other/%E5%90%AC%E3%80%8A%E5%B7%A5%E4%BD%9C%E4%B8%89%E5%B9%B4%E6%88%91%E5%AD%A6%E5%88%B0%E4%BA%86%E4%BB%80%E4%B9%88%E3%80%8B%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2020/01/05/new/other/听《工作三年我学到了什么》总结/</id>
    <published>2020-01-04T16:53:03.000Z</published>
    <updated>2020-01-04T16:54:59.543Z</updated>
    
    <content type="html"><![CDATA[<p>最近听到一篇文章，觉得其中很多的点给了我很多收获。所以反复听了很多遍，并做了大概的总结。关键词：沟通、尝试、上升、思考、落地。</p><ul><li>不要把自己局限于某一个位置，试着多尝试不同的东西，“管理”好自己,“管理”好身边的人。</li><li>你的技术能力决定了你能多快去完成目标。而你的非技术能力决定了你在朝哪个方向努力。</li></ul><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakzw4xmkcj30u00ubn5h.jpg" alt=""></p><a id="more"></a><p>总的来说，就是站在不同角色的角度来看待事情，思他人之所思。(领导、依赖人、客户、被求助者、被依赖人)</p><h2 id="向上管理"><a href="#向上管理" class="headerlink" title="向上管理"></a>向上管理</h2><p>在工作当中，我们经常都是领导分配什么任务，我们就去努力完成任务。<br>而没有去思考这个任务到底能不能胜任，有没有更适合去做这个任务的人，以及更适合自己的任务却被分配给了其他的人。<br><b>领导是一个统筹管理的角色</b>，他大多时候只会关注总体任务是否完成。而没在意谁完成，怎么完成。</p><p><font color="red">我们应该站在领导的角度上去思考整个项目任务</font>当我们遇到不合理任务时，及时表达自己的想法和看法，看是否存在更好解决方案。<br>一个适合自己的任务，不仅能够节省大量完成任务的时间，还能保证完成的质量。</p><p>当然，在更多时候人手并不是很充足，所以并不是说一味的去拒绝任务；完成任务仍然是第一优先级，只有在完成任务的基础上，才能去发表和实现自己的想法。</p><h2 id="沟通先行"><a href="#沟通先行" class="headerlink" title="沟通先行"></a>沟通先行</h2><p>在整个项目流程当中，我们会遇到很多依赖别人的点。我们尽量在到达这个点之间就提前跟相关依赖人沟通，确定资源，而不是在需要的时候才去申请资源。</p><h2 id="高效会议"><a href="#高效会议" class="headerlink" title="高效会议"></a>高效会议</h2><p>在参加会议前，我们需要明确自己在其中的角色、需要了解、表达的东西。明确需要沟通的相关人员及其负责部分。<br>在会议当中，我们需要准确的提出自己的问题以及看法，避免形成沟通黑洞。<br>会议之后，需要及时记录会议记录，避免忘记。不同紧急程度的任务可以采用不同的方式去联系相关人员。</p><h2 id="上升意识"><a href="#上升意识" class="headerlink" title="上升意识"></a>上升意识</h2><p>不要将自己的角色给限制死，需要时常的跳出去，从不同的维度发展自己。不断的去尝试边界，并尝试突破。<br>主动的去发现项目的风险点、改进点。多从其他人手中争取锻炼自己的机会。</p><blockquote><p><a href="https://pythonhunter.org/episodes/sp02" target="_blank" rel="noopener">原文：https://pythonhunter.org/episodes/sp02</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近听到一篇文章，觉得其中很多的点给了我很多收获。所以反复听了很多遍，并做了大概的总结。关键词：沟通、尝试、上升、思考、落地。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不要把自己局限于某一个位置，试着多尝试不同的东西，“管理”好自己,“管理”好身边的人。&lt;/li&gt;
&lt;li&gt;你的技术能力决定了你能多快去完成目标。而你的非技术能力决定了你在朝哪个方向努力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwgy1gakzw4xmkcj30u00ubn5h.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="生活杂记" scheme="http://yoursite.com/categories/%E7%94%9F%E6%B4%BB%E6%9D%82%E8%AE%B0/"/>
    
    
      <category term="思考" scheme="http://yoursite.com/tags/%E6%80%9D%E8%80%83/"/>
    
      <category term="总结" scheme="http://yoursite.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>JB全家桶激活教程</title>
    <link href="http://yoursite.com/2020/01/04/new/other/JB%E5%85%A8%E5%AE%B6%E6%A1%B6%E6%BF%80%E6%B4%BB%E6%95%99%E7%A8%8B/"/>
    <id>http://yoursite.com/2020/01/04/new/other/JB全家桶激活教程/</id>
    <published>2020-01-04T04:31:38.000Z</published>
    <updated>2020-01-04T04:32:26.238Z</updated>
    
    <content type="html"><![CDATA[<ul><li>本教程适用于jetbrains全家桶开发工具（Pycharm、Idea、WebStorm、phpstorm、CLion、RubyMine、AppCode、DataGrid）</li><li>本教程适用于所有版本</li><li>软件直接从官网下载即可</li><li>不需要修改host</li></ul><h2 id="激活教程"><a href="#激活教程" class="headerlink" title="激活教程"></a>激活教程</h2><h3 id="1-下载破解补丁"><a href="#1-下载破解补丁" class="headerlink" title="1. 下载破解补丁"></a>1. 下载破解补丁</h3><p>下载补丁文件：<a href="https://pan.baidu.com/s/1Kc-byjcH_pvrN4CTgfKSFA" target="_blank" rel="noopener">jetbrains-agent.jar</a><br>文件保存位置可以任意，建议放置到软件安装路径的bin目录下。避免误删文件。</p><a id="more"></a><h3 id="2-点击试用"><a href="#2-点击试用" class="headerlink" title="2. 点击试用"></a>2. 点击试用</h3><p>如果你是刚下载的IDEA，则需要点击激活窗口的“Evaluate for free”免费试用，然后再创建一个空项目，这样就可以进入到IDEA的工作页面<br><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gaketkrmc0j30su0aigmp.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakeuydlulj30zw0u0ahk.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakev1f4tcj314a0qojty.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakev6d8cxj314a0qo0ux.jpg" alt=""></p><h3 id="3-修改配置文件"><a href="#3-修改配置文件" class="headerlink" title="3. 修改配置文件"></a>3. 修改配置文件</h3><p><font color="red"> 配置文件修改已经不在bin目录下直接修改，而是通过IDEA修改</font><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakexpa10mj31100qs0uc.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakextkszmj31c60u0jvx.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakexxczvlj31c60u076b.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakeyew4ilj31c60u0tb5.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakeyicahmj31hc0sktcn.jpg" alt=""></p><p>进入到项目界面后，点击IDEA最上面的菜单栏中的 “Help” -&gt; “Edit Custom VM Options …”<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakeyw6muqj31gf0u0n2b.jpg" alt=""></p><p>如果提示是否要创建文件，请点”Yes”。</p><p>在打开的vmoptions编辑窗口末行添加：<font color="red"> -javaagent:你IDEA的安装目录\jetbrains-agent.jar</font> 请仔细检查补丁路径是否正确，如果错误则会出现IDEA打不开的情况。<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakezxp1tij31hc0tsq8e.jpg" alt=""><br><b>修改完配置文件之后切记重启IDEA软件</b></p><p>如果修改完打不开软件，或者提示没有jdk等问题，这时候可以删除用户目录下的IDEA文件夹，注意这个文件夹是隐藏目录！<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">windwos：C:\Users\用户名\</span><br><span class="line">macos：~/Library/Preferences/</span><br><span class="line">ubuntu：~/.</span><br></pre></td></tr></table></figure></p><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakf0tyctij31gd0u046p.jpg" alt=""></p><h3 id="4-输入激活码"><a href="#4-输入激活码" class="headerlink" title="4. 输入激活码"></a>4. 输入激活码</h3><p>修改完配置文件之后重启IDEA，点击菜单栏中的 “Help” -&gt; “Register …”<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakf1mhjaaj31ga0u0jyg.jpg" alt=""></p><p>选择最后一种License server激活方式，地址填入：<a href="http://jetbrains-license-server" target="_blank" rel="noopener">http://jetbrains-license-server</a> （应该会自动填上），或者点击按钮：”Discover Server”来自动填充地址，完成激活。</p><p>注意：服务器激活需要联网！<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakf2mn7tdj31hc0tr438.jpg" alt=""></p><p>如果服务器激活方式无法激活，还可以选择Activation code方式激活，复制下面激活码即可<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakf3hatfwj314a0qogrb.jpg" alt=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JQE11SV0BR-eyJsaWNlbnNlSWQiOiJKUUUxMVNWMEJSIiwibGljZW5zZWVOYW1lIjoicGlnNiIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IklJIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkFDIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRQTiIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJQUyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJHTyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJETSIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJDTCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSUzAiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUkMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUkQiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUEMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUk0iLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiV1MiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREIiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlNVIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9XSwiaGFzaCI6IjEyNzk2ODc3LzAiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-khgsQrnDiglknF0m+yyoYGJXX4vFE3IIVaoMd0bkpfAlMiYM4FUK1JM7uMnVSN0NBC7qtZjYlNzPscEyKE8634uGuY/uToFQnIOCtyUfBxB6j0wF/DcCjhKMNDbnJ1RKZ2VaALuC9B6d6lhtEKm9+urXWTBq7h2VfIBv5wk1Ul9T/m9Dwkz/LccTqnxO0PP288fF13ZbmcLI1/D0dqp/QxYshW6CLR+2Tvk6QCPoaOTKDU/eL1AssD7/mO1g2ZJA+k//8qfRMLgdLmLrMdyiaIhrsM/jJk2qDfTaMcCNylkWXLgKwSvEQG95IhitLN9+GQ4pBW3gOTNl82Gem7jEkA==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG/PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg/nYV31HLF7fJUAplI/1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4/G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd/GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt/wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59/THOT7NJQhr6AyLkhhJCdkzE2cob/KouVp4ivV7Q3Fc6HX7eepHAAF/DpxwgOrg9smX6coXLgfp0b1RU2u/tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB/40BjpMUrDRCeKuiBahC0DCoU/4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV/g==</span><br></pre></td></tr></table></figure></p><h3 id="5-查看有效期"><a href="#5-查看有效期" class="headerlink" title="5. 查看有效期"></a>5. 查看有效期</h3><p>当你激活完毕后，IDEA右下角会有个Registration小长条提示框，大致的内容为：You copy is Licensed to XXX意思就会告诉你：兄弟，你已经激活成功了，激活码的许可来源是：XXX。<br>查看有效期的步骤为点击：Help-&gt;About这里可以看到你的IDEA的版本号、许可来源、有效期、以及一些环境<br>服务器激活是没有期限的，即为永久有效<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gakf4dn7abj31hc0th44m.jpg" alt=""></p><blockquote><p>资源来源：<br><a href="https://zhile.io/" target="_blank" rel="noopener">https://zhile.io/</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;本教程适用于jetbrains全家桶开发工具（Pycharm、Idea、WebStorm、phpstorm、CLion、RubyMine、AppCode、DataGrid）&lt;/li&gt;
&lt;li&gt;本教程适用于所有版本&lt;/li&gt;
&lt;li&gt;软件直接从官网下载即可&lt;/li&gt;
&lt;li&gt;不需要修改host&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;激活教程&quot;&gt;&lt;a href=&quot;#激活教程&quot; class=&quot;headerlink&quot; title=&quot;激活教程&quot;&gt;&lt;/a&gt;激活教程&lt;/h2&gt;&lt;h3 id=&quot;1-下载破解补丁&quot;&gt;&lt;a href=&quot;#1-下载破解补丁&quot; class=&quot;headerlink&quot; title=&quot;1. 下载破解补丁&quot;&gt;&lt;/a&gt;1. 下载破解补丁&lt;/h3&gt;&lt;p&gt;下载补丁文件：&lt;a href=&quot;https://pan.baidu.com/s/1Kc-byjcH_pvrN4CTgfKSFA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jetbrains-agent.jar&lt;/a&gt;&lt;br&gt;文件保存位置可以任意，建议放置到软件安装路径的bin目录下。避免误删文件。&lt;/p&gt;
    
    </summary>
    
      <category term="软件" scheme="http://yoursite.com/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    
      <category term="破解教程" scheme="http://yoursite.com/tags/%E7%A0%B4%E8%A7%A3%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>pika学习之数据结构篇</title>
    <link href="http://yoursite.com/2019/12/29/new/pika/pika%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AF%87/"/>
    <id>http://yoursite.com/2019/12/29/new/pika/pika学习之数据结构篇/</id>
    <published>2019-12-29T15:58:59.000Z</published>
    <updated>2019-12-29T16:00:07.049Z</updated>
    
    <content type="html"><![CDATA[<p>pika的持久化存储模块称为nemo存储引擎，其本质上是对rocksDB(只支持KV存储)的改造和封装。使其支持多数据结构的存储。<br>pika作为类redis数据库，所以肯定得兼容redis最基本的五种数据结构：string、hash、list、set、zset。 </p><h2 id="KV存储"><a href="#KV存储" class="headerlink" title="KV存储"></a>KV存储</h2><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae07se7opj30k204tq33.jpg" alt=""><br>KV存储作为rocksDB原生支持的存储方式，所以并没有做太多的处理。仅仅只是在value的结尾加上8个字节的附加信息(前4个字节表示version，后4个字节表示ttl)。<br>version字段用于对该键值对进行标记，以便后续处理，如删除一个键值对时，可以在该version进行标记，后续再进行真正的删除，这样可以减少删除操作造成的服务阻塞时间。</p><h2 id="Hash存储"><a href="#Hash存储" class="headerlink" title="Hash存储"></a>Hash存储</h2><p>对于每一个Hash结构，它都包含hash键(key)、域名(field)、值(value)。<br>nome的存储方式是将key和field组合成为一个新的key，将这个新生成的key与要存储的value组成最终落盘的kv键值对。<br>对于每一个hash键，nome还为它添加了一个存储元数据信息的落盘kv，它保存的是对应hash键下的所有域值对的个数。<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae07pcssxj30jx04y0t0.jpg" alt=""></p><ul><li>左图字段保存的是hash键的对象，它由标记位+key+version+ttl组成</li><li>右图字段仅仅只保存一个数字，表示该hash下field的数量</li></ul><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae0docgmtj30rg06iq3b.jpg" alt=""><br>上图表示nome对传统hash结构转换成kv结构的拆分存储模式。</p><ul><li>k结构部分由标记位+长度+key+field组成。size表示的是hash键key的长度。</li><li>v结构部分就由具体的value+version+ttl组成。<a id="more"></a></li></ul><h2 id="List存储"><a href="#List存储" class="headerlink" title="List存储"></a>List存储</h2><p>每个List结构的底层存储也是采用链表结构来完成，对于每个List键，它的每个元素都落盘成一个kv键值对。<br>和Hash结构一样，每个List也需要拥有一个它的元素信息结构。<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae0oa3gxuj30m806mjrq.jpg" alt=""></p><ul><li>List的key存储和hash的一样，只有标记位不一样而已。</li><li>value则存储了List的元数据信息，它有四个字段，从前到后分别为该List键内的元素个数、最左边元素节点的sequence(表头)、最右边元素节点的sequence(表尾)、下一个插入元素节点应该使用的sequence。</li></ul><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae0oe8d2tj30qx06mq3b.jpg" alt=""></p><ul><li>k结构部分由标记位+长度+key+sequence组成。size表示的是hash键key的长度。</li><li>v结构部分由前一个元素的sequence+后一个元素的sequence+value+version+ttl组成。从而实现了一个双向链表的结构。</li></ul><h2 id="Set存储"><a href="#Set存储" class="headerlink" title="Set存储"></a>Set存储</h2><p>Set，本质上就是一个value值为nil的Hash结构。在Java和Redis中，都是利用hashtable来实现的。nome并没有做什么特殊处理，只是在存储value时，只保存了version和ttl结构。<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae10jcgjdj30lw06oglt.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae10oq2i8j30kw06mq35.jpg" alt=""></p><h2 id="Zset存储"><a href="#Zset存储" class="headerlink" title="Zset存储"></a>Zset存储</h2><p>Zset就是一个有序的Set结构，所以对于每个元素，增加了一个scope值。把该元素对应的score值整合进去，这样便于依据Score值进行排序（因为从rocksdb内拿出的数据时按键排序的）<br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae13azcgrj30ii068q33.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae13e4n73j30oa068wep.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gae13hlow6j30oa068wep.jpg" alt=""><br>score是从double类型转变过来的int64_t类型，这样做是为了可以让原来的浮点型的score直接参与到字符串的排序当中（浮点型的存储格式与字符串的比较方式不兼容）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;pika的持久化存储模块称为nemo存储引擎，其本质上是对rocksDB(只支持KV存储)的改造和封装。使其支持多数据结构的存储。&lt;br&gt;pika作为类redis数据库，所以肯定得兼容redis最基本的五种数据结构：string、hash、list、set、zset。 &lt;/p&gt;
&lt;h2 id=&quot;KV存储&quot;&gt;&lt;a href=&quot;#KV存储&quot; class=&quot;headerlink&quot; title=&quot;KV存储&quot;&gt;&lt;/a&gt;KV存储&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwgy1gae07se7opj30k204tq33.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;KV存储作为rocksDB原生支持的存储方式，所以并没有做太多的处理。仅仅只是在value的结尾加上8个字节的附加信息(前4个字节表示version，后4个字节表示ttl)。&lt;br&gt;version字段用于对该键值对进行标记，以便后续处理，如删除一个键值对时，可以在该version进行标记，后续再进行真正的删除，这样可以减少删除操作造成的服务阻塞时间。&lt;/p&gt;
&lt;h2 id=&quot;Hash存储&quot;&gt;&lt;a href=&quot;#Hash存储&quot; class=&quot;headerlink&quot; title=&quot;Hash存储&quot;&gt;&lt;/a&gt;Hash存储&lt;/h2&gt;&lt;p&gt;对于每一个Hash结构，它都包含hash键(key)、域名(field)、值(value)。&lt;br&gt;nome的存储方式是将key和field组合成为一个新的key，将这个新生成的key与要存储的value组成最终落盘的kv键值对。&lt;br&gt;对于每一个hash键，nome还为它添加了一个存储元数据信息的落盘kv，它保存的是对应hash键下的所有域值对的个数。&lt;br&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwgy1gae07pcssxj30jx04y0t0.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;左图字段保存的是hash键的对象，它由标记位+key+version+ttl组成&lt;/li&gt;
&lt;li&gt;右图字段仅仅只保存一个数字，表示该hash下field的数量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwgy1gae0docgmtj30rg06iq3b.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;上图表示nome对传统hash结构转换成kv结构的拆分存储模式。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;k结构部分由标记位+长度+key+field组成。size表示的是hash键key的长度。&lt;/li&gt;
&lt;li&gt;v结构部分就由具体的value+version+ttl组成。
    
    </summary>
    
      <category term="Pika" scheme="http://yoursite.com/categories/Pika/"/>
    
    
      <category term="Pika" scheme="http://yoursite.com/tags/Pika/"/>
    
  </entry>
  
  <entry>
    <title>redis复制过程演变</title>
    <link href="http://yoursite.com/2019/12/29/new/Redis/redis%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B%E6%BC%94%E5%8F%98/"/>
    <id>http://yoursite.com/2019/12/29/new/Redis/redis复制过程演变/</id>
    <published>2019-12-29T14:19:06.000Z</published>
    <updated>2019-12-29T14:21:46.576Z</updated>
    
    <content type="html"><![CDATA[<p>Redis的主从复制主要经历以下的几个阶段：</p><ol><li>2.8版本以下—-sync</li><li>2.8-4.0版本—-psync</li><li>4.0版本+ —-psync2</li></ol><p>下面我就来简单的讲讲Redis主从复制的演变过程。</p><h2 id="Redis主从复制过程"><a href="#Redis主从复制过程" class="headerlink" title="Redis主从复制过程"></a>Redis主从复制过程</h2><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gadwq7etd2j31r50u0464.jpg" alt=""></p><ul><li>客户端发送slaveof命令给Redis实例</li><li>准备阶段函数为<code>replicationSetMaster</code>，这个函数主要会做一些复制之前的数据和状态清理工作。</li><li>更新server.master</li><li>将实例状态修改为REPL_STATE_CONNECT<a id="more"></a><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gadwqm9ps9j31pc0u045z.jpg" alt=""><br><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gadxodwcpuj31pf0u0dns.jpg" alt=""><br>Redis每秒会调用一次<code>replicationCron</code>定时任务。根据Redis当前所处状态来决定下一步操作。</li><li>当Redis状态为<code>REPL_STATE_CONNECT</code>时会调用<code>connectWithMaster</code>创建连接master事件。该函数会将Redis状态修改为<code>REPL_STATE_CONNECTING</code></li><li>接下来进行心跳检查、权限校验等操作</li><li>master接收到slave的复制命令后，就会触发一次rdb全备，并记录下全备期间的命令。</li><li>master将全备文件发送给slave后，将增量命令发送给slave。</li><li>心跳维持和持续复制</li></ul><h2 id="主从复制的演变"><a href="#主从复制的演变" class="headerlink" title="主从复制的演变"></a>主从复制的演变</h2><p>在2.8之前的版本中，如果由于网络等原因导致主从复制断开。那么就会将从节点状态修改为<code>REPL_STATE_CONNECTING</code>。进而会重新进行全量同步流程。</p><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gadxz7g5aoj31rq0gcju1.jpg" alt=""><br>在2.8版本中，Redis增加了psync命令，并且增加了一个复制积压缓冲区的数据结构（默认为1M）。<br>复制积压缓冲区是一个环形的结构，保存了最近可用的写命令数据。<br>在<code>replicationCron</code>定时任务中每秒发送一个<code>REPLCONF ACK OFFSET</code>命令将自身的偏移量信息发送给master，如果offset的命令在复制积压缓冲区中，那么说明增量数据是可用的。就没必要进行全量同步，直接将复制积压缓冲区中的增量数据发送给slave就可以了。</p><p>在redis4.0+版本中又引进了psync2命令来避免一些特殊场景(主从架构、级联架构)下发生主从切换后不必要的全量同步操作。<br>将一组replid和offset给增加成为两组。主要用来记录上一次复制中主实例的runid值。然后在slaveof时判断是否有必要进行全量同步操作。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">replid1：</span><br><span class="line">主节点：自身的replid和offset</span><br><span class="line">从节点：主节点的replid和offset</span><br><span class="line"></span><br><span class="line">replid2:</span><br><span class="line">上一次主实例的replid和offset</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis的主从复制主要经历以下的几个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;2.8版本以下—-sync&lt;/li&gt;
&lt;li&gt;2.8-4.0版本—-psync&lt;/li&gt;
&lt;li&gt;4.0版本+ —-psync2&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下面我就来简单的讲讲Redis主从复制的演变过程。&lt;/p&gt;
&lt;h2 id=&quot;Redis主从复制过程&quot;&gt;&lt;a href=&quot;#Redis主从复制过程&quot; class=&quot;headerlink&quot; title=&quot;Redis主从复制过程&quot;&gt;&lt;/a&gt;Redis主从复制过程&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/006tNbRwgy1gadwq7etd2j31r50u0464.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端发送slaveof命令给Redis实例&lt;/li&gt;
&lt;li&gt;准备阶段函数为&lt;code&gt;replicationSetMaster&lt;/code&gt;，这个函数主要会做一些复制之前的数据和状态清理工作。&lt;/li&gt;
&lt;li&gt;更新server.master&lt;/li&gt;
&lt;li&gt;将实例状态修改为REPL_STATE_CONNECT
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>浅析GeoHash</title>
    <link href="http://yoursite.com/2019/12/26/new/Redis/%E6%B5%85%E6%9E%90GeoHash/"/>
    <id>http://yoursite.com/2019/12/26/new/Redis/浅析GeoHash/</id>
    <published>2019-12-26T12:16:58.000Z</published>
    <updated>2019-12-29T16:03:59.377Z</updated>
    
    <content type="html"><![CDATA[<p>GeoHash算法能够将二维的经纬度转换成字符串。主要有以下几个特性:</p><ol><li>每一个字符串代表了某一矩形区域.</li><li>字符串的长度越长，所表示的位置越精确。</li><li>字符串越相近的表示的举例越接近.</li></ol><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>GeoHash将经纬度转换为hash字符串主要分为三步：</p><ol><li>将纬度(-90, 90)平均分成两个区间(-90, 0)、(0, 90)，如果坐标位置的纬度值在第一区间，则编码是0，否则编码为1</li><li>经纬度的编码合并，从0开始，奇数为是纬度，偶数为是经度</li><li>对经纬度合并后的编码，进行base32编码</li></ol><p>大概过程如下图，不断的对经纬度进行切割，直到精准度达到要求。<br><img src="https://user-gold-cdn.xitu.io/2018/7/4/1646397a223e2019?imageslim" alt="IMAGE"></p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><blockquote><p>将经纬度转换成二进制编码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">private void convert(double min, double max, double value, List&lt;Character&gt; list) &#123;</span><br><span class="line">        if (list.size() &gt; (length - 1)) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        double mid = (max + min) / 2;</span><br><span class="line">        if (value &lt; mid) &#123;</span><br><span class="line">            list.add(&apos;0&apos;);</span><br><span class="line">            convert(min, mid, value, list);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            list.add(&apos;1&apos;);</span><br><span class="line">            convert(mid, max, value, list);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p></blockquote><a id="more"></a><blockquote><p>合并经纬度的二进制编码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Character&gt; latList = new ArrayList&lt;Character&gt;();</span><br><span class="line">List&lt;Character&gt; lngList = new ArrayList&lt;Character&gt;();</span><br><span class="line">convert(Min_Lat, Max_Lat, lat, latList);</span><br><span class="line">convert(Min_Lng, Max_Lng, lng, lngList);</span><br><span class="line">StringBuilder sb = new StringBuilder();</span><br><span class="line">for (int index = 0; index &lt; latList.size(); index++) &#123;</span><br><span class="line">    sb.append(lngList.get(index)).append(latList.get(index));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>base32编码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">private final String[] base32Lookup =</span><br><span class="line">            &#123;&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;, &quot;9&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;,</span><br><span class="line">                    &quot;j&quot;, &quot;k&quot;, &quot;m&quot;, &quot;n&quot;, &quot;p&quot;, &quot;q&quot;, &quot;r&quot;, &quot;s&quot;, &quot;t&quot;, &quot;u&quot;, &quot;v&quot;, &quot;w&quot;, &quot;x&quot;, &quot;y&quot;, &quot;z&quot;&#125;;</span><br><span class="line">    private String base32Encode(final String str) &#123;</span><br><span class="line">        String unit = &quot;&quot;;</span><br><span class="line">        StringBuilder sb = new StringBuilder();</span><br><span class="line">        for (int start = 0; start &lt; str.length(); start = start + 5) &#123;</span><br><span class="line">            unit = str.substring(start, start + 5);</span><br><span class="line">            sb.append(base32Lookup[convertToIndex(unit.split(&quot;&quot;))]);</span><br><span class="line">        &#125;</span><br><span class="line">        return sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line">    private int convertToIndex(String str) &#123;</span><br><span class="line">        int length = str.length();</span><br><span class="line">        int result = 0;</span><br><span class="line">        for (int index = 0; index &lt; length; index++) &#123;</span><br><span class="line">            result += str.charAt(index) == &apos;0&apos; ? 0 : 1 &lt;&lt; (length - 1 - index);</span><br><span class="line">        &#125;</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="Redis中的Geo使用"><a href="#Redis中的Geo使用" class="headerlink" title="Redis中的Geo使用"></a>Redis中的Geo使用</h2><p>在Redis中，Geo的内部结构实际上是一个zset。<br>Redis提供给Geo指定只有6个，但是它可以使用zset的所有指令。</p><h3 id="增加-geoadd"><a href="#增加-geoadd" class="headerlink" title="增加-geoadd"></a>增加-geoadd</h3><p>geoadd指令传入多个经纬度名称三元组，Redis内存会调用函数计算出相应的geohash字符串。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geoadd company 116.48105 39.996794 juejin</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.514203 39.905409 ireader</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.489033 40.007669 meituan</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.562108 39.787602 jd 116.334255 40.027400 xiaomi</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure></p><h3 id="距离-geodist"><a href="#距离-geodist" class="headerlink" title="距离-geodist"></a>距离-geodist</h3><p>geodist 指令可以用来计算两个元素之间的距离，携带集合名称、2 个名称和距离单位。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geodist company juejin ireader km</span><br><span class="line">&quot;10.5501&quot;</span><br><span class="line">127.0.0.1:6379&gt; geodist company juejin meituan km</span><br><span class="line">&quot;1.3878&quot;</span><br><span class="line">127.0.0.1:6379&gt; geodist company juejin jd km</span><br><span class="line">&quot;24.2739&quot;</span><br><span class="line">127.0.0.1:6379&gt; geodist company juejin xiaomi km</span><br><span class="line">&quot;12.9606&quot;</span><br><span class="line">127.0.0.1:6379&gt; geodist company juejin juejin km</span><br><span class="line">&quot;0.0000&quot;</span><br></pre></td></tr></table></figure></p><h3 id="获取元素位置-geopos"><a href="#获取元素位置-geopos" class="headerlink" title="获取元素位置-geopos"></a>获取元素位置-geopos</h3><p>geopos 指令可以获取集合中任意元素的经纬度坐标，可以一次获取多个。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geopos company juejin</span><br><span class="line">1) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">   2) &quot;39.99679348858259686&quot;</span><br><span class="line">127.0.0.1:6379&gt; geopos company ireader</span><br><span class="line">1) 1) &quot;116.5142020583152771&quot;</span><br><span class="line">   2) &quot;39.90540918662494363&quot;</span><br><span class="line">127.0.0.1:6379&gt; geopos company juejin ireader</span><br><span class="line">1) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">   2) &quot;39.99679348858259686&quot;</span><br><span class="line">2) 1) &quot;116.5142020583152771&quot;</span><br><span class="line">   2) &quot;39.90540918662494363&quot;</span><br></pre></td></tr></table></figure></p><h3 id="获取元素的-hash-值-geohash"><a href="#获取元素的-hash-值-geohash" class="headerlink" title="获取元素的 hash 值-geohash"></a>获取元素的 hash 值-geohash</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geohash company ireader</span><br><span class="line">1) &quot;wx4g52e1ce0&quot;</span><br><span class="line">127.0.0.1:6379&gt; geohash company juejin</span><br><span class="line">1) &quot;wx4gd94yjn0&quot;</span><br></pre></td></tr></table></figure><h3 id="附近元素-georadiusbymember"><a href="#附近元素-georadiusbymember" class="headerlink" title="附近元素-georadiusbymember"></a>附近元素-georadiusbymember</h3><p>georadiusbymember 指令是最为关键的指令，它可以用来查询指定元素附近的其它元素，它的参数非常复杂。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 范围 20 公里以内最多 3 个元素按距离正排，它不会排除自身</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember company ireader 20 km count 3 asc</span><br><span class="line">1) &quot;ireader&quot;</span><br><span class="line">2) &quot;juejin&quot;</span><br><span class="line">3) &quot;meituan&quot;</span><br><span class="line"># 范围 20 公里以内最多 3 个元素按距离倒排</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember company ireader 20 km count 3 desc</span><br><span class="line">1) &quot;jd&quot;</span><br><span class="line">2) &quot;meituan&quot;</span><br><span class="line">3) &quot;juejin&quot;</span><br><span class="line"># 三个可选参数 withcoord withdist withhash 用来携带附加参数</span><br><span class="line"># withdist 很有用，它可以用来显示距离</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember company ireader 20 km withcoord withdist withhash count 3 asc</span><br><span class="line">1) 1) &quot;ireader&quot;</span><br><span class="line">   2) &quot;0.0000&quot;</span><br><span class="line">   3) (integer) 4069886008361398</span><br><span class="line">   4) 1) &quot;116.5142020583152771&quot;</span><br><span class="line">      2) &quot;39.90540918662494363&quot;</span><br><span class="line">2) 1) &quot;juejin&quot;</span><br><span class="line">   2) &quot;10.5501&quot;</span><br><span class="line">   3) (integer) 4069887154388167</span><br><span class="line">   4) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">      2) &quot;39.99679348858259686&quot;</span><br><span class="line">3) 1) &quot;meituan&quot;</span><br><span class="line">   2) &quot;11.5748&quot;</span><br><span class="line">   3) (integer) 4069887179083478</span><br><span class="line">   4) 1) &quot;116.48903220891952515&quot;</span><br><span class="line">      2) &quot;40.00766997707732031&quot;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GeoHash算法能够将二维的经纬度转换成字符串。主要有以下几个特性:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每一个字符串代表了某一矩形区域.&lt;/li&gt;
&lt;li&gt;字符串的长度越长，所表示的位置越精确。&lt;/li&gt;
&lt;li&gt;字符串越相近的表示的举例越接近.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;原理&quot;&gt;&lt;a href=&quot;#原理&quot; class=&quot;headerlink&quot; title=&quot;原理&quot;&gt;&lt;/a&gt;原理&lt;/h2&gt;&lt;p&gt;GeoHash将经纬度转换为hash字符串主要分为三步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将纬度(-90, 90)平均分成两个区间(-90, 0)、(0, 90)，如果坐标位置的纬度值在第一区间，则编码是0，否则编码为1&lt;/li&gt;
&lt;li&gt;经纬度的编码合并，从0开始，奇数为是纬度，偶数为是经度&lt;/li&gt;
&lt;li&gt;对经纬度合并后的编码，进行base32编码&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;大概过程如下图，不断的对经纬度进行切割，直到精准度达到要求。&lt;br&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/7/4/1646397a223e2019?imageslim&quot; alt=&quot;IMAGE&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;代码实现&quot;&gt;&lt;a href=&quot;#代码实现&quot; class=&quot;headerlink&quot; title=&quot;代码实现&quot;&gt;&lt;/a&gt;代码实现&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;将经纬度转换成二进制编码&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;private void convert(double min, double max, double value, List&amp;lt;Character&amp;gt; list) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if (list.size() &amp;gt; (length - 1)) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            return;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        double mid = (max + min) / 2;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        if (value &amp;lt; mid) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            list.add(&amp;apos;0&amp;apos;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            convert(min, mid, value, list);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125; else &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            list.add(&amp;apos;1&amp;apos;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            convert(mid, max, value, list);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
</feed>
