<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>OMG_By</title>
  
  <subtitle>你走与不走，路就在那里</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-01-22T15:18:49.766Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>OMG_By</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>当执行-single-transaction做逻辑备份时，遇到DDL</title>
    <link href="http://yoursite.com/2019/01/22/MySQL/mysqldump%E9%81%87%E5%88%B0DDL/"/>
    <id>http://yoursite.com/2019/01/22/MySQL/mysqldump遇到DDL/</id>
    <published>2019-01-22T12:54:48.000Z</published>
    <updated>2019-01-22T15:18:49.766Z</updated>
    
    <content type="html"><![CDATA[<p>当使用-single-transaction做逻辑备份的时候，遇到一个DDL语句会怎样？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;</span><br><span class="line">Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；</span><br><span class="line">/* other tables */</span><br><span class="line">Q3:SAVEPOINT sp;</span><br><span class="line">/* 时刻 1 */</span><br><span class="line">Q4:show create table `t1`;</span><br><span class="line">/* 时刻 2 */</span><br><span class="line">Q5:SELECT * FROM `t1`;</span><br><span class="line">/* 时刻 3 */</span><br><span class="line">Q6:ROLLBACK TO SAVEPOINT sp;</span><br><span class="line">/* 时刻 4 */</span><br><span class="line">/* other tables */</span><br></pre></td></tr></table></figure></p><a id="more"></a><p>在备份开始的时候，为了确保RR隔离级别，再设置一次RR隔离级别（Q1）</p><p>启动事务，使用WITH CONSISTENT SNAPSHOP确保语句执行完得到一个一致性视图（Q2）</p><p>设置一个保存点，这个很重要（Q3）</p><p>show create是为了拿到表结构（Q4），然后正式导数据（Q5），回滚到SAVEPOINT sp，作用是释放t1的MDL锁。</p><p>按照DDL执行的时间不同，效果不同。</p><ol><li>如果在Q4语句执行之前到达，现象：没有影响，备份拿到的是DDL后的表结构。</li><li>如果在“时刻2”到达，则表结构被改过，Q5执行的时候，报Table definition has changed，please retry transaction，现象：mysqldump终止。</li><li>如果在“时刻2”和“时刻3”之间到达，mysqldump占着t1的MDL读锁，binlog被阻塞，现象：主从延迟，知道Q6执行完成。</li><li>从“时刻4”开始，mysqldump释放MDL读锁，现象：没有影响，备份拿到的是DDL前的表结构。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当使用-single-transaction做逻辑备份的时候，遇到一个DDL语句会怎样？&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/* other tables */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Q3:SAVEPOINT sp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/* 时刻 1 */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Q4:show create table `t1`;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/* 时刻 2 */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Q5:SELECT * FROM `t1`;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/* 时刻 3 */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Q6:ROLLBACK TO SAVEPOINT sp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/* 时刻 4 */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/* other tables */&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="MYSQL45讲" scheme="http://yoursite.com/tags/MYSQL45%E8%AE%B2/"/>
    
  </entry>
  
  <entry>
    <title>索引</title>
    <link href="http://yoursite.com/2019/01/21/MySQL/%E7%B4%A2%E5%BC%95/"/>
    <id>http://yoursite.com/2019/01/21/MySQL/索引/</id>
    <published>2019-01-21T14:21:45.000Z</published>
    <updated>2019-01-22T02:20:42.787Z</updated>
    
    <content type="html"><![CDATA[<font color="red">索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。</font><h3 id="索引的常见模型"><a href="#索引的常见模型" class="headerlink" title="索引的常见模型"></a>索引的常见模型</h3><p>索引的出现时为了提高查询效率，但是实现索引的方式有很多种，所以这里也就引入了索引模型的概念。可以用来提高读写操作的数据结构有很多，这里先介绍比较简单的数据结构：哈希表和搜索树。</p><h4 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h4><p>哈希表是一种以K-V存储的数据结构，我们只要输入待查找的值，就可以找到其对应的值。哈希的思路很简单，把值放在数组里，用一个哈希函数把Key换算成一个确认的位置，然后把value放在数组的这个位置。遇到同一个位置上有很多value时，就用一个链表串起来。</p><p>哈希链表适用于只有等值查询的场景</p><h4 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h4><p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。查询的平均复杂度是O(log(N))。<br><a id="more"></a></p><h3 id="InnoDB的索引模型"><a href="#InnoDB的索引模型" class="headerlink" title="InnoDB的索引模型"></a>InnoDB的索引模型</h3><p>在InnoDB中，表都是根据主键的顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用B+树索引模型。每一个索引再InnoDB里面对应一颗B+树。</p><p>假设我们有一个主键列为ID的表，表中有字段k，并且k上有索引。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table T(</span><br><span class="line">id int primary key, </span><br><span class="line">k int not null, </span><br><span class="line">name varchar(16),</span><br><span class="line">index (k))engine=InnoDB;</span><br></pre></td></tr></table></figure></p><p>表中R1~R5的（ID、k）值分别为（100，1）、（200，2）、（300，3）、（500，5）、（600、6）<br><img src="https://m.qpic.cn/psb?/V140pON30woojR/Ei9YpCJeczWr9VO8*BgWLIHjUz30q5UyxUldf8Sp*g4!/b/dL4AAAAAAAAA&amp;bo=WgXyAwAAAAADB4w!&amp;rf=viewer_4" alt=""><br>从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。<br>主键索引的叶子节点存的是整行数据。非主键索引的叶子节点的内容是主键的值。<br>1、如果语句是select <em> from T where ID=500，即主键查询方式，则只需要搜索ID这颗B+树；<br>2、如果语句是select </em> from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID值为500，再到ID索引树搜索一次。这个过程称为回表。</p><h3 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h3><p>B+树为了维护索引的有序性，在插入新值得时候需要做必要的维护。<br>插入：</p><ul><li>当叶子节点未满时，将记录插入对应的叶子节点。</li><li>当叶子节点已满，索引页未满时；拆分中间的节点放入索引页，小于中间节点的放在左边节点，大于等于中间节点的放右边</li><li>当叶子页已满，索引页已满时；逐层拆分，直到所有节点都满足</li><li>当叶子节点的兄弟页未满，索引页已满时；不急于拆分节点，而是做旋转操作，减少页的拆分。<br>删除：<br>B+树使用填充因子来控制树的删除变化，填充因子是指数据填充的百分比。</li><li>当删除节点后，对应的叶子页大于填充因子时；直接删除节点，不做合并页操作。</li><li>当删除节点后，对应的叶子页大于填充因子，但是该节点也是索引节点；直接删除节点，将右边节点更新到对应的索引页。</li><li>当删除节点后，对应的叶子页小于填充因子时；合并页节点及其兄弟页节点。</li><li>当删除节点后，对应的叶子页小于填充因子，该节点也是索引节点；合并页节点及其兄弟页节点，更新索引页。</li><li>当删除节点后，该节点也是索引节点，并且删除该节点索引页也小于填充因子。逐层合并，直到满足条件。</li></ul><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>如果需要查询的值已经在非主键索引中可以完全获取，那么就可以不需要再去主键索引中进行回表操作了。<br><b>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</b></p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p>B+树这种索引结构，可以利用索引的”最左前缀”来定位记录。<br>为了直观的说明这个概念，我们用（name，age）这个联合索引来分析。<br><img src="https://m.qpic.cn/psb?/V140pON30woojR/jMYONpHYjMYo6BaqToUtBg8my7ZjOad9c32kC9kHzN4!/b/dLgAAAAAAAAA&amp;bo=VAW6AwAAAAADB8o!&amp;rf=viewer_4" alt=""><br>可以看到，索引项是按照索引里面定义出现的先后顺序排序的。<br>当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到ID4，然后向后遍历得到所有需要的结果。</p><p>不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p>]]></content>
    
    <summary type="html">
    
      &lt;font color=&quot;red&quot;&gt;索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。&lt;/font&gt;

&lt;h3 id=&quot;索引的常见模型&quot;&gt;&lt;a href=&quot;#索引的常见模型&quot; class=&quot;headerlink&quot; title=&quot;索引的常见模型&quot;&gt;&lt;/a&gt;索引的常见模型&lt;/h3&gt;&lt;p&gt;索引的出现时为了提高查询效率，但是实现索引的方式有很多种，所以这里也就引入了索引模型的概念。可以用来提高读写操作的数据结构有很多，这里先介绍比较简单的数据结构：哈希表和搜索树。&lt;/p&gt;
&lt;h4 id=&quot;哈希表&quot;&gt;&lt;a href=&quot;#哈希表&quot; class=&quot;headerlink&quot; title=&quot;哈希表&quot;&gt;&lt;/a&gt;哈希表&lt;/h4&gt;&lt;p&gt;哈希表是一种以K-V存储的数据结构，我们只要输入待查找的值，就可以找到其对应的值。哈希的思路很简单，把值放在数组里，用一个哈希函数把Key换算成一个确认的位置，然后把value放在数组的这个位置。遇到同一个位置上有很多value时，就用一个链表串起来。&lt;/p&gt;
&lt;p&gt;哈希链表适用于只有等值查询的场景&lt;/p&gt;
&lt;h4 id=&quot;二叉搜索树&quot;&gt;&lt;a href=&quot;#二叉搜索树&quot; class=&quot;headerlink&quot; title=&quot;二叉搜索树&quot;&gt;&lt;/a&gt;二叉搜索树&lt;/h4&gt;&lt;p&gt;二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。查询的平均复杂度是O(log(N))。&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="MySQL45讲" scheme="http://yoursite.com/tags/MySQL45%E8%AE%B2/"/>
    
  </entry>
  
  <entry>
    <title>事务隔离</title>
    <link href="http://yoursite.com/2019/01/16/MySQL/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/"/>
    <id>http://yoursite.com/2019/01/16/MySQL/事务隔离/</id>
    <published>2019-01-16T14:32:26.000Z</published>
    <updated>2019-01-17T15:19:41.983Z</updated>
    
    <content type="html"><![CDATA[<p>简单来说：事务就是保证一组数据库操作，要么全部成功，要么全部是失败。在MySQL中，事务支持是在引擎层实现的。MySQL是一个支持多引擎的系统，并不是所有的引擎都支持事务。比如MySQL原生的MyISAM引擎就不支持事务。</p><h3 id="隔离性和隔离级别"><a href="#隔离性和隔离级别" class="headerlink" title="隔离性和隔离级别"></a>隔离性和隔离级别</h3><p>提到事务，肯定会想到ACID（即原子性、一致性、隔离性、持久性），这里就讨论一下隔离性。<br>当数据库上有多个事务同时执行的时候，就可能出现脏读、不可重复读、幻读的问题，为了解决这些问题，就有了“隔离级别”的概念。</p><ul><li>读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。</li><li>读已提交：一个事务提交后，它做的变更才会被其他事务看到</li><li>可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。</li><li>串行化：后访问的事务必须等前一个事务完成后，才能继续执行。</li></ul><p>假设数据表T中只有一列，其中一行的值为1。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table T(c int) engine=InnoDB;</span><br><span class="line">insert into T(c) values(1);</span><br></pre></td></tr></table></figure></p><p><img src="https://m.qpic.cn/psb?/V140pON30woojR/N34*jAP61rjm0uHLDCigAi2GlkgbvdMqoW4J9gqGBok!/b/dL8AAAAAAAAA&amp;bo=OAT.BAAAAAADB.Q!&amp;rf=viewer_4" alt=""><br><a id="more"></a><br>我们来看看在不同的隔离级别下，事务A会有哪些不同的返回结果，也就是图中的V1、V2、V3的返回值分别是什么。</p><ul><li>若隔离级别是“读未提交”，这V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此V2、V3也都是2。</li><li>若隔离级别是“读提交”，这V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以，V3的值也是2。</li><li>若隔离级别是“可重复读”，则V1、V2是1，V3是2.之所以V2是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。</li><li>若隔离级别是“串行化”。则在事务B执行将1改成2的时候，就会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看，V1、V2、V3的值是2。</li></ul><p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个事务是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接使用加锁的方式来避免并行访问。</p><p>总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。</p><h3 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h3><p>在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。<br>假设一个值从1被按顺序改成了2、3、4，在回滚日志里面都会有类似下面的记录：<br><img src="https://m.qpic.cn/psb?/V140pON30woojR/pyWktvOA4ggEJYuVgTtFYnCH.Id5ReNQfprJmpwT1.8!/b/dMIAAAAAAAAA&amp;bo=TAVIAwAAAAADByA!&amp;rf=viewer_4" alt=""><br>当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-riew。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作等到。</p><p>回滚日志不可能一直保留；在不需要的时候就会被删除，也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志就会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。</p><p>基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。</p><p>长事务意味着系统会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p><p>在MySQL5.5以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>如何避免长事务的出现？<br><b>从开发端来看：</b></p><ol><li>确认是否使用了set autocommit=0。建议将这个值设置成1</li><li>确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来。</li><li>业务连接数据库的时候，根据业务本身的预估，通过set max_execution_time命令来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。</li></ol><p><b>从数据库端看：</b></p><ol><li>监控Information_schema.innodb_trx表，设置长事务阈值，超过就报警。</li><li>在业务功能测试阶段要求输出所欲的general_log，分析日志行为提前发现问题。</li><li>如果使用的是MySQL5.6或更新版本，把innodb_undo_tablespaces设置为2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;简单来说：事务就是保证一组数据库操作，要么全部成功，要么全部是失败。在MySQL中，事务支持是在引擎层实现的。MySQL是一个支持多引擎的系统，并不是所有的引擎都支持事务。比如MySQL原生的MyISAM引擎就不支持事务。&lt;/p&gt;
&lt;h3 id=&quot;隔离性和隔离级别&quot;&gt;&lt;a href=&quot;#隔离性和隔离级别&quot; class=&quot;headerlink&quot; title=&quot;隔离性和隔离级别&quot;&gt;&lt;/a&gt;隔离性和隔离级别&lt;/h3&gt;&lt;p&gt;提到事务，肯定会想到ACID（即原子性、一致性、隔离性、持久性），这里就讨论一下隔离性。&lt;br&gt;当数据库上有多个事务同时执行的时候，就可能出现脏读、不可重复读、幻读的问题，为了解决这些问题，就有了“隔离级别”的概念。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。&lt;/li&gt;
&lt;li&gt;读已提交：一个事务提交后，它做的变更才会被其他事务看到&lt;/li&gt;
&lt;li&gt;可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。&lt;/li&gt;
&lt;li&gt;串行化：后访问的事务必须等前一个事务完成后，才能继续执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;假设数据表T中只有一列，其中一行的值为1。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mysql&amp;gt; create table T(c int) engine=InnoDB;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;insert into T(c) values(1);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://m.qpic.cn/psb?/V140pON30woojR/N34*jAP61rjm0uHLDCigAi2GlkgbvdMqoW4J9gqGBok!/b/dL8AAAAAAAAA&amp;amp;bo=OAT.BAAAAAADB.Q!&amp;amp;rf=viewer_4&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="MySQL实战45讲" scheme="http://yoursite.com/tags/MySQL%E5%AE%9E%E6%88%9845%E8%AE%B2/"/>
    
  </entry>
  
  <entry>
    <title>一条更新语句的执行过程</title>
    <link href="http://yoursite.com/2019/01/14/MySQL/%E4%B8%80%E4%B8%AA%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/01/14/MySQL/一个更新语句的执行过程/</id>
    <published>2019-01-14T14:32:26.000Z</published>
    <updated>2019-01-17T15:26:12.485Z</updated>
    
    <content type="html"><![CDATA[<p>下面我们以下面这个表和更新语句来进行分析：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table T(ID int primary key, c int);</span><br><span class="line">update T set c=c+1 where ID=2;</span><br></pre></td></tr></table></figure></p><p>对于更新语句，查询语句的那一套流程，更新语句同样是会走一遍。</p><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>如果每一次更新操作都要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新；整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL采用了WAL技术来提升更新效率。WAL的全称是write-Ahead Logging。它的关键点在于<font color="red">先写日志，再写磁盘</font>。</p><p>具体来说，就是当有一条记录需要更新的时候，innodb引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，innodb引擎会在适当的时候，将这个操作记录更新到次磁盘里面，而这个更新往往是在系统比较空闲的时候做。</p><p>innodb的redo log是固定大小的，比如可以配置为一组4个文件，每个文件大小是1GB，那么redo log总共就可以记录4GB的操作，从头开始写，写到末尾就又回到开头循环写。<br><img src="https://m.qpic.cn/psb?/V140pON30woojR/cO8DivjlNOs4*4J.jc9sWkTtPIM5APzdpDE8aPjQews!/b/dLYAAAAAAAAA&amp;bo=hAUyAwAAAAADB5I!&amp;rf=viewer_4" alt=""><br><a id="more"></a><br>write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p><p>write pos和checkpoint之间的部分是用来记录新的操作。如果write pos追上checkpoint，那么表示redo log写满了，得先停下来擦掉一些记录，把checkpoint推进一点后才能够继续写入。</p><p>有了redo log，innodb就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称作crash-safe。</p><h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>MySQL从整体来说，其实有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。redo log是innodb引擎特有的日志，Server层也有自己的日志，称为binlog（归档日志）<br>最开始MySQL里并没有innodb引擎，MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而innodb是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力，所以innodb使用另一套日志系统（redo log）来实现crash-safe能力。</p><p>redo log 和 binlog主要有以下三点不同:</p><ol><li>redo log是innodb引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</li><li>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑。</li><li>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。</li></ol><p>我们回过头来看执行器和innodb引擎在执行这个简单的update语句时的内部流程。</p><ol><li>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li><li>执行器拿到引擎的给的行数据，把这个值加上1，等到新的一行数据，再调用引擎接口写入这行新数据。</li><li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成，随时可以提交事务。</li><li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li><li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。<br><img src="https://m.qpic.cn/psb?/V140pON30woojR/7vc6Wi5rjgpfIRIhIttNcrFLh7FmB1heWy5NCCPr8to!/b/dFIBAAAAAAAA&amp;bo=OASgBQAAAAADB7s!&amp;rf=viewer_4" alt=""><h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3>binlog会记录所有的逻辑操作，并且采用的是“追加写”的形式。当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，可以这样做：</li></ol><ul><li>首先找到最近一次的全年备份</li><li>然后从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。</li><li>将表数据从临时库中取出来，按需要恢复到线上库去。</li></ul><p>说完数据恢复过程，我们来说说为什么日志需要“两阶段提交”。<br>由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，那么就是先写完redo log再写binlog或者放过来。</p><ol><li><b>先写redo log后写binlog</b>。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过，redo log写完后，系统及时崩溃，仍然能够将数据恢复回来，所以恢复后这一行c的值是1。<br>但是由于binlog没写就crash了，这时候binlog是没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。<br>然后你会发现，如果需要这个binlog恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0。造成了数据不一致。（主从情况也是一样的）</li><li><b>先写binlog后写 redo log</b>。如果binlog写完后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binglog里面已经记录了“把c从0改成1”这个日子。所以binlog恢复后就多了一个事务。</li></ol><p>可以看到，如果不使用两阶段提交，那么数据库的状态与应用它日子的其他数据库数据不一致。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>redo log用来宝成crash-safe能力，innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都会直接持久化到磁盘。<br>sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;下面我们以下面这个表和更新语句来进行分析：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;create table T(ID int primary key, c int);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;update T set c=c+1 where ID=2;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;对于更新语句，查询语句的那一套流程，更新语句同样是会走一遍。&lt;/p&gt;
&lt;h3 id=&quot;redo-log&quot;&gt;&lt;a href=&quot;#redo-log&quot; class=&quot;headerlink&quot; title=&quot;redo log&quot;&gt;&lt;/a&gt;redo log&lt;/h3&gt;&lt;p&gt;如果每一次更新操作都要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新；整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL采用了WAL技术来提升更新效率。WAL的全称是write-Ahead Logging。它的关键点在于&lt;font color=&quot;red&quot;&gt;先写日志，再写磁盘&lt;/font&gt;。&lt;/p&gt;
&lt;p&gt;具体来说，就是当有一条记录需要更新的时候，innodb引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，innodb引擎会在适当的时候，将这个操作记录更新到次磁盘里面，而这个更新往往是在系统比较空闲的时候做。&lt;/p&gt;
&lt;p&gt;innodb的redo log是固定大小的，比如可以配置为一组4个文件，每个文件大小是1GB，那么redo log总共就可以记录4GB的操作，从头开始写，写到末尾就又回到开头循环写。&lt;br&gt;&lt;img src=&quot;https://m.qpic.cn/psb?/V140pON30woojR/cO8DivjlNOs4*4J.jc9sWkTtPIM5APzdpDE8aPjQews!/b/dLYAAAAAAAAA&amp;amp;bo=hAUyAwAAAAADB5I!&amp;amp;rf=viewer_4&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="MySQL实战45讲" scheme="http://yoursite.com/tags/MySQL%E5%AE%9E%E6%88%9845%E8%AE%B2/"/>
    
  </entry>
  
  <entry>
    <title>一条查询语句的执行过程</title>
    <link href="http://yoursite.com/2019/01/13/MySQL/MySQL%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2019/01/13/MySQL/MySQL基本架构/</id>
    <published>2019-01-13T14:32:26.000Z</published>
    <updated>2019-01-14T14:34:11.225Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MySQL基本架构"><a href="#MySQL基本架构" class="headerlink" title="MySQL基本架构"></a>MySQL基本架构</h2><p><img src="https://m.qpic.cn/psb?/V140pON30woojR/ussYTDB3vJmBbUYn8*kQP.aOU4fUXs6XhkExUtrBwWA!/b/dMMAAAAAAAAA&amp;bo=oAU4BAAAAAARB6k!&amp;rf=viewer_4" alt=""><br>MySQL基本架构可以分为Server层和存储引擎层两部分。</p><p>Server层包括连接器、查询缓存、分析器、优化器、执行器等，覆盖MySQL大多数核心服务功能，以及<font color="red">所有的内置函数</font>（如日期、时间、数学等），所有的跨存储引擎的功能都在这一层实现，如存储过程、触发器、视图等。<br><a id="more"></a><br>下面以select * from T where ID=10；这条语句做讲解。</p><h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>连接器负责和客户端建立连接、获取权限、维持和管理连接。<br>使用mysql客户端工具来跟服务端进行建立连接。在完成经典的TCP握手后，连接器就要验证用户身份。</p><ul><li>如果用户名或密码不对，会收到一个”Access denied for user”的错误，然后客户端程序结束执行。</li><li>如果用户名密码认真通过，连接器会到权限表里面查出你拥有的权限。在此连接后续过程中进行的权限判断逻辑都依赖于此时读取到的权限。</li></ul><p>这意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限进行了修改，也不会影响到已经存在连接的权限。</p><p>连接完成后，如果没有后续动作，这个连接就处于空闲状态；如果处于空闲状态太久没有进行操作，连接器就会自动将它断开。如果在连接端口后，客户端再发送请求的话，就会收到一个错误提醒：Lost connection to MySQL server during query。这时候会进行重连才能够执行请求了。</p><p>有时候会发现MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。但是由于长连接积累一直不释放，导致内存占用太大，被系统强行杀掉（OOM），从现象来看就是MySQL异常重启了。<br>怎么解决这个问题呢？</p><ol><li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li><li>如果使用的是MySQL5.7以上版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li></ol><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>连接建立完成后，就可以开始执行命令了。那么在进行查询语句时，会先到缓存中去查询缓存，之前是不是执行过这条语句。之前执行过的语句和结果可能会以键值对的形式被直接缓存在内存中。key是查询的语句，value是查询的结果。如果能够在缓存中找到查询的语句，那么就会直接返回value值给客户端。</p><p><b>但是大多数情况下，建议是不要使用查询缓存</b><br>查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存就会被清空。对于更新压力大的数据库来说，查询缓存的命中率非常低。出给你的业务就是一张静态表，很长时间才更新一次。<br>你可以将参数query_cache_type设置为DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用SQL_CACHE显式指定：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt;select SQL_CACHE * from T where ID=10;</span><br></pre></td></tr></table></figure></p><p>MySQL8.0版本直接将查询缓存的整块功能给删掉了。</p><h3 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h3><p>如果没有命中缓存，就要开始真正执行语句了。首先MySQL需要知道你要做什么，所以需要对SQL语句进行解析。</p><p>分析器先会做“词法解析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。<br>MySQL从输入的“select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID”。<br>做完识别后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。如果你的语句不对，将会收到“you hava an error in your SQL syntax”的错处提醒。</p><h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>经过了分析器，MySQL就知道你要做什么了。在正式开始执行前，还要经过优化器的处理。<br>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联的时候，决定各个表的连接顺序。</p><h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>MySQL知道了你要做什么，该怎么做后就开始执行了。<br>开始执行的时候，要先判断一下你对这个表T有没有执行权限，如果没有，就会返回没有权限的错误。<br>如果有权限，就打开表继续执行。打开表的时候，执行器会根据表的引擎定义，去使用这个引擎提供的接口。<br>比如我们例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：</p><pre><code>1. 调用InnodDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中。2. 调用引擎接口取“下一行”，重复相同的判断逻辑，知道取到这个表的最后一行。3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</code></pre><p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口。<br>你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。<br>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描函数跟rows_examined并不是完全相同的。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>如果表中没有字段k，而执行select * from T where k=1;肯定会报“不存在列”错误，这个错误是在哪个阶段报出来的？<br>答案：分析器，MySQL设计受Oracle影响，会在分析判断语句是否正确，表是否存在，列是否存在。<br>《高性能MySQL》里提到解析器处理语法和解析查询，会生成一颗对应的解析树</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;MySQL基本架构&quot;&gt;&lt;a href=&quot;#MySQL基本架构&quot; class=&quot;headerlink&quot; title=&quot;MySQL基本架构&quot;&gt;&lt;/a&gt;MySQL基本架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://m.qpic.cn/psb?/V140pON30woojR/ussYTDB3vJmBbUYn8*kQP.aOU4fUXs6XhkExUtrBwWA!/b/dMMAAAAAAAAA&amp;amp;bo=oAU4BAAAAAARB6k!&amp;amp;rf=viewer_4&quot; alt=&quot;&quot;&gt;&lt;br&gt;MySQL基本架构可以分为Server层和存储引擎层两部分。&lt;/p&gt;
&lt;p&gt;Server层包括连接器、查询缓存、分析器、优化器、执行器等，覆盖MySQL大多数核心服务功能，以及&lt;font color=&quot;red&quot;&gt;所有的内置函数&lt;/font&gt;（如日期、时间、数学等），所有的跨存储引擎的功能都在这一层实现，如存储过程、触发器、视图等。&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="MySQL实战45讲" scheme="http://yoursite.com/tags/MySQL%E5%AE%9E%E6%88%9845%E8%AE%B2/"/>
    
  </entry>
  
  <entry>
    <title>记一次磁盘空间不足</title>
    <link href="http://yoursite.com/2018/12/29/Linux/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%E4%B8%8D%E8%B6%B3%EF%BC%8C%E6%89%BE%E4%B8%8D%E5%88%B0%E4%BB%80%E4%B9%88%E6%96%87%E4%BB%B6%E5%AF%BC%E8%87%B4%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>http://yoursite.com/2018/12/29/Linux/记一次磁盘空间不足，找不到什么文件导致的解决方法/</id>
    <published>2018-12-29T03:06:28.000Z</published>
    <updated>2018-12-29T03:42:05.854Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h3><p>在一台虚拟机机器上发现磁盘空间不足的情况，通过登录上去查看，发现是挂载盘占用磁盘资源太多，通过df命令查看，但是并找不到具体是哪个文件占用过多。<br>通过以下查找大文件命令也没有找到相应的大文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -size +100M</span><br></pre></td></tr></table></figure></p><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>文件被删除后，并没有及时的释放磁盘资源，导致磁盘空间不足的情况。<br>通过以下命令，查看已经标记为删除但是没有释放的文件。对相应程序进行重启后解决<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof|grep -i delete|less</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题描述：&quot;&gt;&lt;a href=&quot;#问题描述：&quot; class=&quot;headerlink&quot; title=&quot;问题描述：&quot;&gt;&lt;/a&gt;问题描述：&lt;/h3&gt;&lt;p&gt;在一台虚拟机机器上发现磁盘空间不足的情况，通过登录上去查看，发现是挂载盘占用磁盘资源太多，通过df命令查看，但是并找
      
    
    </summary>
    
      <category term="Linux" scheme="http://yoursite.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>MySQL问答</title>
    <link href="http://yoursite.com/2018/11/29/MySQL/MySQL%E9%97%AE%E7%AD%94/"/>
    <id>http://yoursite.com/2018/11/29/MySQL/MySQL问答/</id>
    <published>2018-11-29T11:51:25.000Z</published>
    <updated>2019-01-20T15:24:52.751Z</updated>
    
    <content type="html"><![CDATA[<h2 id="导致主从不一致的原因"><a href="#导致主从不一致的原因" class="headerlink" title="导致主从不一致的原因"></a>导致主从不一致的原因</h2><ol><li>人为原因（从库写入）</li><li>主库异常宕机</li><li>设置了ignore/do/rewrite等replication等规则</li><li>binlog使用了非row格式</li><li>从库中断</li><li>从库启用了存储过程</li><li>主从数据库版本不一致</li><li>重做时，mysqldump备份没有指定参数</li><li>主从sql_mode不一致</li><li>采用5.6的after_commit方式半同步，主库宕机可能会引起主从不一致。</li><li>启用了增强半同步，但是从库延迟超时自动切换成了异步复制</li></ol><h3 id="预防和解决的方案"><a href="#预防和解决的方案" class="headerlink" title="预防和解决的方案"></a>预防和解决的方案</h3><ol><li>master:innodb_flush_log_at_trx_commit=1&amp;sync_binlog=1</li><li>slave:master_info_repository=”TABLE”&amp;relay_log_info_repository=”TABLE”&amp;relay_log_recovery=1</li><li>设置从库库为只读模式</li><li>可以使用5.7增强半同步避免数据丢失等</li><li>binlog row格式</li><li>必须引定期的数据校验机制</li><li>当使用延迟复制的时候，此时主从数据也是不一致的（计划内），但在切换中，不要把延迟从提升为主库哦~</li><li>mha在主从切换的过程中，因主库系统宕机，可能造成主从不一致（mha本身机制导致这个问题）</li></ol><a id="more"></a><h2 id="为什么决定使用分库分表"><a href="#为什么决定使用分库分表" class="headerlink" title="为什么决定使用分库分表"></a>为什么决定使用分库分表</h2><ol><li>根据业务类型和业务容量评估</li><li>当前数据库本身具有的能力、压力评估</li><li>数据库的物理隔离，如：减少锁的争夺，资源的消耗和隔离</li><li>热点表较多，并且数据量大，可能会引起锁增强，性能下降</li><li>数据库的高并发，数据库读写压力大，可能会导致数据库或启动宕机</li><li>数据库（5.7以下）连接数过高，会增加系统压力</li><li>单表数据量大，如SQL使用不当，导致IO随机读写比例高；查询慢</li><li>备份和恢复时间比较长</li></ol><h3 id="会有什么问题"><a href="#会有什么问题" class="headerlink" title="会有什么问题"></a>会有什么问题</h3><ol><li>全局pk（主键和唯一索引）的冲突检测不准确，全局的自增主键支持不够好</li><li>分片键的选择</li><li>分布式事务</li><li>开发方面：需要进行业务的拆分。部分SQL不兼容。跨库查询、join。</li></ol><h3 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h3><ol><li>使用全局分号器。或者使用全局唯一id。</li><li>应用层来判断唯一索引</li><li>配合应用选择合适的分片键，并加上索引</li><li>配合应用，配合开发，对不兼容SQL进行整改</li></ol><h2 id="MySQL高可用架构应该考虑什么？"><a href="#MySQL高可用架构应该考虑什么？" class="headerlink" title="MySQL高可用架构应该考虑什么？"></a>MySQL高可用架构应该考虑什么？</h2><ol><li>对业务有一定了解，需要考虑业务对数据库一致性要求的敏感程度，切换过程中是否有事务丢失。</li><li>对于基础设施有一定了解，需要了解基础设施的高可用架构。</li><li>对于数据库故障时间掌握，业务方最多能容忍时间范围</li><li>需要了解主流的高可用的优缺点</li><li>考虑多机房多副本分布<h3 id="如何设计？"><a href="#如何设计？" class="headerlink" title="如何设计？"></a>如何设计？</h3></li><li>基础层和基础运维部门配合，了解和避免网络/硬盘/电源等是否会出现单点故障</li><li>应用层和开发配合，在关键日志中记录SQL日志，可以做到即使切换出现丢事务的情况，也可以通过手工补的方式保证数据一致性。</li><li>根据不同的应用制定合理的高可用策略</li><li>单机多实例</li><li>在数据库不可用，可以把已提交的事务先存储到队列或者其他位置，等数据库恢复，重新应用。</li></ol><h2 id="xtrabackup和mysqldump备份造成的锁等待"><a href="#xtrabackup和mysqldump备份造成的锁等待" class="headerlink" title="xtrabackup和mysqldump备份造成的锁等待"></a>xtrabackup和mysqldump备份造成的锁等待</h2><ol><li>xtrabackup在备份非innodb表时会有短暂的全局读锁FTWL</li><li>mysqldump获取一致性快照时会进行锁表</li><li>xtrabackup在备份时会在/tmp目录下生成一个临时文件，如果在备份过程中修改了/tmp的权限，这会造成xtrabackup hang住，正在备份的表不能正常释放锁，会造成锁等待。</li></ol><h2 id="为什么说pt-osc可能会引起主从延迟，有什么好办法解决或规避吗？"><a href="#为什么说pt-osc可能会引起主从延迟，有什么好办法解决或规避吗？" class="headerlink" title="为什么说pt-osc可能会引起主从延迟，有什么好办法解决或规避吗？"></a>为什么说pt-osc可能会引起主从延迟，有什么好办法解决或规避吗？</h2><ol><li>若复制中binlog使用row格式，对大表使用ps-osc把数据从旧表拷贝到临时表，期间会产生大量的binlog，从而导致延时</li><li>pt-osc在搬数据过程中insert..select是有行锁的，会降低事务并行度；且pt-osc搬数据过程中生成的binlog不是并行的，所以在slave不能并行回放。</li><li>可以通过设定参数–chunk-size、–chunk-time控制每次拷贝数据大小，也可以设定–max-log、check-interval、check-slave-lag等参数控制主从复制延迟程度（但这样可能会造成pt-osc工作耗时太久，需要执行权衡）</li></ol><h2 id="哪些原因会造成MySQL异步复制延迟"><a href="#哪些原因会造成MySQL异步复制延迟" class="headerlink" title="哪些原因会造成MySQL异步复制延迟"></a>哪些原因会造成MySQL异步复制延迟</h2><ol><li>master上多为并发事务，slave上则多为单线程回放（5.7起，支持真正的并行回放）</li><li>异步复制，本身就是有一定的延迟</li><li>有时为了节省机器资源，会在slave上运行多个实例</li><li>表结构设计不合理</li><li>slave上运行了大量只读低效率的SQL</li><li>大量大事务，也会造成slave无法并行回放</li><li>业务设计缺陷，或网络延迟等</li></ol><h2 id="MySQL每天产生了多大容量的binlog，可以查到吗"><a href="#MySQL每天产生了多大容量的binlog，可以查到吗" class="headerlink" title="MySQL每天产生了多大容量的binlog，可以查到吗"></a>MySQL每天产生了多大容量的binlog，可以查到吗</h2><p>binlog并不会自动的每天切分统计，所以需要人为这执行flush binlog logs再结合系统层命令完成。</p><h2 id="明明有索引，但是执行的时候没有选中是什么原因？"><a href="#明明有索引，但是执行的时候没有选中是什么原因？" class="headerlink" title="明明有索引，但是执行的时候没有选中是什么原因？"></a>明明有索引，但是执行的时候没有选中是什么原因？</h2><ol><li>隐式转换</li><li>表碎片，表碎片率过高</li><li>根据索引读取到的数据在整个表中的数据占比超过30%</li><li>统计信息没有及时更新</li></ol><h2 id="主从复制正常，但是主从延迟过高是什么原因"><a href="#主从复制正常，但是主从延迟过高是什么原因" class="headerlink" title="主从复制正常，但是主从延迟过高是什么原因"></a>主从复制正常，但是主从延迟过高是什么原因</h2><ol><li>sync_relay_log值过低，导致slave频繁刷新relay_log文件，使slave硬盘资源消耗过高。</li><li>Master/Slave压力过大</li><li>网络丢包严重</li><li>Master和Slave网络链接已经断开，但是slave_net_timeout值等于0（表示完全禁用心跳）或者slave_net_timeout和Slave_heart_period非常大（表示检测主从心跳的时间）</li><li>Master的binlog非常大，io线程的file很长时间在读同一个。</li></ol><h2 id="MySQL-hang的原因有哪些？"><a href="#MySQL-hang的原因有哪些？" class="headerlink" title="MySQL hang的原因有哪些？"></a>MySQL hang的原因有哪些？</h2><ol><li>MySQL使用资源过高导致服务器太累扛不住。</li><li>磁盘无可用空间</li><li>MySQL频繁的创建和销毁连接。</li><li>MySQL使用的最大文件打开数和连接数，超过了操作系统的限制。</li><li>MySQL的锁不能有效的释放。例如持有行锁或者表锁，造成MDL等待。</li><li>MySQL的bug导致的</li></ol><h2 id="MySQL中如果发现乱码该怎么处理？"><a href="#MySQL中如果发现乱码该怎么处理？" class="headerlink" title="MySQL中如果发现乱码该怎么处理？"></a>MySQL中如果发现乱码该怎么处理？</h2><ol><li>直接修改法，alter或者pt-osc等工具直接对工具进行修改。</li><li>备份修改法，利用mysqldump等其他逻辑备份进行备份，备份的结果集再利用iconv进行转换。</li><li>跳过字符集备份，–skip-set-charset</li></ol><h2 id="MySQL的表中有唯一索引，设置unique-check为0时，能否写入重复值"><a href="#MySQL的表中有唯一索引，设置unique-check为0时，能否写入重复值" class="headerlink" title="MySQL的表中有唯一索引，设置unique_check为0时，能否写入重复值"></a>MySQL的表中有唯一索引，设置unique_check为0时，能否写入重复值</h2><p>首先，即便设置unique_checks=0，也无法往唯一索引中写入重复值。</p><p>其次，设置unique_checks=0的作用在于，批量导入数据（例如load data）时，在确保导入数据中无重复值时，无需再次检查其唯一性，加快导入速度。</p><p>所以，unique_checks=0并不是允许唯一约束失效，而是再批量导数据时不再逐行检查唯一性。</p><h2 id="在大表执行ddl的过程中，若临时中断，会发生什么状况，需要特别处理吗-？"><a href="#在大表执行ddl的过程中，若临时中断，会发生什么状况，需要特别处理吗-？" class="headerlink" title="在大表执行ddl的过程中，若临时中断，会发生什么状况，需要特别处理吗 ？"></a>在大表执行ddl的过程中，若临时中断，会发生什么状况，需要特别处理吗 ？</h2><p>前提说明：MySQL5.7.23、innodb表、“双1” </p><p>1、添加/删除列，采用copy的方式 </p><p>1.1、ctrl+c。在当前session中，手动执行ctrl+c。无影响，并且会自动删除产生的临时文件。 </p><p>1.2、kill -9。在执行ddl的时候，服务器发生意外宕机或者手动执行kill -9。待MySQL启动后，则会自动执行InnoDB Recovered流程。并且不会删除产生的临时文件，需要手工处理。 </p><p>2、添加/删除索引，采用INPLACE方式 </p><p>2.1、ctrl+c，同1.1 </p><p>2.2、kill -9。不会删除临时文件，也不会执行InnoDB Recovered流程并且报错 Operating system error number 2 in a file operation ….OS error: 71 </p><p>在开始执行alter table的过程中，在没有结束的时候，并不会写入到binglog文件中。</p><h2 id="MySQL线上实例insert慢常见原因有哪些？"><a href="#MySQL线上实例insert慢常见原因有哪些？" class="headerlink" title="MySQL线上实例insert慢常见原因有哪些？"></a>MySQL线上实例insert慢常见原因有哪些？</h2><ol><li>锁等待：SQL产生的间隙锁、自增锁、死锁、MDL锁、外键检查锁，锁等待时间</li><li>iops达到瓶颈：例如备份任务、高频binlog redolog等文件写入</li><li>semi-sync：因为网络抖动，MySQL半同步、增强半同步导致语句卡住</li><li>高并发：高并发场景下，导致系统资源达到瓶颈，从而SQL执行慢</li><li>大字段：当前表索引过多，或者写入大量的text类型数据</li><li>硬件故障：因为磁盘、raid卡、内存等物理硬件故障导致写入慢</li><li>磁盘资源耗尽：操作系统的磁盘、inode资源耗尽</li><li>文件系统故障：MySQL data目录的所在挂在的不可写、或者被设置为只读</li><li>binlog group commit等待 </li><li>参数配置：innodb_buffer、redo_buffer过小 </li><li>autocommit：事物非自动提交，等待程序提交。</li></ol><h2 id="虽然命中索引，但SQL效率仍然慢，可能有哪些原因？"><a href="#虽然命中索引，但SQL效率仍然慢，可能有哪些原因？" class="headerlink" title="虽然命中索引，但SQL效率仍然慢，可能有哪些原因？"></a>虽然命中索引，但SQL效率仍然慢，可能有哪些原因？</h2><ol><li>索引字段重复值或者空值太多。 </li><li>查询条件范围太广返回结果数太多，全索引扫描 </li><li>没有利用到覆盖索引，造成大量回表 </li><li>查询字段过多，并且包含大字段</li><li>索引字段数据分布太随机，回表不多也会引起大量随机io </li><li>统计信息不准 </li><li>表的单行数据值很大，需要较多io </li><li>表中包含多个索引， 命中的索引不是最优的索引。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;导致主从不一致的原因&quot;&gt;&lt;a href=&quot;#导致主从不一致的原因&quot; class=&quot;headerlink&quot; title=&quot;导致主从不一致的原因&quot;&gt;&lt;/a&gt;导致主从不一致的原因&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;人为原因（从库写入）&lt;/li&gt;
&lt;li&gt;主库异常宕机&lt;/li&gt;
&lt;li&gt;设置了ignore/do/rewrite等replication等规则&lt;/li&gt;
&lt;li&gt;binlog使用了非row格式&lt;/li&gt;
&lt;li&gt;从库中断&lt;/li&gt;
&lt;li&gt;从库启用了存储过程&lt;/li&gt;
&lt;li&gt;主从数据库版本不一致&lt;/li&gt;
&lt;li&gt;重做时，mysqldump备份没有指定参数&lt;/li&gt;
&lt;li&gt;主从sql_mode不一致&lt;/li&gt;
&lt;li&gt;采用5.6的after_commit方式半同步，主库宕机可能会引起主从不一致。&lt;/li&gt;
&lt;li&gt;启用了增强半同步，但是从库延迟超时自动切换成了异步复制&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;预防和解决的方案&quot;&gt;&lt;a href=&quot;#预防和解决的方案&quot; class=&quot;headerlink&quot; title=&quot;预防和解决的方案&quot;&gt;&lt;/a&gt;预防和解决的方案&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;master:innodb_flush_log_at_trx_commit=1&amp;amp;sync_binlog=1&lt;/li&gt;
&lt;li&gt;slave:master_info_repository=”TABLE”&amp;amp;relay_log_info_repository=”TABLE”&amp;amp;relay_log_recovery=1&lt;/li&gt;
&lt;li&gt;设置从库库为只读模式&lt;/li&gt;
&lt;li&gt;可以使用5.7增强半同步避免数据丢失等&lt;/li&gt;
&lt;li&gt;binlog row格式&lt;/li&gt;
&lt;li&gt;必须引定期的数据校验机制&lt;/li&gt;
&lt;li&gt;当使用延迟复制的时候，此时主从数据也是不一致的（计划内），但在切换中，不要把延迟从提升为主库哦~&lt;/li&gt;
&lt;li&gt;mha在主从切换的过程中，因主库系统宕机，可能造成主从不一致（mha本身机制导致这个问题）&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Redis源码阅读(启动过程)</title>
    <link href="http://yoursite.com/2018/11/15/Redis/Redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB(%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B)/"/>
    <id>http://yoursite.com/2018/11/15/Redis/Redis源码阅读(启动过程)/</id>
    <published>2018-11-15T06:12:13.000Z</published>
    <updated>2018-11-23T07:16:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>Redis的启动函数main()在redis.c文件中。 </p><h3 id="初始化配置"><a href="#初始化配置" class="headerlink" title="初始化配置"></a>初始化配置</h3><p>在启动时会使用initServerConfig()函数进行初始化服务器配置工作，redisServer(redis.h)作为保存服务器配置的结构。 redisServer包含以下的一些Redis服务器的信息：  </p><ul><li>一般服务器状态。</li><li>一些服务器统计信息。</li><li>各种链表结构，如保存客户端的链表等。</li><li>配置文件及启动参数中的配置。</li><li>主从复制的状态。</li><li>持久化文件的参数和状态。</li></ul><p><img src="https://i.imgur.com/IXG8CwE.png" alt=""><br><a id="more"></a></p><h3 id="初始化服务器数据结构"><a href="#初始化服务器数据结构" class="headerlink" title="初始化服务器数据结构"></a>初始化服务器数据结构</h3><p>在initServer中会进行初始化服务器所需要的一些数据结构信息</p><ul><li>共享对象</li><li>事件循环</li><li>数据库结构</li><li>TCP套接字</li><li>服务器cron</li><li>事件循环</li><li>打开AOF</li></ul><h3 id="恢复数据"><a href="#恢复数据" class="headerlink" title="恢复数据"></a>恢复数据</h3><p>如果开启了AOF持久化，那么加载AOF文件；否则加载RDB文件。   </p><p><font color="red">如果开启AOF，但是没有AOF文件的话也不会去读取RDB文件，这样会造成数据的丢失！！！</font><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">void loadDataFromDisk(void) &#123;</span><br><span class="line">    // 记录开始时间</span><br><span class="line">    long long start = ustime();</span><br><span class="line"></span><br><span class="line">    // AOF 持久化已打开？</span><br><span class="line">    if (server.aof_state == REDIS_AOF_ON) &#123;</span><br><span class="line">        // 尝试载入 AOF 文件</span><br><span class="line">        if (loadAppendOnlyFile(server.aof_filename) == REDIS_OK)</span><br><span class="line">            // 打印载入信息，并计算载入耗时长度</span><br><span class="line">            redisLog(REDIS_NOTICE,&quot;DB loaded from append only file: %.3f seconds&quot;,(float)(ustime()-start)/1000000);</span><br><span class="line">    // AOF 持久化未打开</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 尝试载入 RDB 文件</span><br><span class="line">        if (rdbLoad(server.rdb_filename) == REDIS_OK) &#123;</span><br><span class="line">            // 打印载入信息，并计算载入耗时长度</span><br><span class="line">            redisLog(REDIS_NOTICE,&quot;DB loaded from disk: %.3f seconds&quot;,</span><br><span class="line">                (float)(ustime()-start)/1000000);</span><br><span class="line">        &#125; else if (errno != ENOENT) &#123;</span><br><span class="line">            redisLog(REDIS_WARNING,&quot;Fatal error loading the DB: %s. Exiting.&quot;,strerror(errno));</span><br><span class="line">            exit(1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="运行事件处理器"><a href="#运行事件处理器" class="headerlink" title="运行事件处理器"></a>运行事件处理器</h3><p>Redis在每次进入事件循环时都会想调用函数beforeSleep()。<br>beforeSleep()会做两件事：  </p><ol><li>如果启用了虚拟内存系统，将会去刷新AOF到磁盘，由flushAppendOnlyFile()函数处理。  </li><li>该函数封装了关于刷新缓冲区的一些复杂的逻辑，该缓冲区保存了AOF的写入缓存。  </li></ol><h4 id="进入事件循环"><a href="#进入事件循环" class="headerlink" title="进入事件循环"></a>进入事件循环</h4><p>Redis通过aeMain()进入主事件循环server.el。通过aeProcessEvents()处理所有已到达的时间事件和所有已就绪的文件事件。</p><h3 id="处理请求并返回响应"><a href="#处理请求并返回响应" class="headerlink" title="处理请求并返回响应"></a>处理请求并返回响应</h3><p>经过上面的启动过程后，Redis已经处于主事件轮询循环中，监听端口并等待客户端连接。<br><img src="https://i.imgur.com/J2YEVoo.png" alt=""></p><h4 id="处理新连接"><a href="#处理新连接" class="headerlink" title="处理新连接"></a>处理新连接</h4><p>在initServer()中，Redis注册acceptHandler()，当IO事件发生时被调用。acceptHandler()会创建一个客户端对象RedisClient。</p><h4 id="从客户端读取命令"><a href="#从客户端读取命令" class="headerlink" title="从客户端读取命令"></a>从客户端读取命令</h4><p>当客户端发送命令请求时，主事件循环调用readQueryFromClient()函数，它会尽可能多的读取（最多1024个字节）到临时缓冲区。<br>然后调用processInputBuffer()函数将客户端对象作为参数传递。processInputBuffer()将客户端的原始查询解析为执行Redis命令的参数，并解析每个参数的Redis字符串对象，并将它存储在客户端对象的数组中。然后调用processCommand()客户端对象来实际执行客户端发送的命令。<br>processCommand()从客户端获取命令的参数并执行。在执行前会进行许多的检查，如果检查失败，会向客户端对象附加一个错误消息并返回。</p><h4 id="执行命令并响应"><a href="#执行命令并响应" class="headerlink" title="执行命令并响应"></a>执行命令并响应</h4><p>call()函数，从客户端对象中获取具体执行命令的指针所指向的函数对象，并调用。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void call(redisClient *c, struct redisCommand *cmd) &#123;</span><br><span class="line">    long long dirty;</span><br><span class="line"></span><br><span class="line">    dirty = server.dirty;</span><br><span class="line">    cmd-&gt;proc(c);</span><br><span class="line">    dirty = server.dirty-dirty;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis的启动函数main()在redis.c文件中。 &lt;/p&gt;
&lt;h3 id=&quot;初始化配置&quot;&gt;&lt;a href=&quot;#初始化配置&quot; class=&quot;headerlink&quot; title=&quot;初始化配置&quot;&gt;&lt;/a&gt;初始化配置&lt;/h3&gt;&lt;p&gt;在启动时会使用initServerConfig()函数进行初始化服务器配置工作，redisServer(redis.h)作为保存服务器配置的结构。 redisServer包含以下的一些Redis服务器的信息：  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一般服务器状态。&lt;/li&gt;
&lt;li&gt;一些服务器统计信息。&lt;/li&gt;
&lt;li&gt;各种链表结构，如保存客户端的链表等。&lt;/li&gt;
&lt;li&gt;配置文件及启动参数中的配置。&lt;/li&gt;
&lt;li&gt;主从复制的状态。&lt;/li&gt;
&lt;li&gt;持久化文件的参数和状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/IXG8CwE.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis对象结构</title>
    <link href="http://yoursite.com/2018/11/10/Redis/Redis%E5%AF%B9%E8%B1%A1/"/>
    <id>http://yoursite.com/2018/11/10/Redis/Redis对象/</id>
    <published>2018-11-10T13:34:13.000Z</published>
    <updated>2018-11-23T07:17:50.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">typedef struct redisObject &#123;</span><br><span class="line"></span><br><span class="line">    // 类型</span><br><span class="line">    unsigned type:4;</span><br><span class="line"></span><br><span class="line">    // 编码</span><br><span class="line">    unsigned encoding:4;</span><br><span class="line"></span><br><span class="line">    // 对象最后一次被访问的时间</span><br><span class="line">    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */</span><br><span class="line"></span><br><span class="line">    // 引用计数</span><br><span class="line">    int refcount;</span><br><span class="line"></span><br><span class="line">    // 指向实际值的指针</span><br><span class="line">    void *ptr;</span><br><span class="line"></span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">typedef struct redisDb &#123;</span><br><span class="line"></span><br><span class="line">    // 数据库键空间，保存着数据库中的所有键值对</span><br><span class="line">    dict *dict;                 /* The keyspace for this DB */</span><br><span class="line"></span><br><span class="line">    // 键的过期时间，字典的键为键，字典的值为过期事件 UNIX 时间戳</span><br><span class="line">    dict *expires;              /* Timeout of keys with a timeout set */</span><br><span class="line"></span><br><span class="line">    // 正处于阻塞状态的键</span><br><span class="line">    dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP) */</span><br><span class="line"></span><br><span class="line">    // 可以解除阻塞的键</span><br><span class="line">    dict *ready_keys;           /* Blocked keys that received a PUSH */</span><br><span class="line"></span><br><span class="line">    // 正在被 WATCH 命令监视的键</span><br><span class="line">    dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */</span><br><span class="line"></span><br><span class="line">    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */</span><br><span class="line"></span><br><span class="line">    // 数据库号码</span><br><span class="line">    int id;                     /* Database ID */</span><br><span class="line"></span><br><span class="line">    // 数据库的键的平均 TTL ，统计信息</span><br><span class="line">    long long avg_ttl;          /* Average TTL, just for stats */</span><br><span class="line"></span><br><span class="line">&#125; redisDb;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">typedef struct redisClient &#123;</span><br><span class="line"></span><br><span class="line">    // 套接字描述符</span><br><span class="line">    int fd;</span><br><span class="line"></span><br><span class="line">    // 当前正在使用的数据库</span><br><span class="line">    redisDb *db;</span><br><span class="line"></span><br><span class="line">    // 当前正在使用的数据库的 id （号码）</span><br><span class="line">    int dictid;</span><br><span class="line"></span><br><span class="line">    // 客户端的名字</span><br><span class="line">    robj *name;             /* As set by CLIENT SETNAME */</span><br><span class="line"></span><br><span class="line">    // 查询缓冲区</span><br><span class="line">    sds querybuf;</span><br><span class="line"></span><br><span class="line">    // 查询缓冲区长度峰值</span><br><span class="line">    size_t querybuf_peak;   /* Recent (100ms or more) peak of querybuf size */</span><br><span class="line"></span><br><span class="line">    // 参数数量</span><br><span class="line">    int argc;</span><br><span class="line"></span><br><span class="line">    // 参数对象数组</span><br><span class="line">    robj **argv;</span><br><span class="line"></span><br><span class="line">    // 记录被客户端执行的命令</span><br><span class="line">    struct redisCommand *cmd, *lastcmd;</span><br><span class="line"></span><br><span class="line">    // 请求的类型：内联命令还是多条命令</span><br><span class="line">    int reqtype;</span><br><span class="line"></span><br><span class="line">    // 剩余未读取的命令内容数量</span><br><span class="line">    int multibulklen;       /* number of multi bulk arguments left to read */</span><br><span class="line"></span><br><span class="line">    // 命令内容的长度</span><br><span class="line">    long bulklen;           /* length of bulk argument in multi bulk request */</span><br><span class="line"></span><br><span class="line">    // 回复链表</span><br><span class="line">    list *reply;</span><br><span class="line"></span><br><span class="line">    // 回复链表中对象的总大小</span><br><span class="line">    unsigned long reply_bytes; /* Tot bytes of objects in reply list */</span><br><span class="line"></span><br><span class="line">    // 已发送字节，处理 short write 用</span><br><span class="line">    int sentlen;            /* Amount of bytes already sent in the current</span><br><span class="line">                               buffer or object being sent. */</span><br><span class="line"></span><br><span class="line">    // 创建客户端的时间</span><br><span class="line">    time_t ctime;           /* Client creation time */</span><br><span class="line"></span><br><span class="line">    // 客户端最后一次和服务器互动的时间</span><br><span class="line">    time_t lastinteraction; /* time of the last interaction, used for timeout */</span><br><span class="line"></span><br><span class="line">    // 客户端的输出缓冲区超过软性限制的时间</span><br><span class="line">    time_t obuf_soft_limit_reached_time;</span><br><span class="line"></span><br><span class="line">    // 客户端状态标志</span><br><span class="line">    int flags;              /* REDIS_SLAVE | REDIS_MONITOR | REDIS_MULTI ... */</span><br><span class="line"></span><br><span class="line">    // 当 server.requirepass 不为 NULL 时</span><br><span class="line">    // 代表认证的状态</span><br><span class="line">    // 0 代表未认证， 1 代表已认证</span><br><span class="line">    int authenticated;      /* when requirepass is non-NULL */</span><br><span class="line"></span><br><span class="line">    // 复制状态</span><br><span class="line">    int replstate;          /* replication state if this is a slave */</span><br><span class="line">    // 用于保存主服务器传来的 RDB 文件的文件描述符</span><br><span class="line">    int repldbfd;           /* replication DB file descriptor */</span><br><span class="line"></span><br><span class="line">    // 读取主服务器传来的 RDB 文件的偏移量</span><br><span class="line">    off_t repldboff;        /* replication DB file offset */</span><br><span class="line">    // 主服务器传来的 RDB 文件的大小</span><br><span class="line">    off_t repldbsize;       /* replication DB file size */</span><br><span class="line">    </span><br><span class="line">    sds replpreamble;       /* replication DB preamble. */</span><br><span class="line"></span><br><span class="line">    // 主服务器的复制偏移量</span><br><span class="line">    long long reploff;      /* replication offset if this is our master */</span><br><span class="line">    // 从服务器最后一次发送 REPLCONF ACK 时的偏移量</span><br><span class="line">    long long repl_ack_off; /* replication ack offset, if this is a slave */</span><br><span class="line">    // 从服务器最后一次发送 REPLCONF ACK 的时间</span><br><span class="line">    long long repl_ack_time;/* replication ack time, if this is a slave */</span><br><span class="line">    // 主服务器的 master run ID</span><br><span class="line">    // 保存在客户端，用于执行部分重同步</span><br><span class="line">    char replrunid[REDIS_RUN_ID_SIZE+1]; /* master run id if this is a master */</span><br><span class="line">    // 从服务器的监听端口号</span><br><span class="line">    int slave_listening_port; /* As configured with: SLAVECONF listening-port */</span><br><span class="line"></span><br><span class="line">    // 事务状态</span><br><span class="line">    multiState mstate;      /* MULTI/EXEC state */</span><br><span class="line"></span><br><span class="line">    // 阻塞类型</span><br><span class="line">    int btype;              /* Type of blocking op if REDIS_BLOCKED. */</span><br><span class="line">    // 阻塞状态</span><br><span class="line">    blockingState bpop;     /* blocking state */</span><br><span class="line"></span><br><span class="line">    // 最后被写入的全局复制偏移量</span><br><span class="line">    long long woff;         /* Last write global replication offset. */</span><br><span class="line"></span><br><span class="line">    // 被监视的键</span><br><span class="line">    list *watched_keys;     /* Keys WATCHED for MULTI/EXEC CAS */</span><br><span class="line"></span><br><span class="line">    // 这个字典记录了客户端所有订阅的频道</span><br><span class="line">    // 键为频道名字，值为 NULL</span><br><span class="line">    // 也即是，一个频道的集合</span><br><span class="line">    dict *pubsub_channels;  /* channels a client is interested in (SUBSCRIBE) */</span><br><span class="line"></span><br><span class="line">    // 链表，包含多个 pubsubPattern 结构</span><br><span class="line">    // 记录了所有订阅频道的客户端的信息</span><br><span class="line">    // 新 pubsubPattern 结构总是被添加到表尾</span><br><span class="line">    list *pubsub_patterns;  /* patterns a client is interested in (SUBSCRIBE) */</span><br><span class="line">    sds peerid;             /* Cached peer ID. */</span><br><span class="line"></span><br><span class="line">    /* Response buffer */</span><br><span class="line">    // 回复偏移量</span><br><span class="line">    int bufpos;</span><br><span class="line">    // 回复缓冲区</span><br><span class="line">    char buf[REDIS_REPLY_CHUNK_BYTES];</span><br><span class="line"></span><br><span class="line">&#125; redisClient;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;typedef struct redisObject &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    // 类型&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    unsigned type:4;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    // 编码&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    unsigned encoding:4;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    // 对象最后一次被访问的时间&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    // 引用计数&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    int refcount;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    // 指向实际值的指针&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    void *ptr;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125; robj;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis原理----主从复制</title>
    <link href="http://yoursite.com/2018/10/26/Redis/Redis%E5%8E%9F%E7%90%86----%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    <id>http://yoursite.com/2018/10/26/Redis/Redis原理----主从复制/</id>
    <published>2018-10-26T13:34:13.000Z</published>
    <updated>2018-10-28T15:41:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>很多企业都没有使用到Redis的集群，但是至少都做了主从。有了主从，当master挂掉的时候，运维让从库过来接管，服务就可以继续，否则master需要经过数据恢复和重启的过程，这就可能会拖很长时间，影响线上业务的持续服务。  </p><p>在了解Redis主从复制之前，让我们先来理解一下现代分布式系统的理论基石–CAP原理。</p><h2 id="CAP原理"><a href="#CAP原理" class="headerlink" title="CAP原理"></a>CAP原理</h2><p>CAP原理就好比分布式领域的牛顿定律，它是分布式存储的理论基石。自打CAP的论文发表之后，分布式存储中间件犹如雨后春笋一个一个涌现出来。  </p><ul><li>C-Consistent 一致性</li><li>A-Availability 可用性</li><li>P-Partition tolerance 分区容忍性</li></ul><p>分布式系统的节点往往都是分布在不同的机器上进行网络隔离开的，这意味着必然会有网络断开的风险，这个网络断开的场景的专业词汇叫着「网络分区」。</p><a id="more"></a><p>在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。<br><img src="https://i.imgur.com/owNDznt.jpg" alt=""><br>一句话概括CAP原理就是–<b>网络分区发生时，一致性和可用性两难全。</b>  </p><p>Redis的主从数据是异步同步的，所以分布式的Redis系统并不满足[一致性]要求。当客户端在Redis的主节点修改了数据后，立即返回，即使在主从网络断开的情况下，主从节点依旧可以正常对外提供服务，所以Redis满足[可用性]。  </p><p>Redis保证[最终一致性]，从节点会努力追赶主节点，最终从节点的状态会和主节点的状态保持一致。如果网络断开，主从节点的数据将会出现大量不一致，一旦网络恢复，从节点会采用多种策略努力追赶上落后的数据，继续经历保持和主节点一致。  </p><h2 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h2><p>Redis同步支持主从同步和从从同步，从从同步功能是Redis后续版本增加的功能，为了减轻主库的同步负担。<br><img src="https://i.imgur.com/1IiirbA.jpg" alt="">  </p><h2 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h2><p>Redis同步的是指令流，主节点会将那些对自己状态产生修改性影响的指令记录在本地的内存buffer中，然后异步将buffer中的指令同步到从节点，从节点一边执行同步的指令流来达到和主节点一样的状态，一边向主节点反馈自己同步的偏移量。  </p><p>因为内存的buffer（复制积压缓冲区）是有限的，所以Redis主库不能将所有的指令都记录在内存buffer中。Redis的复制内存buffer是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容。<br><img src="https://i.imgur.com/I9g0mo3.jpg" alt=""><br>如果因为网络状况不好，从节点在短时间内无法和主节点进行同步，那么在网络状况恢复时，Redis的主节点中那些没有同步的指令在buffer中有可能已经被后续的指令覆盖掉了，从节点将无法直接通过指令流来进行同步，这个时候就需要用到更加复杂的同步机制–快照同步。  </p><h2 id="快照同步"><a href="#快照同步" class="headerlink" title="快照同步"></a>快照同步</h2><p>快照同步是一个非常耗费资源的操作，它首先需要在主库上进行一次bgsave将当前内存中的数据全部快照到磁盘文件中，然后再将快照文件的传送给从节点。从节点在接收完毕后，立即执行一次全量加载，加载之前会将内存中的数据清空。加载完毕后通知主节点继续进行增量同步。  </p><p>在整个快照同步执行的过程中，主节点的复制buffer还在不停的往前移动，如果快照同步的时间过长或者复制buffer太小，都会导致同步期间的增量指令在复制buffer中被覆盖，这样就会导致快照同步完成后无法进行增量复制，然后会再次发起快照同步，如果极有可能陷入无限的死循环，从而影响主节点的正常服务。<br><img src="https://i.imgur.com/aw8EZAS.jpg" alt=""><br><b>请务必设置一个合适复制buffer大小参数，避免这种情况的发生。</b>  </p><h2 id="无盘复制"><a href="#无盘复制" class="headerlink" title="无盘复制"></a>无盘复制</h2><p>主节点在进行快照同步时，会进行很重的文件IO操作，特别是对于非SSD磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行AOF的fsync操作时如果发生快照，fsync将会被推迟执行，这就会严重影响主节点的服务效率。  </p><p>所以从Redis2.8.18版开始支持无盘复制。所谓无盘复制就是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内容，一边将序列化的内容发送给从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。  </p><h2 id="Wait指令"><a href="#Wait指令" class="headerlink" title="Wait指令"></a>Wait指令</h2><p>Redis的复制是异步进行的，wait指令可以让异步复制变身同步复制，确保系统的强一致性（不严格）。wait指令时Redis3.0版本以后出现的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;set key value  </span><br><span class="line">OK  </span><br><span class="line">&gt;wait 1 0  </span><br><span class="line">(interge) 1</span><br></pre></td></tr></table></figure></p><p>wait提供两个参数，第一个参数是从库的数量N，第二个参数是时间t，以毫秒为单位。它表示等待wait指令之前的所有写操作同步到N个从库（也就是确保N个从库的同步没有滞后），最多等待时间t。如果时间t=0，代表无限等待知道N个从库同步完成达到一致。  </p><p>假设此时出现了网络分区，wait指令第二个参数时间t=0，主从同步无法继续进行，wait指令会永远阻塞，Redis服务器将丧失可用性。  </p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>主从复制是Redis分布式的基础，Redis的高可用离开了朱重构复制将无法进行。  </p><p>如果你将Redis只用作缓存，跟memcache一样对待，也就唔需要从库做备份，挂掉了重新启动一下就行了。但是只要你使用了Redis的持久化功能，就必须认真对待主从复制，它是系统数据安全的基础保障。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;很多企业都没有使用到Redis的集群，但是至少都做了主从。有了主从，当master挂掉的时候，运维让从库过来接管，服务就可以继续，否则master需要经过数据恢复和重启的过程，这就可能会拖很长时间，影响线上业务的持续服务。  &lt;/p&gt;
&lt;p&gt;在了解Redis主从复制之前，让我们先来理解一下现代分布式系统的理论基石–CAP原理。&lt;/p&gt;
&lt;h2 id=&quot;CAP原理&quot;&gt;&lt;a href=&quot;#CAP原理&quot; class=&quot;headerlink&quot; title=&quot;CAP原理&quot;&gt;&lt;/a&gt;CAP原理&lt;/h2&gt;&lt;p&gt;CAP原理就好比分布式领域的牛顿定律，它是分布式存储的理论基石。自打CAP的论文发表之后，分布式存储中间件犹如雨后春笋一个一个涌现出来。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C-Consistent 一致性&lt;/li&gt;
&lt;li&gt;A-Availability 可用性&lt;/li&gt;
&lt;li&gt;P-Partition tolerance 分区容忍性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分布式系统的节点往往都是分布在不同的机器上进行网络隔离开的，这意味着必然会有网络断开的风险，这个网络断开的场景的专业词汇叫着「网络分区」。&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis原理----事务</title>
    <link href="http://yoursite.com/2018/10/25/Redis/Redis%E5%8E%9F%E7%90%86----%E4%BA%8B%E5%8A%A1/"/>
    <id>http://yoursite.com/2018/10/25/Redis/Redis原理----事务/</id>
    <published>2018-10-25T13:34:13.000Z</published>
    <updated>2018-10-25T16:25:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>为了确保连续多个操作的原子性，一个成熟的数据库通常都会有事务支持，Redis也不例外。Redis的事务使用非常简单，不同于关系数据库，我们无需理解那么多复杂的事务模型了，就可以直接使用。不过也正是因为这种简单性，它的事务模型很不严格，这要求我们不能像使用关系数据库的事务一样使用Redis。</p><h2 id="Redis事务的基本使用"><a href="#Redis事务的基本使用" class="headerlink" title="Redis事务的基本使用"></a>Redis事务的基本使用</h2><p>每个事务的操作都有begin、commit、和rollback、begin指示事务的开始，commit指示事务的提交，rollback指示事务的回滚。</p><p>Redis与其差不多，对应的分别是multi/exec/discard。multi指示事务的开始，exec指示事务的执行，discard指示事务的丢弃。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;multi  </span><br><span class="line">OK  </span><br><span class="line">&gt;incr books  </span><br><span class="line">QUEUED  </span><br><span class="line">&gt;incr books  </span><br><span class="line">QUEUED  </span><br><span class="line">&gt;exec  </span><br><span class="line">(integer) 1</span><br><span class="line">(integer）2</span><br></pre></td></tr></table></figure><p>上面的指令演示了一个完整的事务过程，所有的指令在exec之前不执行，而是<font color="red">缓存在服务器的一个事务队列中</font>，服务器一旦受到exec指令，就开始执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。因为Redis的单线程特性，它不用担心自己在执行队列的时候被其他指令打搅，可以保证他们得到的[原子性]执行。<br><img src="https://i.imgur.com/l8Awrjs.jpg" alt=""><br>上图显示了以上事务过程完整的交互结果。QUEUED是一个简单字符串，同OK是一个形式，它表示指令已经被服务器缓存到队列里了。<br><a id="more"></a></p><h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>事务的原子性是指要么事务全部成功，要么全部失败，那么Redis事务的执行时原子性的么？  </p><p>下面我们来看一个特别的例子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;multi  </span><br><span class="line">OK  </span><br><span class="line">&gt;set books iamstring  </span><br><span class="line">QUEUED  </span><br><span class="line">&gt;incr books  </span><br><span class="line">QUEUED  </span><br><span class="line">&gt;set poorman iamdesperate  </span><br><span class="line">QUEUED  </span><br><span class="line">&gt;exec  </span><br><span class="line">1) OK  </span><br><span class="line">2) (error)ERR value is not an integer or out of range  </span><br><span class="line">3) OK  </span><br><span class="line">&gt;get books  </span><br><span class="line">&quot;iamstring&quot;  </span><br><span class="line">&gt;get poorman  </span><br><span class="line">&quot;iamdesperate&quot;</span><br></pre></td></tr></table></figure><p>上面的例子是事务执行到中间遇到失败了，因为我们不能对一个字符串进行数学运算，事务在遇到指令执行失败后，后面的指令还继续执行，所以poorman的值能继续得到设置。  </p><p>到这里，应该明白Redis的事务根本不能算[原子性]，而仅仅是满足了事务的[隔离性]，隔离性中的串行化–当前执行的事务有着不被其他事务打断的权利。</p><h2 id="discard-丢弃"><a href="#discard-丢弃" class="headerlink" title="discard(丢弃)"></a>discard(丢弃)</h2><p>Redis为事务提供了一个discard指令，用于丢弃事务缓存队列中的所有指令，在exec执行之前。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>上面Redis事务在发送每个指令到事务缓存队列时都要经过一次网络读写，当一个事务内部的指令较多时，需要的网络IO时间也会线性增长。所以通常Redis的客户端在执行事务时都会结合pipeline一起使用，这样可以将多次IO操作压缩为单次IO操作。</p><h2 id="Watch"><a href="#Watch" class="headerlink" title="Watch"></a>Watch</h2><p>考虑到一个业务场景，Redis存储了我们的账户余额数据，它是一个整数。现在有两个并发的客户端要对账户余额进行修改操作，这个修改不是简单的incrby指令，而是要对余额乘以一个倍数。Redis可没有提供multiplyby这样的指令。我们需要先取出余额然后在内存里乘以倍数，再将结果写回到Redis。  </p><p>这就会出现并发问题，因为有多个客户端会并发进行操作。我们可以通过Redis的分布式锁来避免冲突，这是一个很好的解决方案。<b>分布式锁是一种悲观锁，那是不是可以使用悲观锁的方式来解决冲突呢？</b>  </p><p>Redis提供了watch的机制，它就是一种悲观锁。有了watch我们又多了一种可以用来解决并发修改的方法。watch的使用方式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">while True:  </span><br><span class="line">do_watch()  </span><br><span class="line">commands()  </span><br><span class="line">multi()  </span><br><span class="line">send_commands()  </span><br><span class="line">try:  </span><br><span class="line">exec()  </span><br><span class="line">break  </span><br><span class="line">except WatchError:  </span><br><span class="line">continue</span><br></pre></td></tr></table></figure></p><p>watch会在事务开始之前盯住一个或多个关键变量，当事务执行时，也就是服务受到exec指令要顺序执行缓存的事务队列时，Redis会检查关键变量只watch之后，是否被修改了（包括当前事务所在客户端）。如果关键变量被人动过了，exec指令就会返回null回复告知客户端事务执行失败，这个时候客户端一般会想着重试。  </p><pre><code>&gt;watch books  OK  &gt;incr books  #被修改了  (integer) 1  &gt;multi  OK  &gt;incr books  QUEUED  &gt;exec  #事务执行失败  (nil)  </code></pre><p>当服务器给exec指令返回一个null回复时，客户端知道了事务执行是失败的，通常客户端(redis-py)都会抛出一个WatchError这种错误，不过也有些语言(jedis)不会抛出异常，而是通过在exec方法里返回一个null，这样客户端需要检查一下返回结果是否为null来确定事务是否执行失败。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>Redis禁止在multi和exec之间执行watch指令，而必须在multi之前做好盯住关键变量，否则会出错。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;为了确保连续多个操作的原子性，一个成熟的数据库通常都会有事务支持，Redis也不例外。Redis的事务使用非常简单，不同于关系数据库，我们无需理解那么多复杂的事务模型了，就可以直接使用。不过也正是因为这种简单性，它的事务模型很不严格，这要求我们不能像使用关系数据库的事务一样使用Redis。&lt;/p&gt;
&lt;h2 id=&quot;Redis事务的基本使用&quot;&gt;&lt;a href=&quot;#Redis事务的基本使用&quot; class=&quot;headerlink&quot; title=&quot;Redis事务的基本使用&quot;&gt;&lt;/a&gt;Redis事务的基本使用&lt;/h2&gt;&lt;p&gt;每个事务的操作都有begin、commit、和rollback、begin指示事务的开始，commit指示事务的提交，rollback指示事务的回滚。&lt;/p&gt;
&lt;p&gt;Redis与其差不多，对应的分别是multi/exec/discard。multi指示事务的开始，exec指示事务的执行，discard指示事务的丢弃。  &lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;multi  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;OK  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;incr books  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;QUEUED  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;incr books  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;QUEUED  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;exec  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;(integer) 1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;(integer）2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;上面的指令演示了一个完整的事务过程，所有的指令在exec之前不执行，而是&lt;font color=&quot;red&quot;&gt;缓存在服务器的一个事务队列中&lt;/font&gt;，服务器一旦受到exec指令，就开始执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。因为Redis的单线程特性，它不用担心自己在执行队列的时候被其他指令打搅，可以保证他们得到的[原子性]执行。&lt;br&gt;&lt;img src=&quot;https://i.imgur.com/l8Awrjs.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;上图显示了以上事务过程完整的交互结果。QUEUED是一个简单字符串，同OK是一个形式，它表示指令已经被服务器缓存到队列里了。&lt;br&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis原理----管道</title>
    <link href="http://yoursite.com/2018/10/24/Redis/Redis%E5%8E%9F%E7%90%86----%E7%AE%A1%E9%81%93/"/>
    <id>http://yoursite.com/2018/10/24/Redis/Redis原理----管道/</id>
    <published>2018-10-24T13:34:13.000Z</published>
    <updated>2018-10-24T16:22:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>大多数人一直对Redis管道有一个误解，他们以为这是Redis服务器提供的一种特别的技术，有了这种技术就可以加速Redis的存取效率。但是实际上Redis管道（Pipeline）本身并不是Redis服务器直接提供的技术，这个技术本质上是由客户端提供的，跟服务器没有什么直接的关系。</p><h2 id="Redis的消息交互"><a href="#Redis的消息交互" class="headerlink" title="Redis的消息交互"></a>Redis的消息交互</h2><p>当我们使用客户端对Redis进行一次操作时，如下图所示，客户端将请求传送给服务器，服务器处理完毕后，再将响应回复给客户端。这要花费一个网络数据包的来回时间。  </p><p><img src="https://i.imgur.com/ulCYBhP.jpg" alt=""><br><a id="more"></a><br>如果连续执行多条指令，那就会花费多个网络数据包来回的时间。如下图所示。  </p><p><img src="https://i.imgur.com/zxGuLwE.jpg" alt="">  </p><p>回到客户端代码层面，客户端是经历了写-读-写-读四个操作才完整的执行了两条指令。  </p><p><img src="https://i.imgur.com/kW9apz0.jpg" alt="">  </p><p>现在如果我们调整读写顺序，改成写-写-读-读，这两个指令同样可以正常完成。  </p><p><img src="https://i.imgur.com/V6yvFoA.jpg" alt=""><br>两个连续的写操作和两个连续的读操作总共只会花费一次网络来回，就好比连续的write操作合并了，连续的read操作也合并了一样。</p><p><img src="https://i.imgur.com/qvHYXje.jpg" alt="">    </p><p>这便是管道操作的本质，服务器根本没有任何区别对待，还是收到一条消息，执行一条消息，回复一条消息的正常流程。客户端通过对管道中的指令列表改变读写顺序就可以大幅度节省IO时间，管道中指令越多，效果越好。  </p><h2 id="深入理解管道本质"><a href="#深入理解管道本质" class="headerlink" title="深入理解管道本质"></a>深入理解管道本质</h2><p>接下来我们深入分析一个请求交互的流程，真实的情况是它很复杂，因为要经过网络协议栈，这个就得深入内核了。  </p><p><img src="https://i.imgur.com/Ub6GJ4Z.jpg" alt="">  </p><p>上图就是一个完整的请求交互图。  </p><ol><li>客户端进程挑用write将消息写到操作系统内核为套接字分配的发送缓冲send buffer。  </li><li>客户端操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过[网际路由]送到服务器的网卡。  </li><li>服务器操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲recv buffer。  </li><li>服务器进程调用read从接收缓冲中取出消息进行处理。  </li><li>服务器进程调用write将响应消息写到内核为套接字分配的发送缓冲send buffer。  </li><li>服务器操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过[网际路由]送到客户端网卡。  </li><li>客户端操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲recv buffer。  </li><li>客户端进程调用read从接收缓冲中取出消息返回给上层业务逻辑进行处理。  </li><li>结束。  </li></ol><p>其中步骤5-8和1-4是一样的，只不过方向是反过来的，一个是请求，一个是响应。  </p><p>我们开始以为write操作是要等到对方收到消息才会返回，但实际上不是这样的。write操作只负责将数据写到本地操作系统内核的发送缓冲然后就返回了。剩下的事交给操作系统内核异步将数据送到目标机器。但是如果发送缓冲满了，那么就需要等待缓冲空出空间来，这个就是写IO操作的真正耗时。  </p><p>我们开始以为read操作是从目标机器拉取数据，但实际上不是这样的。read操作只负责将数据从本地操作系统内核的接收缓冲中取出来。但是如果缓冲是空的，那么就需要等待数据到来，这个就是读IO操作的真正耗时。  </p><p>所以对于value = redis.get(key)这样一个简单的请求来说，write操作几乎没有耗时，直接写到发送缓冲就返回，而read就比较耗时了，因为他要等待消息经过网际路由到目标机器处理后的响应消息，再回送到当前的内核读缓冲才可以返回。<b>这是才是一个网络来回的真正开销。</b>  </p><p>而对于管道来说，连续的write操作根本没有耗时，之后第一个read操作会等待一个网络的来回开销，然后所有的响应消息就都已经回送到内核的读缓存了，后续的read操作直接就可以从缓冲拿到结果，瞬间就返回了。  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大多数人一直对Redis管道有一个误解，他们以为这是Redis服务器提供的一种特别的技术，有了这种技术就可以加速Redis的存取效率。但是实际上Redis管道（Pipeline）本身并不是Redis服务器直接提供的技术，这个技术本质上是由客户端提供的，跟服务器没有什么直接的关系。&lt;/p&gt;
&lt;h2 id=&quot;Redis的消息交互&quot;&gt;&lt;a href=&quot;#Redis的消息交互&quot; class=&quot;headerlink&quot; title=&quot;Redis的消息交互&quot;&gt;&lt;/a&gt;Redis的消息交互&lt;/h2&gt;&lt;p&gt;当我们使用客户端对Redis进行一次操作时，如下图所示，客户端将请求传送给服务器，服务器处理完毕后，再将响应回复给客户端。这要花费一个网络数据包的来回时间。  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ulCYBhP.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis原理----持久化</title>
    <link href="http://yoursite.com/2018/10/22/Redis/Redis%E5%8E%9F%E7%90%86----%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    <id>http://yoursite.com/2018/10/22/Redis/Redis原理----持久化/</id>
    <published>2018-10-22T13:30:13.000Z</published>
    <updated>2018-10-23T15:25:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>Redis的数据全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证Redis的数据不会因为故障而丢失，这种机制就是Redis的持久化机制。  </p><p>Redis的持久化机制有两种，第一种就是快照（RDB文件），第二种就是AOF日志。快照是一次全量备份，AOF日志是连续的增量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑，而AOF日志记录的是内存数据修改的指令记录文本。AOF日志在长期的运行过程中会变得非常大，数据库重启时需要加载AOF日志进行指令重放，这个时间会变得无比漫长。所以需要定期进行AOF重写，给AOF文件瘦身。</p><h2 id="快照原理"><a href="#快照原理" class="headerlink" title="快照原理"></a>快照原理</h2><p>我们知道Redis是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。  </p><p>在服务线上请求的同时，Redis还需要进行内存快照，内存快照要求Redis必须进行文件IO操作，可文件IO操作是不能使用多路复用API。  </p><p>这意味着单线程同时在服务线上的请求和吉林文件IO操作，文件IO操作会严重拖垮服务器请求的性能。还有个<b>重要的问题就是为了不阻塞线上的业务，就需要边持久化边响应客户端请求</b>。持久化的同时，内存数据结构还在变化，比如一个大型的hash字典正在持久化，结果一个请求过来把它给删除了，还没持久化，这该怎么办？  </p><font color="red">Redis使用操作系统的多进程COW（copy On Write）机制来实现快照持久化。</font><a id="more"></a><h2 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h2><p>Redis在持久化时会调用glibc的函数fork产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。这时你可以将父子进程想象成一个连体婴儿，共享身体。这时liunx操作系统的机制，为了节约内存资源，所以尽可能让他们共享。在进程分离的一瞬间，内存的增长几乎没有明显变化。  </p><p>子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断修改。  </p><p>这个时候就会使用操作系统的COW机制进行数据段页的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程像一粒的页面是没有变化的，还是进程产生时那一瞬间的数据。  </p><p>随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的2倍大小。另外一个Redis实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分。每个页面的大小只有4k，一个Redis实例里面一般会有成千上万的页面。  </p><p>子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么Redis的持久化交【快照】的原因。接下来子进程就可以非常安心的遍历数据进行序列化写磁盘了。</p><h2 id="AOF原理"><a href="#AOF原理" class="headerlink" title="AOF原理"></a>AOF原理</h2><p>AOF日志存储的Redis服务器的顺序指令序列，AOF日志只记录对内存进行修改的指令记录。  </p><p>假设AOF日志记录了自Redis实例创建以来所有的修改性指令序列，那么就可以通过对一个空的Redis实例顺序执行所有的指令，也就是重放来恢复Redis当前实例的内存数据结构的状态。  </p><p>Redis会在收到客户端修改指令后，进行参数校验进行逻辑处理后，如果没有问题，就立即将该指令存储到AOF日志中，也就是先执行指令才将日志存盘。这点不同于leveldb、hbase等存储引擎，他们都是先存储日志再做逻辑处理。  </p><p>Redis在长期运行的过程中，AOF的日志会变得越来越多。如果实例宕机重启，重放整个AOF日志会非常耗时，导致 长时间Redis无法对外提供服务，所以需要对AOF进行日志瘦身。</p><h2 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h2><p>Redis提供了bgrewriteaof指令用于对AOF日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列Redis的操作指令，序列化到一个新的AOF日志文件中。序列化完毕后再将操作期间发生的增量AOF日志追加到这个新的AOF日志文件中，追加完毕后就立即替换旧的日志文件。</p><h2 id="fsync"><a href="#fsync" class="headerlink" title="fsync"></a>fsync</h2><p>AOF日志是以文件的形式存在的，当程序对AOF日志文件进行写操作时，实际上就是内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘。  </p><p>这意味着如果机器突然宕机，AOF日志内容可能还没来得及完全刷到磁盘，这个时候就会出现日志丢失。  </p><p>Linux的glibc提供了fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要Redis进程实时调用fsync函数就可以保证aof日志不丢失。但是fsync是一个磁盘IO操作，这意味着他很慢。如果Reids执行一条指令就要fsync一次，那么Redis的高性能地位就不保了。  </p><p>所以在生产环境的服务器中，Redis通常是每隔1s左右执行一次fsync操作，这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能使得数据少丢失。  </p><p>Redis提供了另外两种策略：永不fsync（让操作系统来决定何时同步磁盘），用一个指令就fsync一次（非常慢，基本不会在生产中使用）</p><h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><p>快照是通过开启子进程的方式进行的，它是一个比较耗资源的操作。<br>1、遍历整个内存，大块写磁盘会加重系统负载。<br>2、AOF的fsync是一个比较耗时的IO操作，它会降低Redis性能，同时也会增加系统IO负担。  </p><p>所以通常Redis的主节点是不会进行持久化操作，持久化操作主要在从节点进行。从节点是备份节点，没有来自客户端请求的压力，它的操作系统资源比较充沛。  </p><p>但是如果出现网络分区，从节点长期连不上主节点，就会出现数据不一致的问题，特别是网络分区出现的情况下又不小心主节点宕机了，那么数据就会丢失，所以在生产环境要做好实例监控工作，保证网络畅通或者能快速修复。另外还应该再增加一个从节点以降低网络分区的概率，只要有一个从节点数据同步正常，数据也就不会轻易丢失。</p><h2 id="Redis4-0混合持久化"><a href="#Redis4-0混合持久化" class="headerlink" title="Redis4.0混合持久化"></a>Redis4.0混合持久化</h2><p>重启Redis时，我们很少使用rdb来恢复内存状态，因为会丢失大量数据。我们通常使用AOF日志重做，但是重放AOF日志性能相对RDB来说要慢很多，这样在Redis实例很大的情况下，启动需要花费很长的时间。  </p><p>Redis4.0为了解决这个问题，带来了一个新的持久化选项–混合持久化。将RDB文件的内容和增量的AOF日志文件存在一起。这里的AOF日志不在是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量AOF日志，通常这部分AOF日志很小。  </p><p>于是在Redis重启的时候，可以先加载rdb的内容，然后再重放增量AOF日志就可以完全替代之前的AOF全量文件重放，重启效率大幅度提升。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis的数据全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证Redis的数据不会因为故障而丢失，这种机制就是Redis的持久化机制。  &lt;/p&gt;
&lt;p&gt;Redis的持久化机制有两种，第一种就是快照（RDB文件），第二种就是AOF日志。快照是一次全量备份，AOF日志是连续的增量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑，而AOF日志记录的是内存数据修改的指令记录文本。AOF日志在长期的运行过程中会变得非常大，数据库重启时需要加载AOF日志进行指令重放，这个时间会变得无比漫长。所以需要定期进行AOF重写，给AOF文件瘦身。&lt;/p&gt;
&lt;h2 id=&quot;快照原理&quot;&gt;&lt;a href=&quot;#快照原理&quot; class=&quot;headerlink&quot; title=&quot;快照原理&quot;&gt;&lt;/a&gt;快照原理&lt;/h2&gt;&lt;p&gt;我们知道Redis是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。  &lt;/p&gt;
&lt;p&gt;在服务线上请求的同时，Redis还需要进行内存快照，内存快照要求Redis必须进行文件IO操作，可文件IO操作是不能使用多路复用API。  &lt;/p&gt;
&lt;p&gt;这意味着单线程同时在服务线上的请求和吉林文件IO操作，文件IO操作会严重拖垮服务器请求的性能。还有个&lt;b&gt;重要的问题就是为了不阻塞线上的业务，就需要边持久化边响应客户端请求&lt;/b&gt;。持久化的同时，内存数据结构还在变化，比如一个大型的hash字典正在持久化，结果一个请求过来把它给删除了，还没持久化，这该怎么办？  &lt;/p&gt;
&lt;font color=&quot;red&quot;&gt;Redis使用操作系统的多进程COW（copy On Write）机制来实现快照持久化。&lt;/font&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis源码阅读目录</title>
    <link href="http://yoursite.com/2018/10/21/Redis/Redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://yoursite.com/2018/10/21/Redis/Redis源码阅读/</id>
    <published>2018-10-21T13:34:13.000Z</published>
    <updated>2018-10-21T15:51:52.000Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th>文件</th><th style="text-align:center">作用</th></tr></thead><tbody><tr><td>adlist.c 、 adlist.h</td><td style="text-align:center">双端链表数据结构的实现。</td></tr><tr><td>ae.c 、 ae.h 、 ae_epoll.c 、 ae_evport.c 、 ae_kqueue.c 、 ae_select.c</td><td style="text-align:center">事件处理器，以及各个具体实现。</td></tr><tr><td>anet.c 、 anet.h</td><td style="text-align:center">Redis 的异步网络框架，内容主要为对 socket 库的包装。</td></tr><tr><td>aof.c</td><td style="text-align:center">AOF 功能的实现。</td></tr><tr><td>asciilogo.h</td><td style="text-align:center">保存了 Redis 的 ASCII LOGO 。</td></tr><tr><td>bio.c 、 bio.h</td><td style="text-align:center">Redis 的后台 I/O 程序，用于将 I/O 操作放到子线程里面执行， 减少 I/O 操作对主线程的阻塞。</td></tr><tr><td>bitops.c</td><td style="text-align:center">二进制位操作命令的实现文件。</td></tr><tr><td>blocked.c</td><td style="text-align:center">用于实现 BLPOP 命令和 WAIT 命令的阻塞效果。</td></tr><tr><td>cluster.c 、 cluster.h</td><td style="text-align:center">Redis 的集群实现。</td></tr><tr><td>config.c 、 config.h</td><td style="text-align:center">Redis 的配置管理实现，负责读取并分析配置文件， 然后根据这些配置修改 Redis 服务器的各个选项。</td></tr><tr><td>crc16.c 、 crc64.c 、 crc64.h</td><td style="text-align:center">计算 CRC 校验和。</td></tr><tr><td>db.c</td><td style="text-align:center">数据库实现。</td></tr><tr><td>debug.c</td><td style="text-align:center">调试实现。</td></tr><tr><td>dict.c 、 dict.h</td><td style="text-align:center">字典数据结构的实现。</td></tr><tr><td>endianconv.c 、 endianconv.h</td><td style="text-align:center">二进制的大端、小端转换函数。</td></tr><tr><td>fmacros.h</td><td style="text-align:center">一些移植性方面的宏。</td></tr><tr><td>help.h</td><td style="text-align:center">utils/generate-command-help.rb 程序自动生成的命令帮助信息。</td></tr><tr><td>hyperloglog.c</td><td style="text-align:center">HyperLogLog 数据结构的实现。</td></tr><tr><td>intset.c 、 intset.h</td><td style="text-align:center">整数集合数据结构的实现，用于优化 SET 类型。</td></tr><tr><td>lzf_c.c 、 lzf_d.c 、 lzf.h 、 lzfP.h</td><td style="text-align:center">Redis 对字符串和 RDB 文件进行压缩时使用的 LZF 压缩算法的实现。</td></tr><tr><td>Makefile 、 Makefile.dep</td><td style="text-align:center">构建文件。</td></tr><tr><td>memtest.c</td><td style="text-align:center">内存测试。</td></tr><tr><td>mkreleasehdr.sh</td><td style="text-align:center">用于生成释出信息的脚本。</td></tr><tr><td>multi.c</td><td style="text-align:center">Redis 的事务实现。</td></tr><tr><td>networking.c</td><td style="text-align:center">Redis 的客户端网络操作库， 用于实现命令请求接收、发送命令回复等工作， 文件中的函数大多为 write 、 read 、 close 等函数的包装， 以及各种协议的分析和构建函数。</td></tr><tr><td>notify.c</td><td style="text-align:center">Redis 的数据库通知实现。</td></tr><tr><td>object.c</td><td style="text-align:center">Redis 的对象系统实现。</td></tr><tr><td>pqsort.c 、 pqsort.h</td><td style="text-align:center">快速排序（QuickSort）算法的实现。</td></tr><tr><td>pubsub.c</td><td style="text-align:center">发布与订阅功能的实现。</td></tr><tr><td>rand.c 、 rand.h</td><td style="text-align:center">伪随机数生成器。</td></tr><tr><td>rdb.c 、 rdb.h</td><td style="text-align:center">RDB 持久化功能的实现。</td></tr><tr><td>redisassert.h</td><td style="text-align:center">Redis 自建的断言系统。</td></tr><tr><td>redis-benchmark.c</td><td style="text-align:center">Redis 的性能测试程序。</td></tr><tr><td>redis.c</td><td style="text-align:center">负责服务器的启动、维护和关闭等事项。</td></tr><tr><td>redis-check-aof.c 、 redis-check-dump.c</td><td style="text-align:center">RDB 文件和 AOF 文件的合法性检查程序。</td></tr><tr><td>redis-cli.c</td><td style="text-align:center">Redis 客户端的实现。</td></tr><tr><td>redis.h</td><td style="text-align:center">Redis 的主要头文件，记录了 Redis 中的大部分数据结构， 包括服务器状态和客户端状态。</td></tr><tr><td>redis-trib.rb</td><td style="text-align:center">Redis 集群的管理程序。</td></tr><tr><td>release.c 、 release.h</td><td style="text-align:center">记录和生成 Redis 的释出版本信息。</td></tr><tr><td>replication.c</td><td style="text-align:center">复制功能的实现。</td></tr><tr><td>rio.c 、 rio.h</td><td style="text-align:center">Redis 对文件 I/O 函数的包装， 在普通 I/O 函数的基础上增加了显式缓存、以及计算校验和等功能。</td></tr><tr><td>scripting.c</td><td style="text-align:center">脚本功能的实现。</td></tr><tr><td>sds.c 、 sds.h</td><td style="text-align:center">SDS 数据结构的实现，SDS 为 Redis 的默认字符串表示。</td></tr><tr><td>sentinel.c</td><td style="text-align:center">Redis Sentinel 的实现。</td></tr><tr><td>setproctitle.c</td><td style="text-align:center">进程环境设置函数。</td></tr><tr><td>sha1.c 、 sha1.h</td><td style="text-align:center">SHA1 校验和计算函数。</td></tr><tr><td>slowlog.c 、 slowlog.h</td><td style="text-align:center">慢查询功能的实现。</td></tr><tr><td>solarisfixes.h</td><td style="text-align:center">针对 Solaris 系统的补丁。</td></tr><tr><td>sort.c</td><td style="text-align:center">SORT 命令的实现。</td></tr><tr><td>syncio.c</td><td style="text-align:center">同步 I/O 操作。</td></tr><tr><td>testhelp.h</td><td style="text-align:center">测试辅助宏。</td></tr><tr><td>t_hash.c 、 t_list.c 、 t_set.c、 t_string.c 、 t_zset.c</td><td style="text-align:center">定义了 Redis 的各种数据类型，以及这些数据类型的命令。</td></tr><tr><td>util.c 、 util.h</td><td style="text-align:center">各种辅助函数。</td></tr><tr><td>valgrind.sup</td><td style="text-align:center">valgrind 的suppression文件。</td></tr><tr><td>version.h</td><td style="text-align:center">记录了 Redis 的版本号。</td></tr><tr><td>ziplist.c 、 ziplist.h</td><td style="text-align:center">ZIPLIST 数据结构的实现，用于优化 LIST 类型。</td></tr><tr><td>zipmap.c 、 zipmap.h</td><td style="text-align:center">ZIPMAP 数据结构的实现，在 Redis 2.6 以前用与优化 HASH 类型， Redis 2.6 开始已经废弃。</td></tr><tr><td>zmalloc.c 、 zmalloc.h</td><td style="text-align:center">内存管理程序。</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;文件&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;adlist.c 、 adlist.h&lt;/td&gt;
&lt;td style=&quot;t
      
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis原理----通信协议</title>
    <link href="http://yoursite.com/2018/10/21/Redis/Redis%E5%8E%9F%E7%90%86----%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/"/>
    <id>http://yoursite.com/2018/10/21/Redis/Redis原理----通信协议/</id>
    <published>2018-10-21T11:34:13.000Z</published>
    <updated>2018-10-21T15:19:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>Redis的作者认为数据库系统的瓶颈一般不在于网络流量，而是数据库自身内部逻辑处理上。所以即使Redis使用了浪费流量的文本协议，依然可以取得极高的访问性能。Redis将所有数据都放在内存，用一个单线程对外提供服务，单个节点在跑满一个CPU核心的情况下可以达到10w/s的超高QPS。</p><h2 id="RESP"><a href="#RESP" class="headerlink" title="RESP"></a>RESP</h2><p>RESP（Redis Serialization Protocol）是Redis序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。</p><p>Redis歇息将传输的数据结构分为5种最小单元类型，单元结束时统一加上回车换行符号\r\n。  </p><ul><li>单行字符以<font color="red">+</font>符号开头</li><li>多行字符以<font color="red">$</font>符号开头，后跟字符串长度</li><li>整数值以<font color="red">：</font>符号开头，后跟整数的字符串形式</li><li>错误消息以<font color="red">-</font>符号开头</li><li>数组以<font color="red">*</font>符号开头，后跟数组的长度</li></ul><p>单行字符<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+hello world\r\n</span><br></pre></td></tr></table></figure></p><p>多行字符串<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$11\r\n  </span><br><span class="line">hello world\r\n</span><br></pre></td></tr></table></figure></p><p>整数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:1024\r\n</span><br></pre></td></tr></table></figure></p><p>错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-WRONGTYPE Operation ....</span><br></pre></td></tr></table></figure></p><p>数组[1,2,3]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">*3\r\n  </span><br><span class="line">:1\r\n</span><br><span class="line">:2\r\n  </span><br><span class="line">:3\r\n</span><br></pre></td></tr></table></figure></p><a id="more"></a><h2 id="客户端-gt-服务器"><a href="#客户端-gt-服务器" class="headerlink" title="客户端-&gt;服务器"></a>客户端-&gt;服务器</h2><p>客户端向服务器发送的指令只有一种格式，多行字符串数组。比如一个简单的set指令set k v会被序列化成以下字符串。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*3\r\n  </span><br><span class="line">$3\r\n  </span><br><span class="line">set\r\n</span><br><span class="line">$1\r\n</span><br><span class="line">k\r\n</span><br><span class="line">$1\r\n</span><br><span class="line">v\r\n</span><br></pre></td></tr></table></figure></p><h2 id="服务器-gt-客户端"><a href="#服务器-gt-客户端" class="headerlink" title="服务器-&gt;客户端"></a>服务器-&gt;客户端</h2><p>服务器向客户端恢复的响应要支持多种数据结构，所以消息响应在结构上要复杂不少。不过在复杂的响应消息也是以上的5种基本类型的组合。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Redis协议里有大量冗余的回车换行符，但是这并不影响它成为互联网技术领域非常受欢迎的一个文本歇息。有很多开源项目目前使用RESP作为它的通讯协议。在技术领域性能并不是一切，还有简单性、易理解性和易实现性，这些都是需要进行适当权衡的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis的作者认为数据库系统的瓶颈一般不在于网络流量，而是数据库自身内部逻辑处理上。所以即使Redis使用了浪费流量的文本协议，依然可以取得极高的访问性能。Redis将所有数据都放在内存，用一个单线程对外提供服务，单个节点在跑满一个CPU核心的情况下可以达到10w/s的超高QPS。&lt;/p&gt;
&lt;h2 id=&quot;RESP&quot;&gt;&lt;a href=&quot;#RESP&quot; class=&quot;headerlink&quot; title=&quot;RESP&quot;&gt;&lt;/a&gt;RESP&lt;/h2&gt;&lt;p&gt;RESP（Redis Serialization Protocol）是Redis序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。&lt;/p&gt;
&lt;p&gt;Redis歇息将传输的数据结构分为5种最小单元类型，单元结束时统一加上回车换行符号\r\n。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单行字符以&lt;font color=&quot;red&quot;&gt;+&lt;/font&gt;符号开头&lt;/li&gt;
&lt;li&gt;多行字符以&lt;font color=&quot;red&quot;&gt;$&lt;/font&gt;符号开头，后跟字符串长度&lt;/li&gt;
&lt;li&gt;整数值以&lt;font color=&quot;red&quot;&gt;：&lt;/font&gt;符号开头，后跟整数的字符串形式&lt;/li&gt;
&lt;li&gt;错误消息以&lt;font color=&quot;red&quot;&gt;-&lt;/font&gt;符号开头&lt;/li&gt;
&lt;li&gt;数组以&lt;font color=&quot;red&quot;&gt;*&lt;/font&gt;符号开头，后跟数组的长度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;单行字符&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;+hello world\r\n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;多行字符串&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$11\r\n  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hello world\r\n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;整数&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;:1024\r\n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;错误&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;-WRONGTYPE Operation ....&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;数组[1,2,3]&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;*3\r\n  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;:1\r\n&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;:2\r\n  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;:3\r\n&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis原理----线程IO模型</title>
    <link href="http://yoursite.com/2018/10/20/Redis/Redis%E5%8E%9F%E7%90%86----%E7%BA%BF%E7%A8%8BIO%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2018/10/20/Redis/Redis原理----线程IO模型/</id>
    <published>2018-10-20T11:34:13.000Z</published>
    <updated>2018-10-20T15:45:52.000Z</updated>
    
    <content type="html"><![CDATA[<p><b>Redis是一个单线程程序</b></p><h2 id="非阻塞IO"><a href="#非阻塞IO" class="headerlink" title="非阻塞IO"></a>非阻塞IO</h2><p>当我们调用套接字的读写方法，默认他们是阻塞的，比如read方法要传递一个参数n，表示最多读取这门多字节后返回，如果一个字节都没有，那么线程就会卡在那里，直到新的数据到来或者连接关闭，read方法才可以返回，线程才能够继续处理。而write方法一般来说不会阻塞，除非内核为套接字分配的写缓冲区已经写满了，write方法才会阻塞，直到缓冲区有空闲空间。<img src="https://i.imgur.com/0sE9kXD.png" alt=""><br>非阻塞IO在套接字对象上提供了一个选项Non_Blocking,当这个选项打开时，读写方法不会阻塞。能读多少取决于内核为套接字分配的读缓冲区的空闲空间字节数，能写多少取决于内核为套接字分配的写缓冲区的空闲空间字节数。读方法和写方法都会通过返回值来告知程序实际读写了多少字节。</p><h2 id="事件轮询（多路复用）"><a href="#事件轮询（多路复用）" class="headerlink" title="事件轮询（多路复用）"></a>事件轮询（多路复用）</h2><p>非阻塞IO有个问题，就是线程要读数据，但是读了一部分就返回了，线程如何知道什么时候应该继续读，也就是当数据到来时，线程如何得到通知。写也是一样。<img src="https://i.imgur.com/bxF8jbN.png" alt=""><br>事件轮询API就是用来解决这个问题的，最简单的时间轮询API是select函数，它是操作系统提供给用户程序的API。输入时读写描述符列表read_fds &amp; write_fds，输出是与之对应的可读可写时间。同时还提供了一个timeout参数，如果没有任何事件的到来，那么最多等待timeout时间，线程处于阻塞状态。一旦期间有事件到来，就可以立即返回。线程就可以继续挨个处理相应的事件。处理完了继续过来轮询。于是线程就进入了一个死循环。我们把这个死循环称为事件轮询，一个循环为一个周期。<br><b>事件轮询API就是Java语言中的NIO技术</b></p><h2 id="指令队列"><a href="#指令队列" class="headerlink" title="指令队列"></a>指令队列</h2><p>Redis会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。</p><h2 id="响应队列"><a href="#响应队列" class="headerlink" title="响应队列"></a>响应队列</h2><p>Redis同样会为每个客户端套接字关联一个响应队列。<br>Redis服务器通过响应队列来将指令的返回结果回复给客户端。如果队列为空，那么以为这连接暂时处于空闲状态，不需要去获取写事件，也就是可以将当前的客户端描述符从write_fds里面移除。等到队列有数据了，再将描述符放进去。避免select系统调用立即返回写事件，结果发现没什么数据可以写。<b>出现这种情况的线程会飙高CPU</b></p><h2 id="定时任务"><a href="#定时任务" class="headerlink" title="定时任务"></a>定时任务</h2><p>服务器处理要响应的IO事件外，还要处理其他事情。比如定时任务。<br>如果线程阻塞在select系统调用上，定时任务将无法得到准时调度。那么Redis是如何解决这个问题的呢？  </p><p>Redis的定时任务会记录在一个最小堆的数据结构中。这个堆中，最快要执行的任务排在堆的最上方。在每个循环周期，Redis都会将最小堆里面已经到点的任务立即进行处理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是select系统调用的timeout参数。因为Redis知道未来timeout时间内，没有其他定时任务需要处理，所以可以安心睡眠timeout时间。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;b&gt;Redis是一个单线程程序&lt;/b&gt;&lt;/p&gt;
&lt;h2 id=&quot;非阻塞IO&quot;&gt;&lt;a href=&quot;#非阻塞IO&quot; class=&quot;headerlink&quot; title=&quot;非阻塞IO&quot;&gt;&lt;/a&gt;非阻塞IO&lt;/h2&gt;&lt;p&gt;当我们调用套接字的读写方法，默认他们是阻塞的，比如read方
      
    
    </summary>
    
      <category term="Redis" scheme="http://yoursite.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>reset master和reset slave</title>
    <link href="http://yoursite.com/2018/09/23/MySQL/reset%20master%E5%92%8Crester%20slave/"/>
    <id>http://yoursite.com/2018/09/23/MySQL/reset master和rester slave/</id>
    <published>2018-09-23T08:11:15.000Z</published>
    <updated>2019-01-20T15:25:06.468Z</updated>
    
    <content type="html"><![CDATA[<h3 id="reset-master"><a href="#reset-master" class="headerlink" title="reset master"></a>reset master</h3><p>删除index file中记录的所有binlog文件，将日志索引文件清空，创建一个新的日志文件，这个命令通常用于第一次搭建主从关系的主库。  </p><h4 id="reset-master和purge-binary-log的区别"><a href="#reset-master和purge-binary-log的区别" class="headerlink" title="reset master和purge binary log的区别"></a>reset master和purge binary log的区别</h4><ol><li>reset master 删除日志索引文件中记录的所有binlog文件，重新建立一个新的日志文件，起始值从000001开始，purge binary log 命令不会修改记录binlog顺序的数值</li><li>reset master 不能用于有任何slave正在运行的主从关系的主库。因为在slave运行时刻reset master命令不被支持。从库此时会报错。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In MySQL 5.6.5 and later, RESET MASTER also clears the values of the gtid_purged system variable (known as gtid_lost in MySQL 5.6.8 and earlier) as well as the global value of the gtid_executed (gtid_done, prior to MySQL 5.6.9) system variable (but not its session value); that is, executing this statement sets each of these values to an empty string (&apos;&apos;)</span><br></pre></td></tr></table></figure></li></ol><h3 id="reset-slave"><a href="#reset-slave" class="headerlink" title="reset slave"></a>reset slave</h3><p>reset slave 将使slave忘记主从复制关系的位置信息。该语句用于干净的启动，它删除master.info文件和relay-log.info文件以及所有的relay log文件并重新启用一个新的relay-log文件。</p><h3 id="reset-slave-all"><a href="#reset-slave-all" class="headerlink" title="reset slave all"></a>reset slave all</h3><p>在 5.6 版本中 reset slave 并不会清理存储于内存中的复制信息比如  master host, master port, master user, or master password,也就是说如果没有使用change master 命令做重新定向，执行start slave 还是会指向旧的master 上面。<br>当从库执行reset slave之后,将mysqld shutdown 复制参数将被重置。<br>在5.6.3 版本以及以后 使用使用 RESET SLAVE ALL 来完全的清理复制连接参数信息。(Bug #11809016)<br>RESET SLAVE ALL does not clear the IGNORE_SERVER_IDS list set by CHANGE MASTER TO. This issue is fixed in MySQL 5.7. (Bug #18816897)<br>In MySQL 5.6.7 and later, RESET SLAVE causes an implicit commit of an ongoing transaction. See Section 13.3.3, “Statements That Cause an Implicit Commit”.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;reset-master&quot;&gt;&lt;a href=&quot;#reset-master&quot; class=&quot;headerlink&quot; title=&quot;reset master&quot;&gt;&lt;/a&gt;reset master&lt;/h3&gt;&lt;p&gt;删除index file中记录的所有binlog文件，将日志
      
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>python装饰器</title>
    <link href="http://yoursite.com/2018/08/19/python/python%E8%A3%85%E9%A5%B0%E5%99%A8/"/>
    <id>http://yoursite.com/2018/08/19/python/python装饰器/</id>
    <published>2018-08-19T13:40:56.000Z</published>
    <updated>2018-08-19T14:08:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>python装饰器就是用于<font color="red">扩展原来函数功能的一种函数</font>，这个函数的特殊之处在于它的返回值也是一个函数。使用python装饰器的好处就是在不用更改原函数的代码前提下给函数增加新的功能。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原函数</span><br><span class="line">def func():</span><br><span class="line">print(&quot;hello&quot;)</span><br></pre></td></tr></table></figure></p><p>要想扩展一个函数的功能，最简单的方法就是直接修改原函数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def func():</span><br><span class="line">print(&quot;before&quot;)</span><br><span class="line">print(&quot;hello&quot;)</span><br><span class="line">print(&quot;after&quot;)</span><br></pre></td></tr></table></figure></p><p>如果不想修改原函数，还是想增强函数的功能时，可以另外定义一个函数调用原函数。（类似于设计模式中的装饰模式，有组合和代理两种方式）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def deco(func):</span><br><span class="line">print(&quot;before&quot;)</span><br><span class="line">func()</span><br><span class="line">print(&quot;after&quot;)</span><br><span class="line"></span><br><span class="line">def func():</span><br><span class="line">print(&quot;hello&quot;)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    f = func</span><br><span class="line">    deco(f)#只有把func()或者f()作为参数执行，新加入功能才会生效</span><br><span class="line">    print(&quot;f.__name__ is&quot;,f.__name__)#f的name就是func()</span><br><span class="line">    print()</span><br><span class="line">    #func()</span><br></pre></td></tr></table></figure></p><p>但是如果存在很多个类似于func的函数需要相同的扩展，那岂不是要执行deco函数许多次？<br>下面我们实现一个最简陋的装饰器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def deco(func):</span><br><span class="line">def wrapper(*args, **kwargs):</span><br><span class="line">print(&quot;before&quot;)</span><br><span class="line">func(*args, **kwargs)</span><br><span class="line">print(&quot;after&quot;)</span><br><span class="line">return wrapper</span><br><span class="line"></span><br><span class="line">@deco</span><br><span class="line">def func():</span><br><span class="line">print(&quot;hello&quot;)</span><br></pre></td></tr></table></figure></p><p>这里的deco函数就是最原始的装饰器，它的参数是一个函数，然后返回值也是一个函数。其中作为参数的这个函数func()就在返回函数wrapper()的内部执行。然后在函数func()前面加上@deco。<br>所以这里装饰器就像一个注入符号：有了它，拓展了原来函数的功能既不需要侵入函数内更改代码，也不需要重复执行原函数。<br>在func函数前还可以使用多个@的方式来执行多个装饰器，多个装饰器的执行顺序就是从最后一个装饰器开始执行到第一个装饰器，在执行函数本身。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def dec1(func):  </span><br><span class="line">    print(&quot;1111&quot;)  </span><br><span class="line">    def one():  </span><br><span class="line">        print(&quot;2222&quot;)  </span><br><span class="line">        func()  </span><br><span class="line">        print(&quot;3333&quot;)  </span><br><span class="line">    return one  </span><br><span class="line"></span><br><span class="line">def dec2(func):  </span><br><span class="line">    print(&quot;aaaa&quot;)  </span><br><span class="line">    def two():  </span><br><span class="line">        print(&quot;bbbb&quot;)  </span><br><span class="line">        func()  </span><br><span class="line">        print(&quot;cccc&quot;)  </span><br><span class="line">    return two  </span><br><span class="line"></span><br><span class="line">@dec1  </span><br><span class="line">@dec2  </span><br><span class="line">def test():  </span><br><span class="line">    print(&quot;test test&quot;)  </span><br><span class="line"></span><br><span class="line">test()  </span><br><span class="line"></span><br><span class="line">aaaa  </span><br><span class="line">1111  </span><br><span class="line">2222  </span><br><span class="line">bbbb  </span><br><span class="line">test test  </span><br><span class="line">cccc  </span><br><span class="line">3333</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;python装饰器就是用于&lt;font color=&quot;red&quot;&gt;扩展原来函数功能的一种函数&lt;/font&gt;，这个函数的特殊之处在于它的返回值也是一个函数。使用python装饰器的好处就是在不用更改原函数的代码前提下给函数增加新的功能。&lt;br&gt;&lt;figure class=&quot;hig
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>MySQL主从复制</title>
    <link href="http://yoursite.com/2018/08/16/MySQL/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    <id>http://yoursite.com/2018/08/16/MySQL/MySQL主从复制/</id>
    <published>2018-08-16T07:11:15.000Z</published>
    <updated>2019-01-20T15:26:10.648Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是主从复制"><a href="#什么是主从复制" class="headerlink" title="什么是主从复制"></a>什么是主从复制</h3><p>将主数据库中的DDL和DML操作通过二进制日志文件传输到从数据库上，然后将这些日志重新执行（重做）；从而使从数据库的数据和主数据库的数据保持一致。</p><h3 id="主从复制的作用"><a href="#主从复制的作用" class="headerlink" title="主从复制的作用"></a>主从复制的作用</h3><ul><li>主数据库出现问题时，可以切换到从数据库</li><li>可以在数据库层面进行读写分离</li><li>可以在从数据库上进行备份操作</li></ul><h3 id="复制过程"><a href="#复制过程" class="headerlink" title="复制过程"></a>复制过程</h3><p><img src="http://ocx5m3vc3.bkt.clouddn.com/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png" alt=""><br>Binary log：主数据库的二进制文件<br>Relay log：从服务器的中继日志<br><a id="more"></a></p><ol><li>master在每个事物更新数据完成之前，将该操作记录串行地写入binlog文件中。</li><li>salve开启一个I/O线程，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的时间。I/O线程最终的目的是将这些事件写入到中继日志中。</li><li>SQL线程会读取中继日志，并顺序执行该日志中的SQL时间，从而与主数据库中的数据保持一致。</li></ol><h3 id="配置主从"><a href="#配置主从" class="headerlink" title="配置主从"></a>配置主从</h3><p>一、主服务器</p><ul><li>开启二进制日志</li><li>配置唯一的server-id</li><li>创建一个用于slave和master通信的用户账号</li><li>获得master二进制日志文件名及位置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">skip-name-resolve</span><br><span class="line">basedir = /home/huzb/mysql</span><br><span class="line">datadir = /home/huzb/mysql/data</span><br><span class="line">port = 23307</span><br><span class="line">server_id = 119961011</span><br><span class="line">socket = /home/huzb/mysql/mysql_23307.sock</span><br><span class="line">log-bin = master-bin</span><br><span class="line">log-bin-index = master-bin.index</span><br><span class="line"> </span><br><span class="line">sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</span><br><span class="line"> </span><br><span class="line">[client]</span><br><span class="line">port = 23307</span><br><span class="line">socket = /home/huzb/mysql/mysql_23307.sock</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#添加复制权限的用户</span><br><span class="line"></span><br><span class="line">mysql&gt; CREATE USER &apos;repl&apos;@&apos;100.73.41.62&apos; IDENTIFIED BY &apos;slavepass&apos;;</span><br><span class="line">mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &apos;repl&apos;@&apos;100.73.41.62&apos;;</span><br><span class="line"></span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看master状态</span><br><span class="line"></span><br><span class="line">mysql&gt; show master status;</span><br></pre></td></tr></table></figure><p>二、从服务器：</p><ul><li>配置唯一的server-id</li><li>使用master分配的用户账号读取master二进制日志</li><li>启动slave服务<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">skip-name-resolve</span><br><span class="line">basedir = /home/huzb/mysql</span><br><span class="line">datadir = /home/huzb/mysql/data</span><br><span class="line">port = 23306</span><br><span class="line">server_id = 220180801</span><br><span class="line">socket = /home/huzb/mysql/mysql_23306.sock</span><br><span class="line">relay-log = slave-relay-bin</span><br><span class="line">relay-log-index = slave-relay-bin.index</span><br><span class="line"> </span><br><span class="line">sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</span><br><span class="line"> </span><br><span class="line">[client]</span><br><span class="line">port = 23306</span><br><span class="line">socket = /home/huzb/mysql/mysql_23306.sock</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#添加master信息</span><br><span class="line"></span><br><span class="line">mysql&gt; CHANGE MASTER TO</span><br><span class="line"></span><br><span class="line">MASTER_HOST=&apos;100.73.41.53&apos;,</span><br><span class="line">MASTER_PORT=23307,</span><br><span class="line">MASTER_USER=&apos;repl&apos;,</span><br><span class="line">MASTER_PASSWORD=&apos;slavepass&apos;,</span><br><span class="line">MASTER_LOG_FILE=&apos;master-bin.000001&apos;,</span><br><span class="line">MASTER_LOG_POS=629;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#启动slave进程</span><br><span class="line"></span><br><span class="line">mysql&gt; start slave;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#查看slave状态</span><br><span class="line"></span><br><span class="line">当Slave_IO_Running和Slave_SQL_Running都为YES的时候就表示主从同步设置成功了。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;什么是主从复制&quot;&gt;&lt;a href=&quot;#什么是主从复制&quot; class=&quot;headerlink&quot; title=&quot;什么是主从复制&quot;&gt;&lt;/a&gt;什么是主从复制&lt;/h3&gt;&lt;p&gt;将主数据库中的DDL和DML操作通过二进制日志文件传输到从数据库上，然后将这些日志重新执行（重做）；从而使从数据库的数据和主数据库的数据保持一致。&lt;/p&gt;
&lt;h3 id=&quot;主从复制的作用&quot;&gt;&lt;a href=&quot;#主从复制的作用&quot; class=&quot;headerlink&quot; title=&quot;主从复制的作用&quot;&gt;&lt;/a&gt;主从复制的作用&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;主数据库出现问题时，可以切换到从数据库&lt;/li&gt;
&lt;li&gt;可以在数据库层面进行读写分离&lt;/li&gt;
&lt;li&gt;可以在从数据库上进行备份操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;复制过程&quot;&gt;&lt;a href=&quot;#复制过程&quot; class=&quot;headerlink&quot; title=&quot;复制过程&quot;&gt;&lt;/a&gt;复制过程&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://ocx5m3vc3.bkt.clouddn.com/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Binary log：主数据库的二进制文件&lt;br&gt;Relay log：从服务器的中继日志&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL之备份</title>
    <link href="http://yoursite.com/2018/08/11/MySQL/MySQL%E4%B9%8B%E5%A4%87%E4%BB%BD/"/>
    <id>http://yoursite.com/2018/08/11/MySQL/MySQL之备份/</id>
    <published>2018-08-11T08:11:15.000Z</published>
    <updated>2019-01-20T15:25:57.349Z</updated>
    
    <content type="html"><![CDATA[<h2 id="备份的类型"><a href="#备份的类型" class="headerlink" title="备份的类型"></a>备份的类型</h2><h3 id="根据是否需要数据库离线"><a href="#根据是否需要数据库离线" class="headerlink" title="根据是否需要数据库离线"></a>根据是否需要数据库离线</h3><p>1、取决于业务的需求，而不是备份工具。<br>2、MyISAM不支持热备，INNODB支持热备，但是需要专门的工具。  </p><ul><li>冷备：需要关闭mysql服务，读写请求均不支持    状态下进行。</li><li>温备：服务在线，但仅支持读请求，不允许写请求。</li><li>热备：备份的同时，业务不受影响。</li></ul><h3 id="根据备份的数据集合的范围"><a href="#根据备份的数据集合的范围" class="headerlink" title="根据备份的数据集合的范围"></a>根据备份的数据集合的范围</h3><ul><li>完全备份：备份全部字符集。</li><li>增量备份：上一次完全备份或增量备份以来改变的数据。</li><li>差异备份：上一次完全备份以来改变的数。</li></ul><h3 id="根据备份数据或文件"><a href="#根据备份数据或文件" class="headerlink" title="根据备份数据或文件"></a>根据备份数据或文件</h3><ul><li>物理备份：直接备份数据文件。</li><li>逻辑备份：备份表中的数据和代码。<a id="more"></a></li></ul><h2 id="常用的备份工具"><a href="#常用的备份工具" class="headerlink" title="常用的备份工具"></a>常用的备份工具</h2><h3 id="mysqldump"><a href="#mysqldump" class="headerlink" title="mysqldump"></a>mysqldump</h3><p>mysqldump是逻辑备份，所以使用这种备份方式数据的安全的。跨平台、版本都很容易。  </p><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>mysqldump的优势是可以查看或者编辑十分方面，他可以灵活的恢复之前的数据。它也不关心底层的存储引擎，即适用于支持事务的，也适用于不支持事务的的表。  </p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>mysql的缺点是如果数据过大，即使备份步骤需要的时间不算太久，但有可能恢复数据的速度很慢，因为他涉及的SQL语句插入磁盘IO，创建索引等。</p><h3 id="mysqlhotcopy"><a href="#mysqlhotcopy" class="headerlink" title="mysqlhotcopy"></a>mysqlhotcopy</h3><p>mysqlhotcopy使用lock tables、flush tables、cp和scp来快速备份数据库。</p><h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><p>它是备份数据库或单个表最快的途径，完全属于物理备份。</p><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><p>只能用于备份MyIsam和archive存储引擎；并且是一个服务器命令，只能运行在数据库目录所在的机器上。使用mysqlhotcopy命令之前需要安装相应的软件依赖包。</p><h3 id="xtrabackup"><a href="#xtrabackup" class="headerlink" title="xtrabackup"></a>xtrabackup</h3><p>Percona XtraBackup是一款基于MySQL的物理热备份的开源实用程序。xtrabackup基于innodb的crash-recovery（实例恢复）功能，先copy innodb的物理文件（这个时候数据的一致性是无法满足的），然后进行基于redo log进行恢复，达到数据的一致性。</p><h3 id="mysqlbackup"><a href="#mysqlbackup" class="headerlink" title="mysqlbackup"></a>mysqlbackup</h3><p>首先检测并应用全备事务日志文件，然后基于全备去应用增量的log。这个时候如果有多次增量备份也可以（基于LSN点向后应用）。所有的的应用完成之后就是一个可以直接cp的数据库了。</p><h2 id="备份和恢复的实现"><a href="#备份和恢复的实现" class="headerlink" title="备份和恢复的实现"></a>备份和恢复的实现</h2><ol><li>使用select into outfile实现数据的备份和还原。<br>1.1 把需要备份的数据备份出来<br>select * from test into outfile ‘/tmp/out.txt’;<br>1.2 导入<br>load data infile ‘/tmp/out.txt’ into table XXX;</li><li>利用mysqldump工具对数据进行备份和还原<br>mysqldump常用来做温备，所以需要对想备份的数据施加读锁。<br>2.1 施加读锁的方式：<br>2.1.1 直接在备份时添加选项<br>–lock-all-tables：对要备份的数据库的所有表施加读锁。<br>–lock-table：对单表施加读锁。<br>2.1.2 在服务端书写命令<br>mysql&gt;flush tables with read lock;施加锁，表示把内存上的表统统同步到磁盘上去后施加读锁。<br>mysql&gt;flush tables with read unlock;释放锁。<br>2.2 备份策略：完全备份+增量备份+二进制文件。</li></ol><ul><li>先给数据库做全量备份</li><li>回到mysql服务器更新数据</li><li>做增量备份</li><li>到处二进制文件</li><li>让mysql离线</li></ul><ol start="3"><li>利用lvm快照实现几乎热备的数据备份和恢复</li><li>基于Xtrabackup做备份恢复<br>优势：</li></ol><ul><li>快速可靠的进行完全备份</li><li>在备份过程中会影响事务</li><li>支持数据流、网络传输、压缩，所以它可以有效的节约磁盘资源和网络带宽。</li><li>可以自动备份校验数据的可用性。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;备份的类型&quot;&gt;&lt;a href=&quot;#备份的类型&quot; class=&quot;headerlink&quot; title=&quot;备份的类型&quot;&gt;&lt;/a&gt;备份的类型&lt;/h2&gt;&lt;h3 id=&quot;根据是否需要数据库离线&quot;&gt;&lt;a href=&quot;#根据是否需要数据库离线&quot; class=&quot;headerlink&quot; title=&quot;根据是否需要数据库离线&quot;&gt;&lt;/a&gt;根据是否需要数据库离线&lt;/h3&gt;&lt;p&gt;1、取决于业务的需求，而不是备份工具。&lt;br&gt;2、MyISAM不支持热备，INNODB支持热备，但是需要专门的工具。  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;冷备：需要关闭mysql服务，读写请求均不支持    状态下进行。&lt;/li&gt;
&lt;li&gt;温备：服务在线，但仅支持读请求，不允许写请求。&lt;/li&gt;
&lt;li&gt;热备：备份的同时，业务不受影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;根据备份的数据集合的范围&quot;&gt;&lt;a href=&quot;#根据备份的数据集合的范围&quot; class=&quot;headerlink&quot; title=&quot;根据备份的数据集合的范围&quot;&gt;&lt;/a&gt;根据备份的数据集合的范围&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;完全备份：备份全部字符集。&lt;/li&gt;
&lt;li&gt;增量备份：上一次完全备份或增量备份以来改变的数据。&lt;/li&gt;
&lt;li&gt;差异备份：上一次完全备份以来改变的数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;根据备份数据或文件&quot;&gt;&lt;a href=&quot;#根据备份数据或文件&quot; class=&quot;headerlink&quot; title=&quot;根据备份数据或文件&quot;&gt;&lt;/a&gt;根据备份数据或文件&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;物理备份：直接备份数据文件。&lt;/li&gt;
&lt;li&gt;逻辑备份：备份表中的数据和代码。
    
    </summary>
    
      <category term="MySQL" scheme="http://yoursite.com/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
  </entry>
  
</feed>
